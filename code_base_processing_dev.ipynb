{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0cd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.image_processing as imgproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6ade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from re import sub\n",
    "from glob import glob\n",
    "from tqdm                   import tqdm\n",
    "import multiprocessing      as mp\n",
    "from functools              import partial\n",
    "from src.utils import execute_R\n",
    "from pyminc.volumes.factory import volumeFromFile\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "\n",
    "def gunzip_file(gzfile, keep = True, outdir = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Unzip a compressed file.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    gzfile: str\n",
    "        Path to the file to unzip.\n",
    "    keep: bool\n",
    "        Option to keep the compressed file after extraction.\n",
    "    outdir: str\n",
    "        Path to the output directory. If None, the file will\n",
    "        be unzipped in its native directory.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfile: str\n",
    "        Path to the unzipped file.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.system('gunzip -f -k {}'.format(gzfile))\n",
    "    outfile = sub(r'.gz', '', gzfile)\n",
    "    if not keep:\n",
    "        os.system('rm {}'.format(gzfile))\n",
    "    if outdir is not None:\n",
    "        outdir = os.path.join(outdir, '')\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        os.system('mv {} {}'.format(outfile, outdir))\n",
    "        outfile = os.path.join(outdir, os.path.basename(outfile))\n",
    "\n",
    "    return outfile\n",
    "\n",
    "\n",
    "def gunzip_files(infiles, keep = True, outdir = None, parallel = False, nproc = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Unzip a set of compressed files.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to files to unzip.\n",
    "    keep: bool\n",
    "        Option to keep the compressed files after extraction.\n",
    "    outdir: None\n",
    "        Path to the output directory. If None, the files will\n",
    "        be unzipped in their native directories.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nprpc: int\n",
    "        Number of processors to use in parallel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the unzipped files.\n",
    "    \"\"\"\n",
    "    \n",
    "    gunzip_file_partial = partial(gunzip_file, \n",
    "                                  keep = keep,\n",
    "                                  outdir = outdir)\n",
    "    if parallel:\n",
    "        if nproc is None:\n",
    "            raise ValueError(\"Set the nproc argument to specify the number of processors to use\")\n",
    "        pool = mp.Pool(nproc)\n",
    "        outfiles = []\n",
    "        for outfile in tqdm(pool.imap(gunzip_file_partial, infiles), total = len(infiles)):\n",
    "            outfiles.append(outfile)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        outfiles = list(map(gunzip_file_partial, tqdm(infiles)))\n",
    "        \n",
    "    return outfiles\n",
    "\n",
    "\n",
    "def nii_to_mnc(infile, keep = True, outdir = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert a NIFTY file to MINC format.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infile: str\n",
    "        Path to the NIFTY file to convert.\n",
    "    outdir: str\n",
    "        Path to the output directory. If None, the output\n",
    "        MINC file will be stored in the native directory.\n",
    "    keep: bool\n",
    "        Option to keep the input file. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfile: str\n",
    "        Path to the converted MINC file.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.system('nii2mnc -quiet -clobber {}'.format(infile))\n",
    "    outfile = sub(r'.nii', '.mnc', infile)\n",
    "    if not keep:\n",
    "        os.system('rm {}'.format(infile))\n",
    "    if outdir is not None:\n",
    "        outdir = os.path.join(outdir, '')\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        os.system('mv {} {}'.format(outfile, outdir))\n",
    "        outfile = os.path.join(outdir, os.path.basename(outfile))\n",
    "        \n",
    "    return outfile\n",
    "\n",
    "\n",
    "def mnc_to_nii(infile, keep = True, outdir = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert a MINC file to NIFTY format.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infile: str\n",
    "        Path to the MINC file to convert.\n",
    "    outdir: str\n",
    "        Path to the output directory. If None, the output\n",
    "        MINC file will be stored in the native directory.\n",
    "    keep: bool\n",
    "        Option to keep the input file. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfile: str\n",
    "        Path to the converted NIFTY file.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.system('mnc2nii -quiet {}'.format(infile))\n",
    "    outfile = sub(r'.mnc', '.nii', infile)\n",
    "    if not keep:\n",
    "        os.system('rm {}'.format(infile))\n",
    "    if outdir is not None:\n",
    "        outdir = os.path.join(outdir, '')\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        os.system('mv {} {}'.format(outfile, outdir))\n",
    "        outfile = os.path.join(outdir, os.path.basename(outfile))\n",
    "        \n",
    "    return outfile\n",
    "    \n",
    "    \n",
    "def convert_images(infiles, input_format = 'nifty', output_format = 'minc', keep = True, outdir = None, parallel = False, nproc = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert a set of images from NIFTY to MINC or vice versa.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to images to convert.\n",
    "    input_format: str\n",
    "        One of {'nifty', 'minc'} indicating the input format.\n",
    "    output_format: str\n",
    "        One of {'nifty', 'minc'} indicating the output format. \n",
    "        Must be different from the input format.\n",
    "    keep: bool\n",
    "        Option to keep the input file. \n",
    "    outdir: str\n",
    "        Path to the output directory. If None, the converted\n",
    "        images will be stored in the native directory.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nprpc: int\n",
    "        Number of processors to use in parallel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the converted images.\n",
    "    \"\"\"\n",
    "        \n",
    "    if (input_format == 'nifty') & (output_format == 'minc'):\n",
    "        converter = partial(nii_to_mnc, keep = keep, outdir = outdir)\n",
    "    elif (input_format == 'minc') & (output_format == 'nifty'):\n",
    "        converter = partial(mnc_to_nii, keep = keep, outdir = outdir)\n",
    "    else:\n",
    "        raise ValueError \n",
    "        \n",
    "    if parallel:\n",
    "        if nproc is None:\n",
    "            raise ValueError(\"Set the nproc argument to specify the number of processors to use\")\n",
    "        pool = mp.Pool(nproc)\n",
    "        outfiles = []\n",
    "        for outfile in tqdm(pool.imap(converter, infiles), total = len(infiles)):\n",
    "            outfiles.append(outfile)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        outfiles = list(map(converter, tqdm(infiles)))\n",
    "        \n",
    "    return outfiles\n",
    "    \n",
    "    \n",
    "def calculate_human_effect_sizes(demographics, imgdir, maskfile, outdir, ncontrols = 10, threshold = 10, dataset = 1, parallel = False, nproc = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate human effect size images.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    demographics: str\n",
    "        Path to the CSV file containing the human demographics data.\n",
    "    imgdir: str\n",
    "        Path to the directory containing the MINC images to use to compute the effect sizes.\n",
    "    maskfile: str\n",
    "        Path to the mask MINC file for the images.\n",
    "    outdir: str\n",
    "        Path to the directory in which to save the effect size MINC images.\n",
    "    ncontrols: int\n",
    "        Number of propensity-matched controls to use when computing the effect sizes.\n",
    "    threshold: int\n",
    "    dataset: int\n",
    "        A numeric flag indicating which data to use. Set to 1 for all data. Set to 2 for POND and SickKids. Set to 3 for POND only.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nproc: int\n",
    "        Number of processors to use in parallel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the effect size images.\n",
    "    \"\"\"\n",
    "\n",
    "    script = 'calculate_human_effect_sizes.R'\n",
    "    if parallel:\n",
    "        if nproc is None:\n",
    "            raise ValueError(\"Set the nproc argument to specify the number of processors to use\")\n",
    "    else: \n",
    "        nproc = 1\n",
    "    parallel = 'true' if parallel else 'false'\n",
    "    script_args = {'demographics':demographics,\n",
    "                   'imgdir':imgdir,\n",
    "                   'maskfile':maskfile,\n",
    "                   'outdir':outdir,\n",
    "                   'ncontrols':ncontrols,\n",
    "                   'threshold':threshold,\n",
    "                   'dataset':dataset,\n",
    "                   'parallel':parallel,\n",
    "                   'nproc':nproc}\n",
    "    execute_R(script = script, args = script_args)\n",
    "    outfiles = os.listdir(outdir)\n",
    "    return outfiles\n",
    "\n",
    "\n",
    "def resample_image(infile, isostep, outdir = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Resample a MINC image\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infile: str\n",
    "        Path to the image file to resample.\n",
    "    isostep: float\n",
    "        Isotropic dimension of voxels in the resampled image (millimeters).\n",
    "    outdir: str\n",
    "        Path to the directory in which to save the resampled image. If None, resampled image will be written to the directory of the input file.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outfile: str\n",
    "        Path to the resampled image. \n",
    "    \"\"\"\n",
    "    \n",
    "    outfile = sub(r'.mnc', '_resampled_{}.mnc'.format(isostep), infile)\n",
    "    if outdir is not None:\n",
    "        outdir = os.path.join(outdir, '')\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        outfile = os.path.basename(outfile)\n",
    "        outfile = os.path.join(outdir, outfile)\n",
    "    cmd_autocrop = ('autocrop -quiet -clobber -isostep {} {} {}'\n",
    "                    .format(isostep, infile, outfile))\n",
    "    os.system(cmd_autocrop)\n",
    "\n",
    "    return outfile\n",
    "\n",
    "\n",
    "def resample_images(infiles, isostep, outdir = None, parallel = False, nproc = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Resample a set of MINC images.\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to images to resample.\n",
    "    outdir: str\n",
    "        Path to the output directory. If None, the resampled \n",
    "        images will be stored in the native directory.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nproc: int\n",
    "        Number of processors to use in parallel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the resampled images.\n",
    "    \"\"\"\n",
    "\n",
    "    resampler = partial(resample_image,\n",
    "                        isostep = isostep,\n",
    "                        outdir = outdir)\n",
    "    \n",
    "    if parallel:\n",
    "        if nproc is None:\n",
    "            raise ValueError(\"Set the nproc argument to specify the number of processors to use in parallel.\")\n",
    "        pool = mp.Pool(nproc)\n",
    "        outfiles = []\n",
    "        for outfile in tqdm(pool.imap(resampler, infiles), total = len(infiles)):\n",
    "            outfiles.append(outfile)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        outfiles = list(map(resampler, tqdm(infiles)))\n",
    "        \n",
    "    return outfiles\n",
    "        \n",
    "\n",
    "def import_image(img, mask = None, flatten = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Import a MINC image.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    img: str\n",
    "        Path to the MINC image to import.\n",
    "    mask: str\n",
    "        Optional path to the MINC mask. \n",
    "    flatten: bool\n",
    "        Option to flatten image into a 1-dimensional array. \n",
    "        If True and a mask is provided, only the voxels in the mask will be returned.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img: numpy.ndarray\n",
    "        A NumPy array containing the (masked) image.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_vol = volumeFromFile(img)\n",
    "    img_dims = img_vol.getSizes()\n",
    "    img_seps = img_vol.getSeparations()\n",
    "    img = np.array(img_vol.data)\n",
    "    img_vol.closeVolume()\n",
    "\n",
    "    if flatten:\n",
    "        img = img.flatten()\n",
    "\n",
    "    if mask is not None:\n",
    "\n",
    "        mask_vol = volumeFromFile(mask)\n",
    "        mask_dims = mask_vol.getSizes()\n",
    "        mask_seps = mask_vol.getSeparations()\n",
    "        mask = np.array(mask_vol.data)\n",
    "        mask_vol.closeVolume()\n",
    "\n",
    "        if mask_seps != img_seps:\n",
    "            raise Exception(\"Input image and mask have different resolutions.\")\n",
    "        if mask_dims != img_dims:\n",
    "            raise Exception(\"Input image and mask have different dimensions.\")\n",
    "\n",
    "        if flatten:\n",
    "            mask = mask.flatten()\n",
    "            img = img[mask == 1]\n",
    "        else:\n",
    "            img[mask == 0] = 0\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def import_images(infiles, mask = None, output_format = 'list', flatten = True, parallel = False, nproc = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Import a set of MINC images.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to images to import.\n",
    "    mask: str\n",
    "        Optional path to a mask image. \n",
    "    output_format: str\n",
    "        One of {'list', 'numpy', 'pandas'} indicating what format to return.\n",
    "    flatten: bool\n",
    "        Option to flatten images into a 1-dimensional array. \n",
    "        If True and a mask is provided, only the voxels in the mask will be returned.\n",
    "        If False and output_format is not 'list', images will be flattened regardless.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nproc: int\n",
    "        Number of processors to use in parallel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imgs\n",
    "        A list, NumPy array, or Pandas DataFrame containing the (masked) images.\n",
    "    \"\"\"\n",
    "\n",
    "    format_opts = ['list', 'numpy', 'pandas']\n",
    "    format_test = sum([output_format == opt for opt in format_opts])\n",
    "    format_err = (\"Argument output_format must be one of {}: {}\"\n",
    "                   .format(format_opts, output_format))\n",
    "    if format_test != 1:\n",
    "        raise ValueError(format_err)\n",
    "\n",
    "    if not flatten:\n",
    "        if output_format != 'list':\n",
    "            msg_warn = (\"flatten = False is only valid when output_format = 'list'. \"\n",
    "                        \"Proceeding with flattened images.\")\n",
    "            warn(msg_warn)\n",
    "            flatten = True\n",
    "\n",
    "    importer = partial(import_image,\n",
    "                       mask = mask,\n",
    "                       flatten = flatten)\n",
    "\n",
    "    if parallel:\n",
    "        if nproc is None:\n",
    "            raise ValueError(\"Set the nproc argument to specify the number of processors to use in parallel.\")\n",
    "        pool = mp.Pool(nproc)\n",
    "        imgs = []\n",
    "        for img in tqdm(pool.imap(importer, infiles), total = len(infiles)):\n",
    "            imgs.append(img)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        imgs = list(map(importer, tqdm(infiles)))\n",
    "\n",
    "    imgsize_test = [len(img) for img in imgs]\n",
    "    imgsize_err = \"Images provided contain different numbers of voxels.\"\n",
    "    if len(set(imgsize_test)) != 1:\n",
    "        raise Exception(imgsize_err)\n",
    "\n",
    "    if output_format == 'numpy':\n",
    "        return np.asarray(imgs)\n",
    "    elif output_format == 'pandas':\n",
    "        return pd.DataFrame(np.asarray(imgs))\n",
    "    else: \n",
    "        return imgs\n",
    "    \n",
    "    \n",
    "\n",
    "def build_voxel_matrix(infiles, mask = None, file_col = False, sort = False, save = False, outfile = 'voxel_matrix.csv', parallel = False, nproc = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a data frame of voxels from a set of images.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to images.\n",
    "    mask: str\n",
    "        Optional path to a mask image. \n",
    "    file_col: bool\n",
    "        Option to store input files in a column. If true, the paths in infiles are stored in a column called 'file'.\n",
    "    sort: bool\n",
    "        Option to sort rows based on file names.\n",
    "    save: bool\n",
    "        Option to save to CSV.\n",
    "    outfile: str\n",
    "        Path to the output CSV file. Ignored if save = False.\n",
    "    parallel: bool\n",
    "        Option to run in parallel.\n",
    "    nproc: int\n",
    "        Number of processors to use in parallel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_imgs\n",
    "        A Pandas DataFrame containing the (masked) images.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_imgs = import_images(infiles = infiles,\n",
    "                           mask = mask,\n",
    "                           output_format = 'pandas',\n",
    "                           flatten = True,\n",
    "                           parallel = parallel,\n",
    "                           nproc = nproc)\n",
    "    df_imgs['file'] = infiles\n",
    "\n",
    "    if sort:\n",
    "        df_imgs = df_imgs.sort_values(by = 'file')\n",
    "\n",
    "    if not file_col:\n",
    "        df_imgs = df_imgs.drop('file', axis = 1)\n",
    "    \n",
    "    if save:\n",
    "        df_imgs.to_csv(outfile, index = False)\n",
    "    \n",
    "    return df_imgs\n",
    "\n",
    "\n",
    "def cluster_human_data(infiles, rownames = None, nk_max = 10, metric = 'correlation', K = 10, sigma = 0.5, t = 20, outfile = 'clusters.csv'):\n",
    "\n",
    "    \"\"\"\n",
    "    Cluster human effect size images using similarity network fusion.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    infiles: list\n",
    "        List of paths to the CSV files containing effect size data.\n",
    "    rownames: str\n",
    "        Column in CSV files containing row names.\n",
    "    nk_max: int\n",
    "        Maximum number of clusters to identify. Solutions will be obtained for nk = 2 to nk = nk_max.\n",
    "    metric: str\n",
    "        Distance metric used to compute the SNF affinity matrices.\n",
    "    K: int\n",
    "        Number of nearest-neighbours used to compute the SNF affinity matrices.\n",
    "    sigma: float\n",
    "        Variance for the local model in the SNF affinity matrices.\n",
    "    t: int\n",
    "        Number of iterations for the diffusion process in SNF.\n",
    "    outfile: str\n",
    "        Path to the CSV file in which to write the cluster assignments.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A Pandas DataFrame containing cluster assignments.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TO-DO\n",
    "    # - Make this function more general so that it can run SNF on any set of voxel matrices\n",
    "    #   rather than just the specific human effect sizes. \n",
    "    # - Option to run SNF on more than two matrices? \n",
    "    # Make it so that this function exits if an error happens in the R script\n",
    "    \n",
    "    \n",
    "    if type(infiles) is not list:\n",
    "        raise TypeError(\"Argument infiles must be a list.\")\n",
    "    \n",
    "    if len(infiles) != 2:\n",
    "        raise Exception(\"Argument infiles must have length 2.\")\n",
    "    \n",
    "    script = 'cluster_human_data.R'\n",
    "    script_args = {'file1':infiles[0],\n",
    "                   'file2':infiles[1],\n",
    "                   'rownames':rownames,\n",
    "                   'nclusters':nk_max,\n",
    "                   'metric':metric,\n",
    "                   'K':K,\n",
    "                   'sigma':sigma,\n",
    "                   't':t,\n",
    "                   'outfile':outfile}\n",
    "    \n",
    "    if rownames is None:\n",
    "        del script_args['rownames']\n",
    "    \n",
    "    execute_R(script = script, args = script_args)\n",
    "    \n",
    "    return pd.read_csv(outfile)\n",
    "\n",
    "\n",
    "def create_cluster_maps(clusters, imgdir, outdir, method = 'mean', verbose = True):\n",
    "\n",
    "    \"\"\"\n",
    "    Create representative voxel-wise maps for clustered images.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    clusters: str\n",
    "        Path to the CSV file containing cluster assignments.\n",
    "    imgdir: str\n",
    "        Path to the directory containing images to use.\n",
    "    outdir: str\n",
    "        Path to the output directory.\n",
    "    method: str\n",
    "        Method used to create the representative cluster maps.\n",
    "    verbose: bool\n",
    "        Verbosity option.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the cluster maps.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(clusters):\n",
    "        raise OSError(\"Cluster file not found: {}\".format(clusters))\n",
    "    verbose = 'true' if verbose else 'false'\n",
    "    script = 'create_cluster_maps.R'\n",
    "    script_args = {'clusterfile':clusters,\n",
    "                   'imgdir':imgdir,\n",
    "                   'outdir':outdir,\n",
    "                   'method':method,\n",
    "                   'verbose':verbose}\n",
    "    execute_R(script = script, args = script_args)\n",
    "    outfiles = glob(outdir+'*.mnc')\n",
    "    return outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86f0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_R(script, args):\n",
    "    \n",
    "    \"\"\"\n",
    "    Execute an R script.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    script: str\n",
    "        String containing the name of the R script to execute.\n",
    "    args: dict\n",
    "        Dictionary of key-value pairs containing command line arguments to pass to the script\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    args = [['--'+str(key), str(val)] for key, val in args.items()]\n",
    "    args = sum(args, [])\n",
    "    cmd = ['Rscript']+[script]+args\n",
    "    subprocess.run(cmd)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bdfe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_maps(clusters, imgdir, outdir, method = 'mean', verbose = True):\n",
    "\n",
    "    \"\"\"\n",
    "    Create representative voxel-wise maps for clustered images.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    clusters: str\n",
    "        Path to the CSV file containing cluster assignments.\n",
    "    imgdir: str\n",
    "        Path to the directory containing images to use.\n",
    "    outdir: str\n",
    "        Path to the output directory.\n",
    "    method: str\n",
    "        Method used to create the representative cluster maps.\n",
    "    verbose: bool\n",
    "        Verbosity option.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outfiles: list\n",
    "        List of paths to the cluster maps.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(clusters):\n",
    "        raise OSError(\"Cluster file not found: {}\".format(clusters))\n",
    "    verbose = 'true' if verbose else 'false'\n",
    "    script = 'create_cluster_maps.R'\n",
    "    script_args = {'clusterfile':clusters,\n",
    "                   'imgdir':imgdir,\n",
    "                   'outdir':outdir,\n",
    "                   'method':method,\n",
    "                   'verbose':verbose}\n",
    "    execute_R(script = script, args = script_args)\n",
    "    outfiles = glob(outdir+'*.mnc')\n",
    "    return outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8643b74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cluster file not found: test.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m outdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/human/clustering/cluster_maps/absolute/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcreate_cluster_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mimgdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimgdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [30], line 26\u001b[0m, in \u001b[0;36mcreate_cluster_maps\u001b[0;34m(clusters, imgdir, outdir, method, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mCreate representative voxel-wise maps for clustered images.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    List of paths to the cluster maps.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(clusters):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCluster file not found: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(clusters))\n\u001b[1;32m     27\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m script \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_cluster_maps.R\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: Cluster file not found: test.csv"
     ]
    }
   ],
   "source": [
    "# clusters = 'data/human/clustering/human_clusters_nk_10_metric_correlation_K_10_sigma_0.5_t_20_3.0mm.csv'\n",
    "clusters = 'test.csv'\n",
    "imgdir = 'data/human/effect_sizes/absolute/resolution_3.0_dataset_1_ncontrols_10_threshold_5/'\n",
    "outdir = 'data/human/clustering/cluster_maps/absolute/'\n",
    "method = 'mean'\n",
    "\n",
    "create_cluster_maps(clusters = clusters,\n",
    "                    imgdir = imgdir,\n",
    "                    outdir = outdir,\n",
    "                    method = 'mean',\n",
    "                    verbose = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

---
title: "Human cluster characteristics"
author: "Antoine Beauchamp"
date: '`r Sys.Date()`'
output: pdf_document
---

# Initialization

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(RMINC))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(ggbeeswarm))
```

```{r environment}
SRCPATH <- Sys.getenv("SRCPATH")
PROJECTPATH <- Sys.getenv("PROJECTPATH")
```

```{r functions}
source(file.path(SRCPATH, "utils.R"))
source(file.path(SRCPATH, "processing.R"))
```

```{r parameters}
# Output directory
output_dir <- "outputs/human_cluster_characteristics/"

# Human registration version
version <- "v3"

# Registration directory
registration_dir <- file.path(PROJECTPATH, "data/human/registration/")
registration_dir <- file.path(registration_dir, version)

# Pipeline directory
pipeline_dir <- file.path(PROJECTPATH, "data/human/derivatives/")
pipeline_dir <- file.path(pipeline_dir, version)

#Human parameters
dataset <- "POND-SickKids"
resolution <- 0.8
es_method <- "normative-growth"
es_df <- 3
centroid_method <- "mean"

metadata <- file.path(pipeline_dir, "metadata.csv")
params <- fetch_params_metadata(metadata = metadata,
                                dataset = dataset,
                                resolution = resolution,
                                es_method = es_method,
                                es_df = es_df)
params
```

```{r paths}
# Parameter set ID
params_id <- "700"

# Pipeline directory
pipeline_dir <- file.path(pipeline_dir, params_id)

# Cluster resolution
cluster_resolution <- params %>% 
  filter(id == params_id) %>% 
  pull(cluster_resolution)
cluster_resolution <- sprintf("%.1f", cluster_resolution)

# Max number of clusters
nk_max <- params %>% 
  filter(id == params_id) %>% 
  pull(cluster_nk_max)

# Cluster directory
cluster_dir <- file.path(pipeline_dir, "clusters", paste0("resolution_", cluster_resolution))

# Output directory
output_dir <- file.path(output_dir, version, params_id)
if (!(dir.exists(output_dir))) {dir.create(output_dir, recursive = TRUE)}
```

```{r import}
# Demogrpahics information
demographics <- file.path(registration_dir, "subject_info", "demographics.csv")
demographics <- read_csv(demographics, show_col_types = FALSE)

demographics <- demographics %>% 
  filter(!is.na(DX),
         !is.na(Age),
         !is.na(Sex),
         !is.na(Site),
         !is.na(Scanner))

# Clusters information
clusters <- file.path(cluster_dir, "clusters.csv")
clusters <- read_csv(clusters, show_col_types = FALSE)
```


# Total brain volume

```{r}
# Image resolution to use
res <- 3.0

# Add columns for Jacobian volumes
clusters_vol <- clusters %>% 
  mutate(volumes = 0)

# Mask file
mask <- file.path(registration_dir, "reference_files", "mask_3.0mm.mnc")

# Paths to Jacobians
jacobians <- c("absolute", "relative")
jacobians_dir <- file.path(registration_dir, "jacobians_resampled", "resolution_3.0", "absolute")

# Get Jacobian image files
imgfiles <- clusters_vol[["ID"]]
imgfiles <- file.path(jacobians_dir, imgfiles)

# Import absolute Jacobians
voxels <- import_images(imgfiles, mask = mask,
                        output_format = "matrix" , nproc = 8)

# Native values are on log scale. 
# Convert to linear scale and multiple by the voxel resolution
voxels <- (res^3)*exp(voxels)

# Sum voxel volumes to get TBV 
volumes <- rowSums(voxels)

# Convert to cm^3
clusters_vol[["volumes"]] <- volumes*(0.1^3)
```

```{r}
df_vol_kw <- tibble(nk = 2:nk_max, 
                    h = 0, p = 0)
for (i in 1:nrow(df_vol_kw)) {
  
  # Pull nk
  nk <- df_vol_kw[[i, "nk"]]
  
  # Get cluster labels and volumes
  labels <- factor(clusters_vol[[paste0("nk", nk)]])
  vols <- clusters_vol[["volumes"]]
  
  # Run KW test
  kw <- kruskal.test(x = vols, g = labels)
  df_vol_kw[[i, "h"]] <- kw[["statistic"]]
  df_vol_kw[[i, "p"]] <- kw[["p.value"]]
  
  p_tbv_i <- tibble(x = labels, y = vols) %>% 
    ggplot(aes(x = x, y = y)) + 
    geom_beeswarm(shape = 21, col = "grey50", fill = "grey80") + 
    geom_boxplot(alpha = 0.5, col = "black", outlier.shape = NA) +
    labs(x = "k",
         y = "Total brain volume (cm^3)",
         title = paste0("Total brain volume for ", nk, "-cluster solution"),
         subtitle = paste0("Kruskal-Wallis: p = ", formatC(kw[["p.value"]], format = "e", digits = 2))) +
    theme_bw() 
  
  outfile <- paste0("tbv_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(10, "inch"),
      height = unit(5, "inch"))
  print(p_tbv_i)
  dev.off()
  
}
```


# Diagnoses

```{r}
# Join demographics information to clusters
cluster_demographics <- clusters %>% 
  left_join(demographics, by = c("ID" = "file"))

# Create new coarse label DX
df_diagnoses <- tibble(DX = c("ASD", "OCD", "ADHD", "Sub-threshold OCD", "Anxiety", "Sub-threshold ADHD", "Intellectual Disability only", "Tourette Syndrome", "Other", "Fragile X"),
                       DX_new = c("ASD", "OCD", "ADHD", "OCD", "Other", "ADHD", "Other", "Other", "Other", "Other"))

# Join new DX categories to clusters
cluster_demographics <- cluster_demographics %>% 
  left_join(df_diagnoses, by = "DX")

# DX levels
dx_lvls <- c("ASD", "ADHD", "OCD", "Other")

df_dx_chi2 <- tibble(nk = 2:nk_max,
                     chi2 = 0, p = 0)
for (i in 1:nrow(df_dx_chi2)) {
  
  # Pull nk
  nk <- df_dx_chi2[[i, "nk"]]
  
  # Get cluster labels and volumes
  labels <- factor(cluster_demographics[[paste0("nk", nk)]])
  diagnoses <- factor(cluster_demographics[["DX_new"]], levels = dx_lvls)
  
  set.seed(1)
  chi2_dx <- chisq.test(x = labels, y = diagnoses,
                        simulate.p.value = TRUE, B = 1e5)  
  
  df_dx_chi2[[i, "chi2"]] <- chi2_dx[["statistic"]]
  df_dx_chi2[[i, "p"]] <- chi2_dx[["p.value"]]
  
  diagnoses_grid <- expand_grid(DX_new = df_diagnoses$DX_new,
                                k = 1:nk)
  
  df_prop_nk <- cluster_demographics %>% 
    select(k = paste0("nk", nk), DX_new) %>% 
    group_by(k) %>% 
    mutate(n_per_k = n()) %>% 
    group_by(k, DX_new) %>% 
    mutate(n_per_k_per_dx = n(),
           prop_per_k_per_dx = n_per_k_per_dx/n_per_k) %>% 
    ungroup() %>% 
    distinct() %>% 
    right_join(diagnoses_grid, by = c("k", "DX_new")) %>% 
    mutate(prop_per_k_per_dx = ifelse(is.na(prop_per_k_per_dx), 0, prop_per_k_per_dx),
           k = factor(k),
           DX_new = factor(DX_new, levels = dx_lvls))
  
  p_dx_nk <- ggplot(df_prop_nk, 
                    aes(x = k, y = prop_per_k_per_dx, fill = DX_new)) +
    geom_col(position = "dodge") +
    labs(x = "k",
         y = "Proportion per cluster",
         fill = "Diagnosis",
         title = paste0("Diagnostic proportions for ", nk, "-cluster solution"),
         subtitle = paste0("Chi-squared: p = ", round(chi2_dx$p.value, 4))) + 
    theme_bw() 
  
  outfile <- paste0("dx_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(10, "inch"),
      height = unit(5, "inch"))
  print(p_dx_nk) 
  dev.off()
  
}
```


## Fragile X

```{r eval = FALSE}
df_fxs <- cluster_demographics %>% 
  filter(DX == "Fragile X")

df_fxs
```

```{r eval = FALSE}
mouse_clusters <- "../../data/mouse/derivatives/v2/107/clusters/clusters.csv"
mouse_clusters <- read_csv(mouse_clusters, show_col_types = FALSE)
colnames(mouse_clusters) <- c("ID", str_c("nk", 2:10))

ind_fmr1 <- str_detect(mouse_clusters[["ID"]], "Fmr1")
mouse_clusters[ind_fmr1,]
```

Human FXS patient and mouse models are in matching clusters in nk = 2, 3, 4, 5. Then we have H6-1 to M6-6, which is not significant. After that the two mouse models aren't even in the same cluster. H7-1 and M7-5 have p = 0.09. No significant match at nk = 8, 9, or 10.


```{r}
# pond_genetics <- file.path(registration_dir, "subject_info", "POND_variants.xlsx")
# pond_genetics <- read_excel(pond_genetics)
# 
# fxs_id <- df_fxs[["Subject_ID"]] %>% 
#   str_remove("POND_")
# 
# pond_genetics %>% 
#   filter(POND_ID == fxs_id)
```

No identified variant for the FXS patient.


# Sex 

```{r}
df_sex_chi2 <- tibble(nk = 2:nk_max,
                      chi2 = 0, p = 0)
for (i in 1:nrow(df_sex_chi2)) {
  
  
  # Pull nk
  nk <- df_sex_chi2[[i, "nk"]]
  
  # Get cluster labels and volumes
  labels <- factor(cluster_demographics[[paste0("nk", nk)]])
  sex <- factor(cluster_demographics[["Sex"]])
  
  set.seed(1)
  chi2_sex <- chisq.test(x = labels, y = sex,
                         simulate.p.value = TRUE, B = 1e5)  
  
  df_sex_chi2[[i, "chi2"]] <- chi2_sex[["statistic"]]
  df_sex_chi2[[i, "p"]] <- chi2_sex[["p.value"]]
  
  sex_grid <- expand_grid(Sex = c("Female", "Male"),
                          k = 1:nk)
  
  df_prop_nk <- cluster_demographics %>% 
    select(k = paste0("nk", nk), Sex) %>% 
    group_by(k) %>% 
    mutate(n_per_k = n()) %>% 
    group_by(k, Sex) %>% 
    mutate(n_per_k_per_sex = n(),
           prop_per_k_per_sex = n_per_k_per_sex/n_per_k) %>% 
    ungroup() %>% 
    distinct() %>% 
    right_join(sex_grid, by = c("k", "Sex")) %>% 
    mutate(prop_per_k_per_sex = ifelse(is.na(prop_per_k_per_sex), 0, prop_per_k_per_sex),
           k = factor(k),
           Sex = factor(Sex))
  
  p_sex_nk <- ggplot(df_prop_nk, 
                     aes(x = k, y = prop_per_k_per_sex, fill = Sex)) +
    geom_col(position = "dodge") +
    labs(x = "k",
         y = "Proportion per cluster",
         fill = "Sex",
         title = paste0("Sex proportions for ", nk, "-cluster solution"),
         subtitle = paste0("Chi-squared: p = ", round(chi2_sex$p.value, 4))) + 
    theme_bw() 
  
  outfile <- paste0("sex_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile, 
      width = unit(10, "inch"),
      height = unit(5, "inch"))
  print(p_sex_nk) 
  dev.off()
  
}
```

# Age

```{r}
df_age_kw <- tibble(nk = 2:nk_max, 
                    h = 0, p = 0)
for (i in 1:nrow(df_age_kw)) {
  
  # Pull nk
  nk <- df_age_kw[[i, "nk"]]
  
  # Get cluster labels and volumes
  labels <- factor(cluster_demographics[[paste0("nk", nk)]])
  age <- cluster_demographics[["Age"]]
  
  # Run KW test
  kw <- kruskal.test(x = age, g = labels)
  df_age_kw[[i, "h"]] <- kw[["statistic"]]
  df_age_kw[[i, "p"]] <- kw[["p.value"]]
  
  p_age_i <- tibble(x = labels, y = age) %>% 
    ggplot(aes(x = x, y = y)) + 
    geom_beeswarm(shape = 21, col = "grey50", fill = "grey80") + 
    geom_boxplot(alpha = 0.5, col = "black", outlier.shape = NA) +
    labs(x = "k",
         y = "Age",
         title = paste0("Age for ", nk, "-cluster solution"),
         subtitle = paste0("Kruskal-Wallis: p = ", round(kw[["p.value"]], 4))) +
    theme_bw() 
  
  outfile <- paste0("age_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(10, "inch"),
      height = unit(5, "inch"))
  print(p_age_i)
  dev.off() 
  
}
```

# Datasets

```{r}
df_dataset_chi2 <- tibble(nk = 2:nk_max,
                          chi2 = 0, p = 0)
for (i in 1:nrow(df_dataset_chi2)) {
  
  # Pull nk
  nk <- df_dataset_chi2[[i, "nk"]]
  
  # Get cluster labels and volumes
  labels <- factor(cluster_demographics[[paste0("nk", nk)]])
  dataset <- factor(cluster_demographics[["Dataset"]])
  
  set.seed(1)
  chi2_dataset <- chisq.test(x = labels, y = dataset,
                             simulate.p.value = TRUE, B = 1e5)  
  
  df_dataset_chi2[[i, "chi2"]] <- chi2_dataset[["statistic"]]
  df_dataset_chi2[[i, "p"]] <- chi2_dataset[["p.value"]]
  
  dataset_grid <- expand_grid(Dataset = c("POND", "SickKids"),
                              k = 1:nk)
  
  df_prop_nk <- cluster_demographics %>% 
    select(k = paste0("nk", nk), Dataset) %>% 
    group_by(k) %>% 
    mutate(n_per_k = n()) %>% 
    group_by(k, Dataset) %>% 
    mutate(n_per_k_per_dataset = n(),
           prop_per_k_per_dataset = n_per_k_per_dataset/n_per_k) %>% 
    ungroup() %>% 
    distinct() %>% 
    right_join(dataset_grid, by = c("k", "Dataset")) %>% 
    mutate(prop_per_k_per_dataset = ifelse(is.na(prop_per_k_per_dataset), 0, prop_per_k_per_dataset),
           k = factor(k),
           Dataset = factor(Dataset))
  
  p_dataset_nk <- ggplot(df_prop_nk, 
                         aes(x = k, y = prop_per_k_per_dataset, fill = Dataset)) +
    geom_col(position = "dodge") +
    labs(x = "k",
         y = "Proportion per cluster",
         fill = "Dataset",
         title = paste0("Dataset proportions for ", nk, "-cluster solution"),
         subtitle = paste0("Chi-squared: p = ", round(chi2_dataset$p.value, 4))) + 
    theme_bw() 
  
  outfile <- paste0("dataset_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile, 
      width = unit(10, "inch"),
      height = unit(5, "inch")) 
  print(p_dataset_nk) 
  dev.off()
  
}
```

```{r}
df_demo_tests <- list(TBV = df_vol_kw, 
                      Diagnosis = df_dx_chi2,
                      Sex = df_sex_chi2,
                      Age = df_age_kw,
                      Dataset = df_dataset_chi2) %>% 
  map(.f = function(x){select(x,nk,p)}) %>% 
  bind_rows(.id = "variable") %>% 
  mutate(nk = factor(nk),
         variable = factor(variable),
         plog = -log10(p),
         plog = ifelse(plog > 5, 5, plog),
         significant = ifelse(p < 0.05, "*", ""))

p_demo_tests_pvals <- ggplot(df_demo_tests,
       aes(x = nk, y = variable, fill = plog)) + 
  geom_tile(col = "black") +
  geom_text(mapping = aes(label = significant)) + 
  scale_x_discrete(expand = expansion()) + 
  scale_y_discrete(expand = expansion()) + 
  scale_fill_gradientn(colours = brewer.pal(n = 9, name = "Reds")) +
  labs(x = "nk",
       y = NULL,
       fill = "-log10(p)",
       title = "Cluster demographics tests",
       caption = "Log p-values clamped to 5") +
  theme_bw() +
  theme(axis.title.y = element_blank())

# Export plot
outfile <- paste0("demographics_tests_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(4, "inch"))
print(p_demo_tests_pvals)
dev.off()
```


# Clinical scores for POND participants

```{r}
# Import POND clinical information
# pond_clinical <- "../../data/human/registration/v2/subject_info/POND_clinical_scores_20230915.csv"
pond_clinical <- "../../data/human/registration/v3/subject_info/POND/POND_clinical_scores_20230915.csv"
pond_clinical <- read_csv(pond_clinical, show_col_types = FALSE)
pond_clinical <- pond_clinical[,-1]

# Remove columns that aren't directly related to clinical scales
pond_clinical <- pond_clinical %>% 
  select(-contains("NSI"), 
         -contains("ETHNCTY"),
         -contains("EDUC"),
         -HSHLD_INCOME_STD,
         -PRMY_CGVR_STD)

# Examine remaining columns
colnames(pond_clinical)
```

What are these scales? 

- CB68IPTS: CBCL (6-18 years) internalizing problems T-score
- CB68EPTS: CBCL (6-18 years) externalizing problems T-score
- CBIPTS: CBCL (1.5-5 years) internalizing problems T-score
- CBEPTS: CBCL (1.5-5 years) externalizing problems T-score
- AB21GCCS: ABAS-II (5-21 years) GAC composite score
- BOT2_BLTC_SS: BOT 2 bilateral coordination - scale score
- BOT2_BAL_SS: BOT 2 balance - scale score
- BOT2_BDYC_STDS: BOT 2 body coordinate - standard score
- KKID_TOT: Kid-KINDL interview total quality of life score
- KKDO_TOT: Kiddo-KINDL interview total quality of life score
- KKDY_TOT: Kiddy-KINDL interview total quality of life score
- NEPSYII_A34_AR_SS: NEPSY-II (ages 3-4) AR scaled score
- NEPSYII_A34_TM_SS: NEPSY-II (ages 3-4) TM scaled score
- NEPSYII_A516_AR_SS: NEPSY-II (ages 5-16) AR scaled score
- NEPSYII_A516_MF_SS: NEPSY-II (ages 5-16) MF scaled score
- NEPSYII_A516_MFD_SS: NEPSY-II (ages 5-16) MFD scaled score
- NEPSYII_A516_MF_MFD_CCS: NEPSY-II (ages 5-16) MF vs. MFD contrast scaled score
- NEPSYII_A516_TM_SS: NEPSY-II (ages 5-16) TM scaled score
- NEPSYII-A716_AS_TCSSC: NEPSY-II (ages 5-16) AS total correct sorts scaled score
- NEPSYII-A718_AS_CSS: NEPSY-II (ages 5-16) AS combined scaled score
- OWLLCSS: OWLS LC standard score
- OWLOESS: OWLS OE standard score
- OWLOCSS: OWLS oral composite (OC) standard score
- OWL2LCSS: OWLS-II LC standard score (age only)
- OWL2OESS: OWLS-II OE standard score (age only)
- OWL2OLCSS: OWLS-II oral language composite (OLC) standard score
- RBSALLT: RBS-R overall score
- SCQTOT: SCQ Lifetime total score
- SSP_TACTILE_RS: Short Sensory Profile 1 tactile sensitivity raw score
- SSP_TASTE_SMELL_RS: Short Sensory Profile 1 taste/smell sensitivity raw score
- SSP_MOVEMENT_RS: Short Sensory Profile 1 movement sensitivity raw score
- SSP_UNDERRESP_SEEKS_RS: Short Sensory Profile 1 underresponsive/seek sensation raw score
- SSP_AUD_FILTER_RS: Short Sensory Profile 1 auditory filtering raw score
- SSP_LOW_ENRGY_WEAK_RS: Short Sensory Profile 1 low energy/weak raw score
- SSP_VIS_AUD_RS: Short Sensory Profile 1 visual/audio sensitivity raw score
- SSP_TOTAL_RS: Short Sensory Profile 1 total raw score
- S0B_TGT_ACCURACY: Spatial 0-back percentage target trials identified as such
- S0B_NONTGT_ACCURACY: Spatial 0-back percentage of non-target trials identified as such
- S1B_TFT_ACCURACY: Spatial 1-back percentage target trials identified as such
- S1B_NONTFT_ACCURACY: Spatial 1-back percentage of non-target trials identified as such
- S2B_TFT_ACCURACY: Spatial 2-back percentage target trials identified as such
- S2B_NONTFT_ACCURACY: Spatial 2-back percentage of non-target trials identified as such
- MT_ST_PCRT: STOP Task percent correct response total
- MT_ST_MCRTT: STOP Task mean correct response total
- MT_ST_CRTSDT: STOP Task standard deviation of total correct response times
- MT_ST_PSIT: STOP Task percent stopping inhibition of all trials
- MT_ST_SSRTT: STOP Task signal stop reaction time of all trials
- MT_ST_ITSSRT: STOP Task interpolated stop-signal response time
- MT_ST_PSRRT: STOP Task post signal-response RT mean
- ADHD_I_SUB: SWAN Rating Scale total number of items 1-9 with score of -2 or -3
- ADHD_HI_SUB: SWAN Rating Scale total number of items 10-18 with score of -2 or -3
- TPOCS_TOT: TOCS sum of items 1 to 21


```{r}
# Remove additional columns
# DX will be joined in later
pond_clinical <- pond_clinical %>% 
  select(-site, -SUB_ID, -DOB, 
         -PRIMARY_DIAGNOSIS, -RESEARCH_CONFIRM_DIAG,
         -SWANPDOC, -TPOCSPDOC) %>% 
  rename(Subject_ID = subject)

# Extract the set of clinical scales
clinical_scales <- pond_clinical %>% 
  select(-Subject_ID) %>% 
  colnames()

# Join demographics and clinical data to clusters data
clusters_clinical <- clusters %>%
  rename(file = ID) %>% 
  left_join(demographics, by = "file") %>% 
  mutate(Subject_ID = str_remove(Subject_ID, "sub-")) %>% 
  filter(Dataset == "POND") %>% 
  mutate(Subject_ID = as.numeric(Subject_ID)) %>% 
  left_join(pond_clinical, by = "Subject_ID")

# Convert cluster data to long format
clusters_long <- clusters %>% 
  pivot_longer(cols = -ID, names_to = "nk", values_to = "k") %>% 
  mutate(nk = str_remove(nk, "nk"),
         nk = as.numeric(nk),
         k = as.numeric(k)) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE)

# Number of participants per cluster
cluster_counts <- clusters_long %>% 
  group_by(cluster_id, nk, k) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(nk, k)
```

```{r}
# Number of patients with clinical data
npatients <- nrow(clusters_clinical)

# Calculate the completion rate for each of the scales
scales_completed <- clusters_clinical %>% 
  select(Subject_ID, all_of(clinical_scales)) %>% 
  pivot_longer(cols = -Subject_ID, 
               names_to = "scale",
               values_to = "score") %>% 
  mutate(missing = is.na(score)) %>% 
  group_by(scale) %>% 
  summarise(ncompleted = sum(!missing),
            pcompleted = ncompleted/npatients,
            .groups = "drop") 

# Proportions plot for scale completion rate.
p_scale_completion <- scales_completed %>% 
  select(-ncompleted) %>% 
  mutate(scale = factor(scale, levels = clinical_scales),
         pmissing = 1 - pcompleted) %>% 
  rename(completed = pcompleted,
         missing = pmissing) %>% 
  pivot_longer(cols = -scale, names_to = "status", values_to = "percent") %>% 
  mutate(status = factor(status, levels = c("missing", "completed"))) %>% 
  ggplot(aes(x = percent, y = fct_rev(scale),
             fill = status)) + 
  geom_col(width = 1,
           col = "grey50") + 
  geom_vline(xintercept = seq(0.2, 1.0, by = 0.2),
             linetype = "dashed",
             col = "red") + 
  scale_fill_manual(values = c("grey90", "green3"),
                    labels = c("Missing", "Completed")) +
  labs(x = "Percentage", y = "Scale", fill = NULL) +
  scale_x_continuous(breaks = seq(0, 1.0, by = 0.2),
                     expand = expansion(),
                     sec.axis = sec_axis(~.*npatients,
                                         name = "Number of patients",
                                         breaks = round(seq(0, 1.0, by = 0.2)*npatients))) + 
  theme_bw() +
  theme(axis.text.y = element_text(size = 7))

# Export plot
outfile <- "clinical_scale_completion.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_scale_completion)
dev.off()
```

```{r}
# Get the scales with the minimum completion rate
completion_threshold <- 120
clinical_scales_thresh <- scales_completed %>% 
  filter(ncompleted > completion_threshold) %>% 
  pull(scale)

# Subset the data set for those scales with suitable completion
clusters_clinical_thresh <- clusters_clinical %>% 
  select(Subject_ID, contains("nk"), all_of(clinical_scales_thresh))

# Some scales have values of 999. Set these to NA.
for (s in clinical_scales_thresh) {
  scores <- clusters_clinical_thresh[[s]]
  scores[scores == 999] <- NA
  clusters_clinical_thresh[[s]] <- scores
}

# Histograms of clinical scales
for (s in 1:length(clinical_scales_thresh)) {
  
  # Generate histogram for given scale
  p_scale_dist <- clusters_clinical_thresh %>% 
    select(x = clinical_scales_thresh[s]) %>% 
    filter(!is.na(x)) %>% 
    ggplot(aes(x = x)) + 
    geom_histogram() +
    labs(x = "Score",
         y = "Count",
         title = clinical_scales_thresh[s]) + 
    theme_bw()
  
  # Export plot
  outfile <- paste0("clinical_scores_dist_", clinical_scales_thresh[s], ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(8, "inch"),
      height = unit(4, "inch"))
  print(p_scale_dist)
  dev.off()
}
```

```{r}
# Examine 2-cluster distributions for all selected scales
nk <- 2
for (s in 1:length(clinical_scales_thresh)) {
  
  # Filter data for 2-cluster assignments and current scale
  df_plot <- clusters_clinical_thresh %>% 
    select(k = all_of(paste0("nk", nk)),
           scores = all_of(clinical_scales_thresh[s])) %>% 
    filter(!is.na(scores)) %>% 
    mutate(k = factor(k))
  
  # Compute scale score distribution summaries
  df_plot_summary <- df_plot %>% 
    group_by(k) %>% 
    summarise(scores_med = median(scores),
              scores_lwr = quantile(scores, probs = 0.25),
              scores_upr = quantile(scores, probs = 0.75))
  
  # Beeswarm plot with crossbars
  p_nk2_scales <- ggplot(df_plot, 
                         aes(x = k, y = scores)) + 
    geom_beeswarm(col = "grey50") + 
    geom_crossbar(data = df_plot_summary,
                  mapping = aes(y = scores_med, 
                                ymin = scores_lwr, 
                                ymax = scores_upr),
                  fill = "grey70",
                  alpha = 0.3) +
    labs(y = "Scores",
         title = clinical_scales_thresh[s]) + 
    theme_bw()
  
  # Export plot
  outfile <- paste0("clinical_scores_nk_2_", clinical_scales_thresh[s], ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(8, "inch"),
      height = unit(6, "inch"))
  print(p_nk2_scales)
  dev.off()
  
}
```

```{r}
# Compute Wilcoxon rank sum tests for all select scales 
# across 2-cluster solutions

# Initialize results data frame
df_wilcoxon <- tibble(nk = 2, 
                      scale = clinical_scales_thresh) %>% 
  mutate(uval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_wilcoxon)) {
  
  # Pull nk and scale acronym
  nk <- df_wilcoxon[[i, "nk"]]
  s <- df_wilcoxon[[i, "scale"]]
  
  # Get cluster labels and scale scores
  labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
  scores <- clusters_clinical_thresh[[s]]
  
  # Remove patients with missing scores
  missing <- is.na(scores)
  labels <- labels[!missing]
  scores <- scores[!missing]
  
  # Check that completed entries are not all in 
  # a single cluster. If they are, set NA. 
  # Otherwise, run Wilcoxon test.
  labels_count <- table(labels)
  test_ngroups <- length(labels_count) > 1
  if (test_ngroups) {
    wilcoxon <- wilcox.test(scores ~ factor(labels))
    df_wilcoxon[[i, "uval"]] <- wilcoxon[["statistic"]]
    df_wilcoxon[[i, "pval"]] <- wilcoxon[["p.value"]]
  } else {
    df_wilcoxon[[i, "uval"]] <- NA
    df_wilcoxon[[i, "pval"]] <- NA
  }
  df_wilcoxon[[i, "npatients"]] <- length(labels)
}

# Significance bins
sig_bins <- c("p >= 0.1",
              "0.05 <= p < 0.1",
              "0.01 <= p < 0.05",
              "p < 0.01")

# Convert p-values to log scale and create significance bins
df_wilcoxon_p <- df_wilcoxon %>% 
  mutate(pval_log = -log10(pval),
         scale = factor(scale, levels = clinical_scales_thresh),
         significance = case_when(pval >= 0.1 ~ sig_bins[1],
                                  pval >= 0.05 & pval < 0.1 ~ sig_bins[2],
                                  pval >= 0.01 & pval < 0.05 ~ sig_bins[3],
                                  pval < 0.01 ~ sig_bins[3]),
         significance = factor(significance, levels = sig_bins))

# p-value thresholds
pval_thresh <- c(0.1, 0.05, 0.01)
pval_thresh_log <- -log10(pval_thresh)

# Point and segment plot for significance
p_nk2_pvals <- ggplot(df_wilcoxon_p, 
                      aes(x = pval_log, y = scale, col = significance)) + 
  geom_segment(aes(xend = 0, yend = scale)) + 
  geom_point() +
  geom_vline(xintercept = pval_thresh_log,
             linetype = "dashed") +
  scale_color_manual(values = c("grey40", "red")) + 
  labs(x = "-log10(p)",
       y = "Clinical scale",
       color = "Significance",
       title = "2-cluster Wilcoxon rank sum tests") + 
  theme_bw()

# Export plot
outfile <- paste0("clinical_scores_nk_2_wilcoxon_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_nk2_pvals)
dev.off()
```


```{r}
# Compute Kruskal-Wallis tests for all select scales 
# across all cluster solutions

# Maximum number of cluster solutions
nk_max <- max(cluster_counts["nk"])

# Initialize results data frame
df_kw <- expand_grid(nk = 2:nk_max,
                     scale = clinical_scales_thresh) %>% 
  mutate(hval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_kw)) {
  
  # Pull nk and scale acronym
  nk <- df_kw[[i, "nk"]]
  s <- df_kw[[i, "scale"]]
  
  # Get cluster labels and scale scores
  labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
  scores <- clusters_clinical_thresh[[s]]
  
  # Remove patients with missing scores
  missing <- is.na(scores)
  labels <- labels[!missing]
  scores <- scores[!missing]
  
  # Check that completed entries are not all in 
  # a single cluster. If they are, set NA. 
  # Otherwise, run KW test.
  labels_count <- table(labels)
  test_ngroups <- length(labels_count) > 1
  if (test_ngroups) {
    kw <- kruskal.test(x = scores, g = factor(labels))
    df_kw[[i, "hval"]] <- kw[["statistic"]]
    df_kw[[i, "pval"]] <- kw[["p.value"]]
  } else {
    df_kw[[i, "hval"]] <- NA
    df_kw[[i, "pval"]] <- NA
  }
  df_kw[[i, "npatients"]] <- length(labels)
}

# Convert p-values to log scale and create significance indicator
df_kw_p <- df_kw %>% 
  mutate(nk = factor(nk),
         scale = factor(scale, levels = clinical_scales_thresh),
         pval_log = -log10(pval),
         significant = ifelse(pval < 0.05, "*", ""))

p_kw_pvals <- ggplot(df_kw_p,
                     aes(x = nk, y = scale, fill = pval_log)) + 
  geom_tile(col = "black") +
  geom_text(mapping = aes(label = significant)) + 
  scale_x_discrete(expand = expansion()) + 
  scale_y_discrete(expand = expansion()) + 
  scale_fill_gradientn(colours = brewer.pal(n = 9, name = "Reds")) +
  labs(x = "nk",
       y = "Clinical scale",
       fill = "-log10(p)",
       title = "Kruskal-Wallis tests") +
  theme_bw()

# Export plot
outfile <- paste0("clinical_scores_kruskalwallis_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_kw_pvals)
dev.off()
```


```{r}
# ANOVA code. Later replaced with KW above.

# for (i in 1:nrow(df_anova)) {
#   
#   nk <- df_anova[[i, "nk"]]
#   s <- df_anova[[i, "scale"]]
#   
#   labels <- clusters_clinical[[paste0("nk", nk)]]
#   scores <- clusters_clinical[[s]]
#   
#   missing <- is.na(scores)
#   labels <- labels[!missing]
#   scores <- scores[!missing]
#   
#   anova <- summary(aov(scores ~ factor(labels)))
#   df_anova[[i, "Fval"]] = anova[[1]][[1,"F value"]]
#   df_anova[[i, "pval"]] = anova[[1]][[1,"Pr(>F)"]]
#   df_anova[[i, "npatients"]] = length(labels)
#   
# }
# 
# 
# min_groupsize <- 50
# df_anova_large <- expand_grid(nk = 2:nk_max,
#                               scale = clinical_scales) %>% 
#   mutate(Fval = 0, pval = 0, npatients = 0)
# for (i in 1:nrow(df_anova_large)) {
# 
#     nk <- df_anova_large[[i, "nk"]]
#   s <- df_anova_large[[i, "scale"]]
#   
#   ind_nk <- cluster_counts[["nk"]] == nk
#   cluster_counts_nk <- cluster_counts[ind_nk,]
#   ind_groupsize <- cluster_counts_nk[["n"]] > min_groupsize
#   labels_pass <- cluster_counts_nk[ind_groupsize, "k"][[1]]
#   
#   labels <- clusters_clinical[[paste0("nk", nk)]]
#   scores <- clusters_clinical[[s]]
#   
#   missing <- is.na(scores)
#   labels <- labels[!missing]
#   scores <- scores[!missing]
#   
#   labels_filter <- labels %in% labels_pass
#   labels <- labels[labels_filter]
#   scores <- scores[labels_filter]
#   
#   anova <- summary(aov(scores ~ factor(labels)))
#   df_anova_large[[i, "Fval"]] = anova[[1]][[1,"F value"]]
#   df_anova_large[[i, "pval"]] = anova[[1]][[1,"Pr(>F)"]]
#   df_anova_large[[i, "npatients"]] = length(labels)
#   
# }
```
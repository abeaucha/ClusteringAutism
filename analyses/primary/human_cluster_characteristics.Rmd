---
title: "Human cluster characteristics"
author: "Antoine Beauchamp"
date: '`r Sys.Date()`'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(RMINC))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(ggbeeswarm))
```

```{r functions}
source("../../src/utils.R")
source("../../src/processing.R")
# source("../../src/analysis.R")
```


```{r parameters}
#Output directory
output_dir <- "outputs/human_cluster_characteristics/"

#Human directories
version <- "v3"

registration_dir <- "../../data/human/registration/"
registration_dir <- file.path(registration_dir, version)

pipeline_dir <- "../../data/human/derivatives/"
pipeline_dir <- file.path(pipeline_dir, version)

#Human parameters
resolution <- 0.8
es_method <- "normative-growth"
es_df <- 3
cluster_map_method <- "mean"

metadata <- file.path(pipeline_dir, "metadata.csv")
params <- fetch_params_metadata(metadata = metadata,
                                resolution = resolution,
                                es_method = es_method,
                                es_df = es_df)
params
```



```{r}
#Parameter set ID
params_id <- 700

#Pipeline directory
pipeline_dir <- file.path(pipeline_dir, params_id)

#Cluster resolution
cluster_resolution <- params %>% 
  filter(id == params_id) %>% 
  pull(cluster_resolution)
cluster_resolution <- sprintf("%.1f", cluster_resolution)

#Cluster directory
cluster_dir <- file.path(pipeline_dir, "clusters", paste0("resolution_", cluster_resolution))

#Output directory
output_dir <- file.path(output_dir, version, params_id)
if (!(dir.exists(output_dir))) {dir.create(output_dir, recursive = TRUE)}
```

```{r}
demographics <- file.path(registration_dir, "subject_info", "demographics.csv")
demographics <- read_csv(demographics, show_col_types = FALSE)
```

```{r}
clusters <- file.path(cluster_dir, "clusters.csv")
clusters <- read_csv(clusters, show_col_types = FALSE)
```

# 2-cluster total volume


```{r}
clusters_vol <- clusters %>% 
  mutate(absolute = 0,
         relative = 0)
```

```{r eval = FALSE}
# res <- params[["resolution"]]
res <- 3.0

# mask <- file.path(registration_dir, "reference_files", "mask_0.8mm.mnc")
mask <- file.path(registration_dir, "reference_files", "mask_3.0mm.mnc")

jacobians <- c("absolute", "relative")
jacobians_dir <- file.path(registration_dir, "jacobians_resampled", "resolution_3.0", jacobians)
names(jacobians_dir) <- jacobians

for (j in jacobians) {
  
  imgfiles <- clusters_vol[["ID"]]
  imgfiles <- file.path(jacobians_dir[[j]], imgfiles)
  voxels <- import_images(imgfiles, mask = mask, output_format = "matrix", 
                          inparallel = TRUE, nproc = 4)
  voxels <- (res^3)*exp(voxels)
  volumes <- rowSums(voxels)
  clusters_vol[[j]] <- volumes*(0.1^3)
}
```

```{r eval = FALSE}
p_cluster_vol <- ggplot(clusters_vol, aes(x = factor(nk2), y = absolute)) + 
  geom_jitter(col = "grey70") + 
  geom_boxplot(alpha = 0.5) + 
  labs(x = "Cluster ID", 
       y = "Total absolute volume (cm^3)",
       title = "Total brain volume comparison for human 2-cluster solution") + 
  theme_bw()

outfile <- "cluster_volumes_nk2.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(10, "in"),
    height = unit(10, "in"))
print(p_cluster_vol)
dev.off()
```

```{r eval = FALSE}
df_model <- clusters_vol %>% 
  select(cluster = nk2, volume = absolute) %>% 
  mutate(cluster = factor(cluster))

summary(lm(volume ~ cluster, data = df_model))
```

# Cluster diagnoses


```{r}
demographics <- demographics %>% 
  filter(!is.na(DX),
         !is.na(Age),
         !is.na(Sex),
         !is.na(Site),
         !is.na(Scanner))

cluster_demographics <- clusters %>% 
  left_join(demographics, by = c("ID" = "file"))

df_diagnoses <- tibble(DX = c("ASD", "OCD", "ADHD", "Sub-threshold OCD", "Anxiety", "Sub-threshold ADHD", "Intellectual Disability only", "Tourette Syndrome", "Other", "Fragile X"),
                       DX_new = c("ASD", "OCD", "ADHD", "OCD", "Other", "ADHD", "Other", "Other", "Other", "Other"))

cluster_demographics <- cluster_demographics %>% 
  left_join(df_diagnoses, by = "DX")
```


```{r}
dx_lvls <- c("ASD", "ADHD", "OCD", "Other")

nk_max <- 10
chi2_pvals <- numeric(nk_max-1)
for (nk in 2:nk_max) {
  
  df_tmp <- cluster_demographics %>% 
    select(k = paste0("nk", nk), DX_new) %>% 
    mutate(k = factor(k),
           DX_new = factor(DX_new, levels = dx_lvls))
  
  chi2 <- chisq.test(x = df_tmp$k, y = df_tmp$DX_new, simulate.p.value = TRUE, B = 1e5)
  
  diagnoses_grid <- expand_grid(DX_new = df_diagnoses$DX_new,
                                k = 1:nk)
  
  
  df_prop_nk <- cluster_demographics %>% 
    select(k = paste0("nk", nk), DX_new) %>% 
    group_by(k) %>% 
    mutate(n_per_k = n()) %>% 
    group_by(k, DX_new) %>% 
    mutate(n_per_k_per_dx = n(),
           prop_per_k_per_dx = n_per_k_per_dx/n_per_k) %>% 
    ungroup() %>% 
    distinct() %>% 
    right_join(diagnoses_grid, by = c("k", "DX_new")) %>% 
    mutate(prop_per_k_per_dx = ifelse(is.na(prop_per_k_per_dx), 0, prop_per_k_per_dx),
           k = factor(k),
           DX_new = factor(DX_new, levels = dx_lvls))
  
  p_dx_nk <- ggplot(df_prop_nk, 
                    aes(x = k, y = prop_per_k_per_dx, fill = DX_new)) +
    geom_col(position = "dodge") +
    labs(x = "k",
         y = "Proportion per cluster",
         fill = "Diagnosis",
         caption = paste("Chi-squared test p-value:", round(chi2$p.value, 4))) + 
    theme_bw() 
  
  outfile <- paste0("dx_proportions_nk_", nk, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(10, "inch"),
      height = unit(5, "inch"))
  print(p_dx_nk)
  dev.off()
  
  
}
```


## Fragile X

```{r}
df_fxs <- cluster_demographics %>% 
  filter(DX == "Fragile X")

df_fxs
```

```{r}
mouse_clusters <- "../../data/mouse/derivatives/v2/107/clusters/clusters.csv"
mouse_clusters <- read_csv(mouse_clusters, show_col_types = FALSE)
colnames(mouse_clusters) <- c("ID", str_c("nk", 2:10))

ind_fmr1 <- str_detect(mouse_clusters[["ID"]], "Fmr1")
mouse_clusters[ind_fmr1,]
```

Human FXS patient and mouse models are in matching clusters in nk = 2, 3, 4, 5. Then we have H6-1 to M6-6, which is not significant. After that the two mouse models aren't even in the same cluster. H7-1 and M7-5 have p = 0.09. No significant match at nk = 8, 9, or 10.


```{r}
# pond_genetics <- file.path(registration_dir, "subject_info", "POND_variants.xlsx")
# pond_genetics <- read_excel(pond_genetics)
# 
# fxs_id <- df_fxs[["Subject_ID"]] %>% 
#   str_remove("POND_")
# 
# pond_genetics %>% 
#   filter(POND_ID == fxs_id)
```

No identified variant for the FXS patient.


# POND clinical scores

```{r}
# Import POND clinical information
# pond_clinical <- "../../data/human/registration/v2/subject_info/POND_clinical_scores_20230915.csv"
pond_clinical <- "../../data/human/registration/v3/subject_info/POND/POND_clinical_scores_20230915.csv"
pond_clinical <- read_csv(pond_clinical, show_col_types = FALSE)
pond_clinical <- pond_clinical[,-1]

# Remove columns that aren't directly related to clinical scales
pond_clinical <- pond_clinical %>% 
  select(-contains("NSI"), 
         -contains("ETHNCTY"),
         -contains("EDUC"),
         -HSHLD_INCOME_STD,
         -PRMY_CGVR_STD)

# Examine remaining columns
colnames(pond_clinical)
```

What are these scales? 

- CB68IPTS: CBCL (6-18 years) internalizing problems T-score
- CB68EPTS: CBCL (6-18 years) externalizing problems T-score
- CBIPTS: CBCL (1.5-5 years) internalizing problems T-score
- CBEPTS: CBCL (1.5-5 years) externalizing problems T-score
- AB21GCCS: ABAS-II (5-21 years) GAC composite score
- BOT2_BLTC_SS: BOT 2 bilateral coordination - scale score
- BOT2_BAL_SS: BOT 2 balance - scale score
- BOT2_BDYC_STDS: BOT 2 body coordinate - standard score
- KKID_TOT: Kid-KINDL interview total quality of life score
- KKDO_TOT: Kiddo-KINDL interview total quality of life score
- KKDY_TOT: Kiddy-KINDL interview total quality of life score
- NEPSYII_A34_AR_SS: NEPSY-II (ages 3-4) AR scaled score
- NEPSYII_A34_TM_SS: NEPSY-II (ages 3-4) TM scaled score
- NEPSYII_A516_AR_SS: NEPSY-II (ages 5-16) AR scaled score
- NEPSYII_A516_MF_SS: NEPSY-II (ages 5-16) MF scaled score
- NEPSYII_A516_MFD_SS: NEPSY-II (ages 5-16) MFD scaled score
- NEPSYII_A516_MF_MFD_CCS: NEPSY-II (ages 5-16) MF vs. MFD contrast scaled score
- NEPSYII_A516_TM_SS: NEPSY-II (ages 5-16) TM scaled score
- NEPSYII-A716_AS_TCSSC: NEPSY-II (ages 5-16) AS total correct sorts scaled score
- NEPSYII-A718_AS_CSS: NEPSY-II (ages 5-16) AS combined scaled score
- OWLLCSS: OWLS LC standard score
- OWLOESS: OWLS OE standard score
- OWLOCSS: OWLS oral composite (OC) standard score
- OWL2LCSS: OWLS-II LC standard score (age only)
- OWL2OESS: OWLS-II OE standard score (age only)
- OWL2OLCSS: OWLS-II oral language composite (OLC) standard score
- RBSALLT: RBS-R overall score
- SCQTOT: SCQ Lifetime total score
- SSP_TACTILE_RS: Short Sensory Profile 1 tactile sensitivity raw score
- SSP_TASTE_SMELL_RS: Short Sensory Profile 1 taste/smell sensitivity raw score
- SSP_MOVEMENT_RS: Short Sensory Profile 1 movement sensitivity raw score
- SSP_UNDERRESP_SEEKS_RS: Short Sensory Profile 1 underresponsive/seek sensation raw score
- SSP_AUD_FILTER_RS: Short Sensory Profile 1 auditory filtering raw score
- SSP_LOW_ENRGY_WEAK_RS: Short Sensory Profile 1 low energy/weak raw score
- SSP_VIS_AUD_RS: Short Sensory Profile 1 visual/audio sensitivity raw score
- SSP_TOTAL_RS: Short Sensory Profile 1 total raw score
- S0B_TGT_ACCURACY: Spatial 0-back percentage target trials identified as such
- S0B_NONTGT_ACCURACY: Spatial 0-back percentage of non-target trials identified as such
- S1B_TFT_ACCURACY: Spatial 1-back percentage target trials identified as such
- S1B_NONTFT_ACCURACY: Spatial 1-back percentage of non-target trials identified as such
- S2B_TFT_ACCURACY: Spatial 2-back percentage target trials identified as such
- S2B_NONTFT_ACCURACY: Spatial 2-back percentage of non-target trials identified as such
- MT_ST_PCRT: STOP Task percent correct response total
- MT_ST_MCRTT: STOP Task mean correct response total
- MT_ST_CRTSDT: STOP Task standard deviation of total correct response times
- MT_ST_PSIT: STOP Task percent stopping inhibition of all trials
- MT_ST_SSRTT: STOP Task signal stop reaction time of all trials
- MT_ST_ITSSRT: STOP Task interpolated stop-signal response time
- MT_ST_PSRRT: STOP Task post signal-response RT mean
- ADHD_I_SUB: SWAN Rating Scale total number of items 1-9 with score of -2 or -3
- ADHD_HI_SUB: SWAN Rating Scale total number of items 10-18 with score of -2 or -3
- TPOCS_TOT: TOCS sum of items 1 to 21


```{r}
# Remove additional columns
# DX will be joined in later
pond_clinical <- pond_clinical %>% 
  select(-site, -SUB_ID, -DOB, 
         -PRIMARY_DIAGNOSIS, -RESEARCH_CONFIRM_DIAG,
         -SWANPDOC, -TPOCSPDOC) %>% 
  rename(Subject_ID = subject)

# Extract the set of clinical scales
clinical_scales <- pond_clinical %>% 
  select(-Subject_ID) %>% 
  colnames()

# Join demographics and clinical data to clusters data
clusters_clinical <- clusters %>%
  rename(file = ID) %>% 
  left_join(demographics, by = "file") %>% 
  mutate(Subject_ID = str_remove(Subject_ID, "sub-")) %>% 
  filter(Dataset == "POND") %>% 
  mutate(Subject_ID = as.numeric(Subject_ID)) %>% 
  left_join(pond_clinical, by = "Subject_ID")

# Convert cluster data to long format
clusters_long <- clusters %>% 
  pivot_longer(cols = -ID, names_to = "nk", values_to = "k") %>% 
  mutate(nk = str_remove(nk, "nk"),
         nk = as.numeric(nk),
         k = as.numeric(k)) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE)

# Number of participants per cluster
cluster_counts <- clusters_long %>% 
  group_by(cluster_id, nk, k) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(nk, k)
```

```{r}
# Number of patients with clinical data
npatients <- nrow(clusters_clinical)

# Calculate the completion rate for each of the scales
scales_completed <- clusters_clinical %>% 
  select(Subject_ID, all_of(clinical_scales)) %>% 
  pivot_longer(cols = -Subject_ID, 
               names_to = "scale",
               values_to = "score") %>% 
  mutate(missing = is.na(score)) %>% 
  group_by(scale) %>% 
  summarise(ncompleted = sum(!missing),
            pcompleted = ncompleted/npatients,
            .groups = "drop") 

# Proportions plot for scale completion rate.
p_scale_completion <- scales_completed %>% 
  select(-ncompleted) %>% 
  mutate(scale = factor(scale, levels = clinical_scales),
         pmissing = 1 - pcompleted) %>% 
  rename(completed = pcompleted,
         missing = pmissing) %>% 
  pivot_longer(cols = -scale, names_to = "status", values_to = "percent") %>% 
  mutate(status = factor(status, levels = c("missing", "completed"))) %>% 
  ggplot(aes(x = percent, y = fct_rev(scale),
                fill = status)) + 
  geom_col(width = 1,
           col = "grey50") + 
  geom_vline(xintercept = seq(0.2, 1.0, by = 0.2),
             linetype = "dashed",
             col = "red") + 
  scale_fill_manual(values = c("grey90", "green3"),
                    labels = c("Missing", "Completed")) +
  labs(x = "Percentage", y = "Scale", fill = NULL) +
  scale_x_continuous(breaks = seq(0, 1.0, by = 0.2),
                     expand = expansion(),
                     sec.axis = sec_axis(~.*npatients,
                                         name = "Number of patients",
                                         breaks = round(seq(0, 1.0, by = 0.2)*npatients))) + 
  theme_bw() +
  theme(axis.text.y = element_text(size = 7))

# Export plot
outfile <- "clinical_scale_completion.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_scale_completion)
dev.off()
```

```{r}
# Get the scales with the minimum completion rate
completion_threshold <- 120
clinical_scales_thresh <- scales_completed %>% 
  filter(ncompleted > completion_threshold) %>% 
  pull(scale)

# Subset the data set for those scales with suitable completion
clusters_clinical_thresh <- clusters_clinical %>% 
  select(Subject_ID, contains("nk"), all_of(clinical_scales_thresh))

# Some scales have values of 999. Set these to NA.
for (s in clinical_scales_thresh) {
  scores <- clusters_clinical_thresh[[s]]
  scores[scores == 999] <- NA
  clusters_clinical_thresh[[s]] <- scores
}

# Histograms of clinical scales
for (s in 1:length(clinical_scales_thresh)) {
  
  # Generate histogram for given scale
  p_scale_dist <- clusters_clinical_thresh %>% 
    select(x = clinical_scales_thresh[s]) %>% 
    filter(!is.na(x)) %>% 
    ggplot(aes(x = x)) + 
    geom_histogram() +
    labs(x = "Score",
         y = "Count",
         title = clinical_scales_thresh[s]) + 
    theme_bw()
  
  # Export plot
  outfile <- paste0("clinical_scores_dist_", clinical_scales_thresh[s], ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(8, "inch"),
      height = unit(4, "inch"))
  print(p_scale_dist)
  dev.off()
}
```

```{r}
# Examine 2-cluster distributions for all selected scales
nk <- 2
for (s in 1:length(clinical_scales_thresh)) {
  
  # Filter data for 2-cluster assignments and current scale
  df_plot <- clusters_clinical_thresh %>% 
    select(k = all_of(paste0("nk", nk)),
           scores = all_of(clinical_scales_thresh[s])) %>% 
    filter(!is.na(scores)) %>% 
    mutate(k = factor(k))
  
  # Compute scale score distribution summaries
  df_plot_summary <- df_plot %>% 
    group_by(k) %>% 
    summarise(scores_med = median(scores),
              scores_lwr = quantile(scores, probs = 0.25),
              scores_upr = quantile(scores, probs = 0.75))
  
  # Beeswarm plot with crossbars
  p_nk2_scales <- ggplot(df_plot, 
         aes(x = k, y = scores)) + 
    geom_beeswarm(col = "grey50") + 
    geom_crossbar(data = df_plot_summary,
                  mapping = aes(y = scores_med, 
                                ymin = scores_lwr, 
                                ymax = scores_upr),
                  fill = "grey70",
                  alpha = 0.3) +
      labs(y = "Scores",
           title = clinical_scales_thresh[s]) + 
      theme_bw()
    
    # Export plot
    outfile <- paste0("clinical_scores_nk_2_", clinical_scales_thresh[s], ".pdf")
    outfile <- file.path(output_dir, outfile)
    pdf(file = outfile,
        width = unit(8, "inch"),
        height = unit(6, "inch"))
    print(p_nk2_scales)
    dev.off()
  
}
```

```{r}
# Compute Wilcoxon rank sum tests for all select scales 
# across 2-cluster solutions

# Initialize results data frame
df_wilcoxon <- tibble(nk = 2, 
                      scale = clinical_scales_thresh) %>% 
  mutate(uval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_wilcoxon)) {
 
    # Pull nk and scale acronym
    nk <- df_wilcoxon[[i, "nk"]]
    s <- df_wilcoxon[[i, "scale"]]
  
    # Get cluster labels and scale scores
    labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
    scores <- clusters_clinical_thresh[[s]]
    
    # Remove patients with missing scores
    missing <- is.na(scores)
    labels <- labels[!missing]
    scores <- scores[!missing]
    
    # Check that completed entries are not all in 
    # a single cluster. If they are, set NA. 
    # Otherwise, run Wilcoxon test.
    labels_count <- table(labels)
    test_ngroups <- length(labels_count) > 1
    if (test_ngroups) {
      wilcoxon <- wilcox.test(scores ~ factor(labels))
      df_wilcoxon[[i, "uval"]] <- wilcoxon[["statistic"]]
      df_wilcoxon[[i, "pval"]] <- wilcoxon[["p.value"]]
    } else {
      df_wilcoxon[[i, "uval"]] <- NA
      df_wilcoxon[[i, "pval"]] <- NA
    }
    df_wilcoxon[[i, "npatients"]] <- length(labels)
}

# Significance bins
sig_bins <- c("p >= 0.1",
              "0.05 <= p < 0.1",
              "0.01 <= p < 0.05",
              "p < 0.01")

# Convert p-values to log scale and create significance bins
df_wilcoxon_p <- df_wilcoxon %>% 
  mutate(pval_log = -log10(pval),
         scale = factor(scale, levels = clinical_scales_thresh),
         significance = case_when(pval >= 0.1 ~ sig_bins[1],
                                  pval >= 0.05 & pval < 0.1 ~ sig_bins[2],
                                  pval >= 0.01 & pval < 0.05 ~ sig_bins[3],
                                  pval < 0.01 ~ sig_bins[3]),
         significance = factor(significance, levels = sig_bins))

# p-value thresholds
pval_thresh <- c(0.1, 0.05, 0.01)
pval_thresh_log <- -log10(pval_thresh)

# Point and segment plot for significance
p_nk2_pvals <- ggplot(df_wilcoxon_p, 
       aes(x = pval_log, y = scale, col = significance)) + 
  geom_segment(aes(xend = 0, yend = scale)) + 
  geom_point() +
  geom_vline(xintercept = pval_thresh_log,
             linetype = "dashed") +
  scale_color_manual(values = c("grey40", "red")) + 
  labs(x = "-log10(p)",
       y = "Clinical scale",
       color = "Significance",
       title = "2-cluster Wilcoxon rank sum tests") + 
  theme_bw()

# Export plot
outfile <- paste0("clinical_scores_nk_2_wilcoxon_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_nk2_pvals)
dev.off()
```


```{r}
# Compute Kruskal-Wallis tests for all select scales 
# across all cluster solutions

# Maximum number of cluster solutions
nk_max <- max(cluster_counts["nk"])

# Initialize results data frame
df_kw <- expand_grid(nk = 2:nk_max,
                     scale = clinical_scales_thresh) %>% 
  mutate(hval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_kw)) {
  
  # Pull nk and scale acronym
  nk <- df_kw[[i, "nk"]]
  s <- df_kw[[i, "scale"]]
  
  # Get cluster labels and scale scores
  labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
  scores <- clusters_clinical_thresh[[s]]
  
  # Remove patients with missing scores
  missing <- is.na(scores)
  labels <- labels[!missing]
  scores <- scores[!missing]
  
  # Check that completed entries are not all in 
  # a single cluster. If they are, set NA. 
  # Otherwise, run KW test.
  labels_count <- table(labels)
  test_ngroups <- length(labels_count) > 1
  if (test_ngroups) {
    kw <- kruskal.test(x = scores, g = factor(labels))
    df_kw[[i, "hval"]] <- kw[["statistic"]]
    df_kw[[i, "pval"]] <- kw[["p.value"]]
  } else {
    df_kw[[i, "hval"]] <- NA
    df_kw[[i, "pval"]] <- NA
  }
  df_kw[[i, "npatients"]] <- length(labels)
}

# Convert p-values to log scale and create significance indicator
df_kw_p <- df_kw %>% 
  mutate(nk = factor(nk),
         scale = factor(scale, levels = clinical_scales_thresh),
         pval_log = -log10(pval),
         significant = ifelse(pval < 0.05, "*", ""))

p_kw_pvals <- ggplot(df_kw_p,
       aes(x = nk, y = scale, fill = pval_log)) + 
  geom_tile(col = "black") +
  geom_text(mapping = aes(label = significant)) + 
  scale_x_discrete(expand = expansion()) + 
  scale_y_discrete(expand = expansion()) + 
  scale_fill_gradientn(colours = brewer.pal(n = 9, name = "Reds")) +
  labs(x = "nk",
       y = "Clinical scale",
       fill = "-log10(p)",
       title = "Kruskal-Wallis tests") +
  theme_bw()

# Export plot
outfile <- paste0("clinical_scores_kruskalwallis_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_kw_pvals)
dev.off()
```


```{r}
# ANOVA code. Later replaced with KW above.

# for (i in 1:nrow(df_anova)) {
#   
#   nk <- df_anova[[i, "nk"]]
#   s <- df_anova[[i, "scale"]]
#   
#   labels <- clusters_clinical[[paste0("nk", nk)]]
#   scores <- clusters_clinical[[s]]
#   
#   missing <- is.na(scores)
#   labels <- labels[!missing]
#   scores <- scores[!missing]
#   
#   anova <- summary(aov(scores ~ factor(labels)))
#   df_anova[[i, "Fval"]] = anova[[1]][[1,"F value"]]
#   df_anova[[i, "pval"]] = anova[[1]][[1,"Pr(>F)"]]
#   df_anova[[i, "npatients"]] = length(labels)
#   
# }
# 
# 
# min_groupsize <- 50
# df_anova_large <- expand_grid(nk = 2:nk_max,
#                               scale = clinical_scales) %>% 
#   mutate(Fval = 0, pval = 0, npatients = 0)
# for (i in 1:nrow(df_anova_large)) {
# 
#     nk <- df_anova_large[[i, "nk"]]
#   s <- df_anova_large[[i, "scale"]]
#   
#   ind_nk <- cluster_counts[["nk"]] == nk
#   cluster_counts_nk <- cluster_counts[ind_nk,]
#   ind_groupsize <- cluster_counts_nk[["n"]] > min_groupsize
#   labels_pass <- cluster_counts_nk[ind_groupsize, "k"][[1]]
#   
#   labels <- clusters_clinical[[paste0("nk", nk)]]
#   scores <- clusters_clinical[[s]]
#   
#   missing <- is.na(scores)
#   labels <- labels[!missing]
#   scores <- scores[!missing]
#   
#   labels_filter <- labels %in% labels_pass
#   labels <- labels[labels_filter]
#   scores <- scores[labels_filter]
#   
#   anova <- summary(aov(scores ~ factor(labels)))
#   df_anova_large[[i, "Fval"]] = anova[[1]][[1,"F value"]]
#   df_anova_large[[i, "pval"]] = anova[[1]][[1,"Pr(>F)"]]
#   df_anova_large[[i, "npatients"]] = length(labels)
#   
# }
```
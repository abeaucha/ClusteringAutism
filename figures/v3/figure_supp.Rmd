---
title: "Supplementary Figures"
subtitle: "Clustering Autism"
author: "Antoine Beauchamp"
date: "2024-08-27"
output: html_document
---

# Initialization

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r packages}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggnewscale))
suppressPackageStartupMessages(library(grid))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(RMINC))
suppressPackageStartupMessages(library(MRIcrotome))
suppressPackageStartupMessages(library(SNFtool))
suppressPackageStartupMessages(library(cluster))
suppressPackageStartupMessages(library(ggalluvial))
suppressPackageStartupMessages(library(patchwork))
suppressPackageStartupMessages(library(RColorBrewer))

suppressPackageStartupMessages(library(rcartocolor))
suppressPackageStartupMessages(library(pheatmap))
```

```{r environment}
SRCPATH <- Sys.getenv("SRCPATH")
PROJECTPATH <- Sys.getenv("PROJECTPATH")

if (PROJECTPATH == "") {
  PROJECTPATH <- "/projects/abeauchamp/Projects/MouseHumanMapping/Paper_ClusteringAutism/main"
  Sys.setenv(PROJECTPATH = PROJECTPATH)
}

if (SRCPATH == "") {
  SRCPATH <- "/projects/abeauchamp/Projects/MouseHumanMapping/Paper_ClusteringAutism/main/src"
  Sys.setenv(SRCPATH = SRCPATH)
}
```

```{r functions}
source(file.path(SRCPATH, "utils.R"))
source(file.path(SRCPATH, "processing.R"))
source(file.path(SRCPATH, "analysis.R"))

#Function to estimate cluster metrics over a range of solutions
estimate_cluster_metrics <- function (W, NUMC = 2:5){
  if (min(NUMC) == 1) {
    warning("Note that we always assume there are more than one cluster.")
    NUMC <- NUMC[NUMC > 1]
  }
  W <- (W + t(W))/2
  diag(W) <- 0
  if (length(NUMC) <= 0) {
    warning(paste("Invalid NUMC provided, must be an integer vector", 
                  "with atleast one other number than 1.", "Using default NUMC=c(2,3,4,5)", 
                  sep = ""))
    NUMC <- 2:5
  }
  degs <- rowSums(W)
  degs[degs == 0] <- .Machine$double.eps
  D <- diag(degs)
  L <- D - W
  Di <- diag(1/sqrt(degs))
  L <- Di %*% L %*% Di
  eigs <- eigen(L)
  eigs_order <- sort(eigs$values, index.return = T)$ix
  eigs$values <- eigs$values[eigs_order]
  eigs$vectors <- eigs$vectors[, eigs_order]
  eigengap <- abs(diff(eigs$values))
  quality <- list()
  for (c_index in 1:length(NUMC)) {
    ck <- NUMC[c_index]
    UU <- eigs$vectors[, 1:ck]
    EigenvectorsDiscrete <- SNFtool:::.discretisation(UU)[[1]]
    EigenVectors <- EigenvectorsDiscrete^2
    temp1 <- EigenVectors[do.call(order, lapply(1:ncol(EigenVectors), 
                                                function(i) EigenVectors[, i])), ]
    temp1 <- t(apply(temp1, 1, sort, TRUE))
    quality[[c_index]] <- (1 - eigs$values[ck + 1])/(1 - 
                                                       eigs$values[ck]) * sum(sum(diag(1/(temp1[, 1] + .Machine$double.eps)) %*% 
                                                                                    temp1[, 1:max(2, ck - 1)]))
  }
  
  out <- tibble(nk = NUMC,
                eigengap = eigengap[NUMC],
                rotation = unlist(quality))
  
  return(out)
}
```

```{r params}
#Output directory
output_dir <- "figure_supplementary"
if (!(dir.exists(output_dir))) {dir.create(output_dir, recursive = TRUE)}

# Plot file prefix
output_plot_prefix <- "figure_supp"

# Similarity pipeline
version <- "v3"
pipeline_dir <- file.path(PROJECTPATH, "/data/cross_species/")
pipeline_dir <- file.path(pipeline_dir, version)

# Fetch parameter set
metadata <- file.path(pipeline_dir, "metadata.csv")
params <- fetch_params_metadata(metadata = metadata,
                                id = 375)
params
```


```{r paths}
# Parameter set ID
params_id <- 375

# Update pipeline directory with parameter set ID
pipeline_dir <- file.path(pipeline_dir, params_id)

# Jacobians
jacobians <- c("absolute", "relative")

# Human parameter set ID
human_params_id <- params %>% 
  filter(id == params_id) %>% 
  pull(input_1_id)

# Mouse parameter set ID
mouse_params_id <- params %>% 
  filter(id == params_id) %>% 
  pull(input_2_id)

# Max number of clusters
nk_max <- 10

# Human pipeline directory
human_pipeline_dir <- file.path(PROJECTPATH, "/data/human/derivatives/")
human_pipeline_dir <- file.path(human_pipeline_dir, version, human_params_id)

# Human cluster directory
human_cluster_dir <- file.path(human_pipeline_dir, "clusters")
human_cluster_resolution <- 3.0
human_cluster_resolution <- sprintf("%.1f", human_cluster_resolution)
human_cluster_dir <- file.path(human_cluster_dir, str_c("resolution_", human_cluster_resolution))

# Human cluster map directories
human_resolution <- 0.8
human_centroid_dirs <- file.path(human_pipeline_dir, "centroids")
human_centroid_dirs <- file.path(human_centroid_dirs, str_c("resolution_", human_resolution))
human_centroid_dirs <- file.path(human_centroid_dirs, jacobians)
names(human_centroid_dirs) <- jacobians

# Mouse pipeline directory
mouse_pipeline_dir <- file.path(PROJECTPATH, "data/mouse/derivatives/")
mouse_pipeline_dir <- file.path(mouse_pipeline_dir, version, mouse_params_id)

# Mouse cluster directory
mouse_cluster_dir <- file.path(mouse_pipeline_dir, "clusters", "resolution_0.2")

# Mouse cluster map directories
mouse_resolution <- 0.2
mouse_centroid_dirs <- file.path(mouse_pipeline_dir, "centroids")
mouse_centroid_dirs <- file.path(mouse_centroid_dirs, str_c("resolution_", mouse_resolution))
mouse_centroid_dirs <- file.path(mouse_centroid_dirs, jacobians)
names(mouse_centroid_dirs) <- jacobians

# Mouse cluster map directories at 50um
mouse_centroid_dirs_50um <- file.path(mouse_pipeline_dir, "centroids")
mouse_centroid_dirs_50um <- file.path(mouse_centroid_dirs_50um, "resolution_0.05")
mouse_centroid_dirs_50um <- file.path(mouse_centroid_dirs_50um, jacobians)
names(mouse_centroid_dirs_50um) <- jacobians
```

```{r graphical-params}
# Number of bigpts in an inch
pt_per_in <- 72

# Font family
font_family <- "Helvetica"

# Nature suggested font size: 5-7 pt
font_size <- 6

# Empty rectangle grob
empty_rect_grob <- rectGrob(gp = gpar(fill = NA))

# Maximal figure dimensions in bigpts
fig_width_pt <- 510
fig_height_pt <- 481
```


# Supplementary Figure 1: Human Sankey diagram

# Supplementary Figure 2: Mouse Sankey diagram

# Supplementary Figure 3: Eigengap distributions

```{r fig-supp-3 }
# Human cluster assignments
human_cluster_file <- file.path(human_cluster_dir, "clusters.csv")
df_human_clusters <- read_csv(human_cluster_file, show_col_types = FALSE)

hbn_cluster_file <- file.path(PROJECTPATH, "/data/human/derivatives/v3/013/clusters/resolution_3.0/clusters.csv")
df_hbn_clusters <- read_csv(hbn_cluster_file, show_col_types = FALSE)

# Mouse cluster assignments
mouse_cluster_file <- file.path(mouse_cluster_dir, "clusters.csv")
df_mouse_clusters <- read_csv(mouse_cluster_file, show_col_types = FALSE)
colnames(df_mouse_clusters) <- c("ID", str_c("nk", 2:10))

# Human affinity matrix
human_affinity_file <- file.path(human_cluster_dir, "affinity.csv")
df_human_affinity <- read_csv(human_affinity_file, show_col_types = FALSE)
mat_human_affinity <- as.matrix(df_human_affinity)
rownames(mat_human_affinity) <- colnames(mat_human_affinity)

hbn_affinity_file <- file.path(PROJECTPATH, "/data/human/derivatives/v3/013/clusters/resolution_3.0/affinity.csv")
df_hbn_affinity <- read_csv(hbn_affinity_file, show_col_types = FALSE)
mat_hbn_affinity <- as.matrix(df_hbn_affinity)
rownames(mat_hbn_affinity) <- colnames(mat_hbn_affinity)

# Mouse affinity matrix
mouse_affinity_file <- file.path(mouse_cluster_dir, "affinity.RData")
load(mouse_affinity_file)
mat_mouse_affinity <- W
df_mouse_affinity <- as_tibble(mat_mouse_affinity)

# Max nk to examine
eigengap_nk_max <- 20

# Get human cluster metrics
df_human_cluster_metrics <- estimate_cluster_metrics(W = mat_human_affinity, NUMC = 2:eigengap_nk_max)
df_hbn_cluster_metrics <- estimate_cluster_metrics(W = mat_hbn_affinity, NUMC = 2:eigengap_nk_max)
df_mouse_cluster_metrics <- estimate_cluster_metrics(W = mat_mouse_affinity, NUMC = 2:eigengap_nk_max)

df_cluster_metrics <- bind_rows(
  df_human_cluster_metrics %>% 
    mutate(species = "POND + Taylor"),
  df_hbn_cluster_metrics %>% 
    mutate(species = "HBN"),
  df_mouse_cluster_metrics %>% 
    mutate(species = "MICe")
)

df_cluster_metrics <- df_cluster_metrics %>% 
  mutate(species = factor(species, levels = c("POND + Taylor", "HBN", "MICe")))

# Plot of eigengap distributions
fig_supp_3 <- ggplot(df_cluster_metrics,
                     aes(x = nk, y = eigengap, col = species)) + 
  geom_line(size = 0.4) + 
  geom_point(size = 1) +
  coord_cartesian(xlim = c(2, eigengap_nk_max),
                  ylim = c(0, 0.1)) + 
  scale_x_continuous(breaks = seq(0, eigengap_nk_max, by = 1)) +
  scale_y_continuous(breaks = seq(0, 0.1, by = 0.01)) + 
  labs(x = "Number of clusters (K)",
       y = "Eigengap",
       col = "Dataset") +
  theme_bw() + 
  theme(axis.title = element_text(size = font_size+1,
                                  family = font_family),
        axis.text = element_text(size = font_size,
                                 family = font_family),
        legend.title = element_text(size = font_size+1,
                                    family = font_family),
        legend.text = element_text(size = font_size,
                                   family = font_family),
        panel.grid.minor.x = element_blank())

# Figure dimensions
fig_supp_3_width_pt <- fig_width_pt
fig_supp_3_height_pt <- fig_width_pt/3

# Export
outfile <- paste(output_plot_prefix, 3, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
export_pdf(x = ggplotGrob(fig_supp_3),
           width = fig_supp_3_width_pt,
           height = fig_supp_3_height_pt,
           units = "bigpts",
           file = outfile)
```


# Supplementary Figure 4: Human 2-cluster centroid slice series

```{r fig-supp-4-files}
# Human anatomy
human_anat_file <- file.path(PROJECTPATH, "data/human/registration/v3/reference_files/model_0.8mm.mnc")
human_anat <- mincGetVolume(human_anat_file)
human_anat_vol <- mincArray(human_anat)

# Cropped human images along sagittal and transverse planes
human_slices_dim_1 <- 27:220
human_slices_dim_2 <- 10:280
human_slices_dim_3 <- 10:220
human_anat_vol_cropped <- human_anat_vol[human_slices_dim_1,,human_slices_dim_3]

# Human mask
human_mask_file <- file.path(PROJECTPATH, "data/human/registration/v3/reference_files/mask_0.8mm.mnc")
human_mask <- mincGetVolume(human_mask_file)

# Image threshold method
threshold <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold)

# Image threshold value
threshold_value <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold_value)

# Image threshold symmetric option
threshold_symmetric <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold_symmetric)

# Cluster solutions to visualize
nk_human <- 2
```

```{r fig-supp-4-import}
# Iterate over jacobians  
list_human_centroids <- vector(mode = "list", length = length(jacobians))
names(list_human_centroids) <- jacobians
for (j in jacobians) {
  
  # Iterate over clusters in nk solution
  list_human_centroids[[j]] <- vector(mode = "list", length = nk_human)
  names(list_human_centroids[[j]]) <- paste(nk_human, 1:nk_human, sep = "-")
  for (k in 1:nk_human) {
    
    # Import centroid image for specific cluster using threshold
    img_human <- import_cluster_map(imgdir = human_centroid_dirs[[j]],
                                    mask = human_mask_file,
                                    nk = nk_human, k = k,
                                    threshold = threshold,
                                    threshold_value = threshold_value,
                                    threshold_symmetric = threshold_symmetric)
    
    # Crop image to remove black space
    img_human <- mincArray(img_human)
    img_human <- img_human[human_slices_dim_1,,human_slices_dim_3]
    list_human_centroids[[j]][[k]] <- img_human
    
  }
}
```

```{r fig-supp-4-ss}
# Number of slices per ss
ss_nslices <- 8

# Human slices
human_slices <- floor(seq(60, 220, length.out = ss_nslices))

# Human anatomy thresholds
human_anat_low <- 40
human_anat_high <- 110

# Overlay thresholds from previous code chunk
overlay_low <- 0.2
overlay_high <- 0.7

# Iterate over clusters
for (k in 1:nk_human) {
  
  # Generate slice series grob
  fig_supp_4_grob <- sliceSeries(nrow = ss_nslices, ncol = 1, begin = 60, end = 220) %>% 
    anatomy(human_anat_vol_cropped, low = human_anat_low, high = human_anat_high) %>% 
    overlay(list_human_centroids[["absolute"]][[k]], low = overlay_low, high = overlay_high, symmetric = TRUE) %>% 
    sliceSeries() %>% anatomy() %>% 
    overlay(list_human_centroids[["relative"]][[k]], low = overlay_low, high = overlay_high, symmetric = TRUE) %>%   
    legend() %>% 
    grobify()
  
  # Dimensions
  fig_supp_4_width_pt <- fig_width_pt/(3)
  fig_supp_4_height_pt <- (fig_supp_4_width_pt/3)*ss_nslices
  
  # Export slice series
  outfile <- paste(output_plot_prefix, 4, nk_human, k, sep = "_")
  outfile <- paste0(outfile, ".pdf")
  outfile <- file.path(output_dir, outfile)
  export_pdf(x = fig_supp_4_grob,
             file = outfile,
             width = fig_supp_4_width_pt,
             height = fig_supp_4_height_pt,
             units = "bigpts")
  
}
```


# Supplementary Figure 5: Mouse 4-cluster centroid slice series

```{r fig-supp-5-files}
# Mouse anatomy
mouse_anat_file <- file.path(PROJECTPATH, "data/mouse/atlas/DSURQE_CCFv3_average_50um.mnc")
mouse_anat <- mincGetVolume(mouse_anat_file)
mouse_anat_vol <- mincArray(mouse_anat)

# Mouse mask
mouse_mask_file <- file.path(PROJECTPATH, "data/mouse/atlas/coronal_50um_coverage_bin0.8.mnc")
mouse_mask <- mincGetVolume(mouse_mask_file)

# Image threshold method
threshold <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold)

# Image threshold value
threshold_value <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold_value)

# Image threshold symmetric option
threshold_symmetric <- params %>% 
  filter(id == params_id) %>% 
  pull(threshold_symmetric)

# Cluster solutions to visualize
nk_mouse <- 4
```

```{r fig-supp-5-resample}
# Mouse images need to be resampled to 50um
run <- FALSE
if (run) {
  for (j in jacobians) {
    
    indir <- mouse_cluster_map_dirs[[j]]
    outdir <- mouse_cluster_map_dirs_50um[[j]]
    
    for (nk in 2:nk_max) {
      for (k in 1:nk) {
        
        infile <- paste0("cluster_map_nk_", nk, "_k_", k, ".mnc")
        outfile <- infile
        
        infile <- file.path(indir, infile)
        outfile <- file.path(outdir, outfile)
        
        cmd_mincresample <- paste("mincresample", "-clobber",
                                  "-like", mouse_anat_file,
                                  infile, outfile)
        system(command = cmd_mincresample)
        
      }
    }
  }
}
```

```{r fig-supp-5-import}
# Iterate over jacobians  
list_mouse_centroids <- vector(mode = "list", length = length(jacobians))
names(list_mouse_centroids) <- jacobians
for (j in jacobians) {
  
  # Iterate over clusters in nk solution
  list_mouse_centroids[[j]] <- vector(mode = "list", length = nk_mouse)
  names(list_mouse_centroids[[j]]) <- paste(nk_mouse, 1:nk_mouse, sep = "-")
  for (k in 1:nk_mouse) {
    
    # Import centroid image for specific cluster using threshold
    img_mouse <- import_cluster_map(imgdir = mouse_centroid_dirs_50um[[j]],
                                    mask = mouse_mask_file,
                                    nk = nk_mouse, k = k,
                                    threshold = threshold,
                                    threshold_value = threshold_value,
                                    threshold_symmetric = threshold_symmetric)
    
    list_mouse_centroids[[j]][[k]] <- mincArray(img_mouse)
    
  }
}
```

```{r fig-supp-5-ss}
# Mouse anatomy thresholds
mouse_anat_low <- 800
mouse_anat_high <- 2000

# Overlay thresholds from previous code chunk
overlay_low <- 0.19
overlay_high <- 1.0

# Iterate over clusters
for (k in 1:nk_mouse) {
  
  # Slice series grob
  fig_supp_5_grob <- sliceSeries(nrow = ss_nslices, ncol = 1, begin = 20, end = 200) %>% 
    anatomy(mouse_anat_vol, low = mouse_anat_low, high = mouse_anat_high) %>% 
    overlay(list_mouse_centroids[["absolute"]][[k]], low = overlay_low, high = overlay_high, symmetric = TRUE) %>% 
    sliceSeries() %>% anatomy() %>% 
    overlay(list_mouse_centroids[["relative"]][[k]], low = overlay_low, high = overlay_high, symmetric = TRUE) %>%   
    legend() %>% 
    grobify()
  
  # Dimensions
  fig_supp_5_width_pt <- fig_width_pt/(2)
  fig_supp_5_height_pt <- (fig_supp_5_width_pt/4)*ss_nslices
  
  # Export
  outfile <- paste(output_plot_prefix, 5, nk_mouse, k, sep = "_")
  outfile <- paste0(outfile, ".pdf")
  outfile <- file.path(output_dir, outfile)
  export_pdf(x = fig_supp_5_grob,
             file = outfile,
             width = fig_supp_5_width_pt,
             height = fig_supp_5_height_pt,
             units = "bigpts")
  
}
```


# Supplementary Figure 6: Molecular pathways Sankey diagrams

```{r fig-supp-6-import}
# Enrichment database versions
stringdb_version <- "12.0"
bader_version <- "2023"
stringdb_score <- 950

# Base directory for pathway data files
mouse_pathways_dir <- file.path(PROJECTPATH, "data/mouse/enrichment/")
mouse_pathways_dir <- file.path(mouse_pathways_dir, 
                                paste("StringDB", stringdb_version, 
                                      "Bader", bader_version, 
                                      sep = "_"))
mouse_pathways_dir <- file.path(mouse_pathways_dir, "NeighbourhoodEnrichment")
mouse_pathways_dir <- file.path(mouse_pathways_dir, stringdb_score)

if (length(list.files(mouse_pathways_dir)) == 0) {
  stop("No files in specified directory")
}

# Prefix for pathway data files
mouse_pathways_file_prefix <- "NewBader_enrichment_clusterneighbourhood_vs_brain_all"

# Pathway IDs for a prior pathway set
if (bader_version == "2020") {
  pathway_ids <- c("ADHERENS JUNCTIONS INTERACTIONS%REACTOME%R-HSA-418990.2",
                   "AXON GUIDANCE%REACTOME DATABASE ID RELEASE 71%422475",
                   "CA2+ PATHWAY%REACTOME DATABASE ID RELEASE 71%4086398",
                   "CHROMATIN ORGANIZATION%REACTOME DATABASE ID RELEASE 71%4839726",
                   "GAP JUNCTION TRAFFICKING AND REGULATION%REACTOME%R-HSA-157858.1",
                   "GENE EXPRESSION (TRANSCRIPTION)%REACTOME DATABASE ID RELEASE 71%74160",
                   "GENERIC TRANSCRIPTION PATHWAY%REACTOME%R-HSA-212436.9",
                   "LONG-TERM POTENTIATION%REACTOME DATABASE ID RELEASE 71%9620244",
                   "MAPK FAMILY SIGNALING CASCADES%REACTOME DATABASE ID RELEASE 71%5683057",
                   "MTOR SIGNALLING%REACTOME%R-HSA-165159.5",
                   "PROTEIN-PROTEIN INTERACTIONS AT SYNAPSES%REACTOME DATABASE ID RELEASE 71%6794362",
                   "SIGNALING BY ERBB2%REACTOME DATABASE ID RELEASE 71%1227986",
                   "SIGNALING BY ERBB4%REACTOME DATABASE ID RELEASE 71%1236394",
                   "SIGNALING BY HEDGEHOG%REACTOME DATABASE ID RELEASE 71%5358351",
                   "SIGNALING BY GPCR%REACTOME%R-HSA-372790.4",
                   "SIGNALING BY NOTCH%REACTOME DATABASE ID RELEASE 71%157118",
                   "SIGNALING BY VEGF%REACTOME DATABASE ID RELEASE 71%194138",
                   "SIGNALING BY WNT%REACTOME%R-HSA-195721.5",
                   "TIGHT JUNCTION INTERACTIONS%REACTOME DATABASE ID RELEASE 71%420029",
                   "TRANSMISSION ACROSS CHEMICAL SYNAPSES%REACTOME%R-HSA-112315.5")
} else if (bader_version == "2023") {
  pathway_ids <- c("ADHERENS JUNCTIONS INTERACTIONS%REACTOME DATABASE ID RELEASE 38%418990",
                   "AXON GUIDANCE%REACTOME%R-HSA-422475.7",
                   "CA2+ PATHWAY%REACTOME%R-HSA-4086398.4",
                   "CHROMATIN ORGANIZATION%REACTOME DATABASE ID RELEASE 38%4839726",
                   "GAP JUNCTION TRAFFICKING AND REGULATION%REACTOME%R-HSA-157858.2",
                   "GENE EXPRESSION (TRANSCRIPTION)%REACTOME%R-HSA-74160.8",
                   "GENERIC TRANSCRIPTION PATHWAY%REACTOME%R-HSA-212436.12",
                   "LONG-TERM POTENTIATION%REACTOME DATABASE ID RELEASE 38%9620244",
                   "MAPK FAMILY SIGNALING CASCADES%REACTOME%R-HSA-5683057.4",
                   "MTOR SIGNALLING%REACTOME%R-HSA-165159.7",
                   "PROTEIN-PROTEIN INTERACTIONS AT SYNAPSES%REACTOME DATABASE ID RELEASE 38%6794362",
                   "SIGNALING BY ERBB2%REACTOME DATABASE ID RELEASE 38%1227986",
                   "SIGNALING BY ERBB4%REACTOME DATABASE ID RELEASE 38%1236394",
                   "SIGNALING BY GPCR%REACTOME DATABASE ID RELEASE 38%372790",
                   "SIGNALING BY HEDGEHOG%REACTOME DATABASE ID RELEASE 38%5358351",
                   "SIGNALING BY NOTCH%REACTOME%R-HSA-157118.6",
                   "SIGNALING BY VEGF%REACTOME%R-HSA-194138.3",
                   "SIGNALING BY WNT%REACTOME DATABASE ID RELEASE 38%195721",
                   "TIGHT JUNCTION INTERACTIONS%REACTOME DATABASE ID RELEASE 38%420029",
                   "TRANSMISSION ACROSS CHEMICAL SYNAPSES%REACTOME%R-HSA-112315.7")
} else {
  stop()
}

# Iterate over cluster solutions and import mouse pathway enrichment files
list_mouse_pathways <- vector(mode = "list", length = nk_max-1)
names(list_mouse_pathways) <- 2:nk_max
for (nk in 2:nk_max) {
  
  # Iterate over cluster number
  list_mouse_pathways[[as.character(nk)]] <- vector(mode = "list", length = nk)
  for (k in 1:nk) {
    pathways_file <- paste(mouse_pathways_file_prefix, nk, k, stringdb_score, sep = "_")
    pathways_file <- paste0(pathways_file, ".csv")
    pathways_file <- file.path(mouse_pathways_dir, pathways_file)
    list_mouse_pathways[[as.character(nk)]][[k]] <- read_csv(pathways_file, show_col_types = FALSE)  
    
    # Fix mouse enrichment p-values and q-values
    list_mouse_pathways[[as.character(nk)]][[k]] <- list_mouse_pathways[[as.character(nk)]][[k]] %>%
      mutate(NLQ = -log10(adj.P.Val))
  }
  
  # Combine clusters per solution
  list_mouse_pathways[[as.character(nk)]] <- list_mouse_pathways[[as.character(nk)]] %>% 
    reduce(.f = bind_rows) %>% 
    rename(pathway = Title,
           k = cluster) %>% 
    filter(ID %in% pathway_ids) %>% 
    mutate(nk = nk) %>% 
    unite(col = "cluster_id", nk, k, 
          sep = "-", remove = FALSE)
  
}

# Reduce list of pathways to a data frame
df_mouse_pathways_all <- list_mouse_pathways %>% 
  bind_rows() %>% 
  filter(ID %in% pathway_ids)
```

```{r fig-supp-6-pathways-info}
# Extract pathway ID and name
df_pathway_info <- df_mouse_pathways_all %>% 
  select(ID, pathway) %>% 
  distinct() %>% 
  arrange(pathway)

# Create pathway acronyms
df_pathway_info[["acronym"]] <- c(
  "AJI", "AG", "Ca2+", "CO",
  "GJTR", "GE", "GTP", "LTP",
  "MAPK", "MTOR", "PPIS", "ERBB2",
  "ERBB4", "GPCR", "HEDGEHOG", "NOTCH",
  "VEGF", "WNT", "TJI", "TACS"
)
```

```{r fig-supp-6-clustering}
# Filter for cluster solutions with nk >= 4
df_pathways_nk_gt4 <- df_mouse_pathways_all %>% 
  filter(nk >= 4)

# Filter for desired pathways
# Compute normalized enrichment and NLQ per pathway
df_pathways_nk_gt4_subset <- df_pathways_nk_gt4 %>% 
  filter(pathway %in% df_pathway_info[["pathway"]]) %>% 
  group_by(pathway) %>% 
  mutate(NLQ_norm = NLQ/max(NLQ)) %>% 
  ungroup() %>% 
  mutate(NLQ_norm = ifelse(is.nan(NLQ_norm), 0, NLQ_norm))

# Convert pathway data frame into matrix 
mat_pathways_nk_gt4_subset <- df_pathways_nk_gt4_subset %>% 
  select(pathway, cluster_id, NLQ_norm) %>% 
  pivot_wider(id_cols = pathway, 
              names_from = cluster_id, 
              values_from = NLQ_norm) %>% 
  column_to_rownames("pathway") %>% 
  as.matrix()

# Hierarchical clustering of the pathways
pathway_hc <- hclust(d = dist(mat_pathways_nk_gt4_subset, 
                              method = "euclidean"))

# Extract pathway order according to clustering
pathway_lvls <- pathway_hc[["labels"]]
pathway_order <- pathway_hc[["order"]]
pathway_lvls_clustered <- pathway_lvls[pathway_order]

# Order pathway acronyms according to clustering
pathway_label_lvls_clustered <- df_pathway_info %>%
  mutate(pathway = factor(pathway, levels = pathway_lvls_clustered)) %>%
  arrange(pathway) %>%
  pull(acronym)
```

```{r fig-supp-6-plot}
# Convert mouse clusters to long format
df_mouse_clusters_long <- df_mouse_clusters %>% 
  pivot_longer(cols = -ID, names_to = "nk_name", values_to = "k") %>% 
  mutate(nk = str_remove(nk_name, "nk"),
         nk = as.numeric(nk))

# Clamping threshold 
NLQ_threshold <- 30

# Create data frame for plotting
df_mouse_pathways_alluvial <- df_mouse_pathways_all %>% 
  select(-ID) %>% 
  right_join(df_mouse_clusters_long, by = c("nk", "k")) %>% 
  mutate(nk = factor(nk),
         k = factor(k),
         pathway = factor(pathway, levels = pathway_lvls_clustered),
         NLQ = ifelse(NLQ > NLQ_threshold, NLQ_threshold, NLQ),
         E = ifelse(E > 30, 30, E))

# Plot Sankey diagrams
fig_supp_6 <- ggplot(df_mouse_pathways_alluvial, 
                     aes(x = nk, 
                         stratum = k,
                         fill = NLQ,
                         alluvium = ID)) + 
  geom_flow(stat = "alluvium", aes.flow = "forward") + 
  geom_stratum(size = 0.15) + 
  facet_wrap(~pathway, ncol = 3, nrow = 7) + 
  scale_fill_gradientn(colors = brewer.pal(n = 9, name = "OrRd")[3:9],
                       limits = c(0, 30),
                       guide = guide_colourbar(title.position = "top",
                                               title.hjust = 0.5)) + 
  labs(x = "Number of clusters (K)",
       y = "Number of models",
       fill = "Enrichment (-log10(q))") + 
  theme_bw() + 
  theme(panel.grid.major.x = element_blank(),
        panel.spacing = unit(2, "bigpts"),
        axis.title = element_text(size = font_size, family = font_family),
        axis.text = element_text(size = font_size-1, family = font_family),
        strip.background = element_rect(fill = "grey90"),
        strip.text = element_text(size = font_size-1, family = font_family, 
                                  margin = margin(t = 1, b = 1, unit = "bigpts")),
        legend.title = element_text(size = font_size, family = font_family),
        legend.text = element_text(size = font_size, family = font_family),
        legend.position = c(0.85, 0.072),
        legend.direction = "horizontal",
        legend.margin = margin(),
        plot.margin = margin())

# Figure dimensions
fig_supp_6_width_pt <- fig_width_pt
fig_supp_6_height_pt <- fig_height_pt

# Export
outfile <- paste(output_plot_prefix, 6, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
export_pdf(x = ggplotGrob(fig_supp_6),
           width = fig_supp_6_width_pt,
           height = fig_supp_6_height_pt,
           units = "bigpts",
           file = outfile)
```


# Supplementary Figure 7: Molecular pathway motifs scree plot

```{r fig-supp-7}
# Generate pathway cluster scree plot
fig_supp_7 <- mat_pathways_nk_gt4_subset %>% 
  t() %>% 
  hclust_wcss() %>% 
  as_tibble() %>% 
  mutate(nk = 1:nrow(.)) %>% 
  ggplot(df_pathway_hclust,
         mapping = aes(nk, y = value)) + 
  geom_line(size = 0.4) + 
  geom_point(size = 1) +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) + 
  labs(x = "Number of clusters (motifs)",
       y = "Within-cluster sum of squared distance") + 
  theme_bw() +
  theme(axis.title = element_text(size = font_size+1,
                                  family = font_family),
        axis.text = element_text(size = font_size,
                                 family = font_family),
        legend.title = element_text(size = font_size+1,
                                    family = font_family),
        legend.text = element_text(size = font_size,
                                   family = font_family),
        panel.grid.minor.x = element_blank())

# Figure dimensions
fig_supp_7_width_pt <- fig_width_pt
fig_supp_7_height_pt <- fig_width_pt/3

# Export
outfile <- paste(output_plot_prefix, 7, sep = "_")
outfile <- paste0(outfile, ".jpeg")
outfile <- file.path(output_dir, outfile)
jpeg(filename = outfile,
     width = fig_supp_7_width_pt/pt_per_in,
     height = fig_supp_7_height_pt/pt_per_in,
     units = "in",
     res = 600,
     quality = 100)
print(fig_supp_7)
dev.off()
```


# Supplementary Figures 8-11: Centroid slice series for mouse and human matches

```{r fig-supp-8-11-import}
# Directory for mouse-human cluster similarity 
similarity_dir <- file.path(pipeline_dir, "similarity")

# Directory for mouse-human cluster similarity permutations
permutation_dir <- file.path(pipeline_dir, "permutations", "similarity")

# Set of similarity files
similarity_file <- file.path(similarity_dir, "similarity.csv")

# Jacobians to use
jacobians <- c("absolute", "relative")

# Import the similarity data and extract cluster information
similarity <- read_csv(similarity_file, show_col_types = FALSE) %>% 
  rename(human_img = img1,
         mouse_img = img2) %>% 
  mutate(human_nk = human_img %>% 
           basename() %>% 
           str_extract("_nk_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         human_k = human_img %>% 
           basename() %>% 
           str_extract("_k_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         human_jacobians = human_img %>% 
           str_extract("absolute|relative"),
         mouse_nk = mouse_img %>% 
           basename() %>% 
           str_extract("_nk_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         mouse_k = mouse_img %>% 
           basename() %>% 
           str_extract("_k_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         mouse_jacobians = mouse_img %>% 
           str_extract("absolute|relative"),) %>% 
  unite(col = "human_cluster_id", human_nk, human_k, 
        sep = "-", remove = FALSE) %>% 
  unite(col = "mouse_cluster_id", mouse_nk, mouse_k, 
        sep = "-", remove = FALSE)

# Compute average similarity values across jacobians for each permutation
df_similarity <- similarity %>% 
  group_by(human_cluster_id, human_nk, human_k, 
           mouse_cluster_id, mouse_nk, mouse_k) %>% 
  summarise(similarity = mean(similarity), .groups = "drop")


# Permutation file names
permutation_files <- list.files(permutation_dir)

# Number of permutations
np <- length(permutation_files)
list_permutations <- vector(mode = "list", length = np)  
for (p in 1:np) {
  
  # Permutation data to import
  permutation_file <- permutation_files %>% 
    str_subset(str_c("similarity_permutation_", p, ".csv"))
  permutation_file <- file.path(permutation_dir, permutation_file)
  
  # Import permutation data
  list_permutations[[p]] <- read_csv(permutation_file, 
                                     show_col_types = FALSE) %>% 
    rename(human_img = img1,
           mouse_img = img2) %>% 
    mutate(human_nk = human_img %>% 
             basename() %>% 
             str_extract("_nk_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           human_k = human_img %>% 
             basename() %>% 
             str_extract("_k_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           mouse_nk = mouse_img %>% 
             basename() %>% 
             str_extract("_nk_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           mouse_k = mouse_img %>% 
             basename() %>% 
             str_extract("_k_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric()) %>% 
    unite(col = "human_cluster_id", human_nk, human_k, 
          sep = "-", remove = FALSE) %>% 
    unite(col = "mouse_cluster_id", mouse_nk, mouse_k, 
          sep = "-", remove = FALSE) %>% 
    mutate(permutation = p)
  
}

# Filter permutations data for desired cluster numbers
# and combine Jacobians
df_permutations <- list_permutations %>% 
  bind_rows() %>% 
  group_by(permutation, human_nk, mouse_nk, human_cluster_id, mouse_cluster_id) %>% 
  summarise(similarity = mean(similarity), .groups = "drop")
```

```{r fig-supp-8-11-pvals}
# Mouse and human max nk
human_nk_max <- max(df_similarity[["human_nk"]])
mouse_nk_max <- max(df_similarity[["mouse_nk"]])

# Iterate along nk diagonal +/- 1
df_sim_pvals_POND <- tibble()
for (h_nk in 2:human_nk_max) {
  for (m_nk in (h_nk-1):(h_nk+1)){
    
    if ((m_nk > 1) & (m_nk <= mouse_nk_max)) {
      
      df_sim_nk <- df_similarity %>% 
        select(human_cluster_id, human_nk, human_k,
               mouse_cluster_id, mouse_nk, mouse_k,
               similarity) %>% 
        filter(human_nk == h_nk,
               mouse_nk == m_nk) %>% 
        mutate(pval = 0)
      
      sim_perm_nk <- df_permutations %>% 
        filter(human_nk == h_nk,
               mouse_nk == m_nk) %>% 
        pull(similarity) %>% 
        sort()
      
      for (i in 1:nrow(df_sim_nk)) {
        ntail <- sum(sim_perm_nk >= df_sim_nk[[i, "similarity"]])
        df_sim_nk[[i, "pval"]] <- ntail/length(sim_perm_nk)
      }
      
      df_sim_pvals_POND <- bind_rows(df_sim_pvals_POND, df_sim_nk)
      
    }
  }
}

# Evaluate significance
sim_alpha <- 0.05
df_sim_pvals_POND <- df_sim_pvals_POND %>% 
  mutate(significant = ifelse(pval < sim_alpha, 1, 0))
```

```{r fig-supp-8-11-matches}
# Determine mouse clusters with human matches
df_mouse_matches <- df_sim_pvals_POND %>% 
  group_by(mouse_nk, mouse_k) %>% 
  summarise(nsignificant = sum(significant), .groups = "drop") %>% 
  mutate(has_match = nsignificant > 0) %>% 
  select(nk = mouse_nk, k = mouse_k, has_match) %>% 
  filter(nk >= 4) %>% 
  unite(col = "cluster_id", "nk", "k", 
        sep = "-", remove = FALSE) %>% 
  filter(has_match) %>% 
  select(cluster_id, nk, k) %>% 
  mutate(nk = as.numeric(as.character(nk)),
         
         k = as.numeric(as.character(k)))

# Filter mouse clusters for >= 4
df_mouse_clusters_long <- df_mouse_clusters_long %>% 
  filter(nk >= 4) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE)  

# Extract cluster IDs for nk = 4
cluster_ids_nk4 <- df_mouse_clusters_long %>% 
  filter(nk == 4) %>% 
  select(cluster_id, nk, k) %>% 
  distinct() %>% 
  arrange(nk, k) %>% 
  pull(cluster_id)

# Extract cluster IDs for nk > 4
cluster_ids_gt4 <- df_mouse_clusters_long %>% 
  semi_join(df_mouse_matches, by = "cluster_id") %>% 
  filter(nk > 4) %>% 
  select(cluster_id, nk, k) %>% 
  distinct() %>% 
  arrange(nk, k) %>% 
  pull(cluster_id)

# For clusters in higher nk solutions, determine the how the models in 
# those clusters relate to those in the 4-cluster solution
df_cluster_grid <- expand_grid(cluster_id_nk4 = cluster_ids_nk4,
                               cluster_id = cluster_ids_gt4,
                               p = 0)
for (i in 1:nrow(df_cluster_grid)) {
  
  models_in_clust_4 <- df_mouse_clusters_long %>% 
    filter(cluster_id == df_cluster_grid[[i, "cluster_id_nk4"]]) %>% 
    pull(ID)
  
  models_in_clust <- df_mouse_clusters_long %>% 
    filter(cluster_id == df_cluster_grid[[i, "cluster_id"]]) %>% 
    pull(ID)
  
  intersection <- intersect(models_in_clust, models_in_clust_4)
  df_cluster_grid[[i, "p"]] <- length(intersection)/length(models_in_clust)
  
}

# Identify which cluster in the 4-cluster solution are most 
# representative of the higher clusters
df_cluster_grid <- df_cluster_grid %>% 
  group_by(cluster_id) %>% 
  filter(p == max(p)) %>% 
  ungroup() %>% 
  mutate(cluster_id = factor(cluster_id, levels = cluster_ids_gt4),
         cluster_id_nk4 = factor(cluster_id_nk4, levels = cluster_ids_nk4)) %>% 
  arrange(cluster_id_nk4, cluster_id) %>% 
  separate(col = "cluster_id", into = c("nk", "k"),
           sep = "-", remove = FALSE) %>% 
  mutate(nk = as.numeric(nk),
         k = as.numeric(k))

df_cluster_grid
```

```{r fig-supp-8-11-ss}
# List of mouse cluster streams
mouse_cluster_streams <- list(c("4-1", "6-5", "7-7", "8-6", "10-4"),
                              c("4-4", "6-1", "7-1", "8-1", "10-1"),
                              c("4-4", "6-4", "7-4", "8-2", "10-5"),
                              c("4-3", "6-3", "7-3", "8-5", "10-3"))

# Supplementary figure numbers
fig_supp_nums <- 8:11

run <- TRUE
if (run) {
  # Iterate over cluster streams
  for (l in 1:length(mouse_cluster_streams)) {
    
    # Iterate over clusters
    clusters <- mouse_cluster_streams[[l]]
    for (mouse_clust in clusters) {
      
      message(paste("Mouse cluster:", mouse_clust))
      
      # Extract cluster IDs
      nk <- str_split(mouse_clust, pattern = "-", simplify = TRUE)[1]
      k <- str_split(mouse_clust, pattern = "-", simplify = TRUE)[2]
      
      # Import absolute centroid
      img_abs <- import_cluster_map(imgdir = mouse_centroid_dirs_50um[["absolute"]],
                                    mask = mouse_mask_file,
                                    nk = nk, k = k,
                                    threshold = threshold,
                                    threshold_value = threshold_value,
                                    threshold_symmetric = threshold_symmetric)
      
      # Import relative centroid
      img_rel <- import_cluster_map(imgdir = mouse_centroid_dirs_50um[["relative"]],
                                    mask = mouse_mask_file,
                                    nk = nk, k = k,
                                    threshold = threshold,
                                    threshold_value = threshold_value,
                                    threshold_symmetric = threshold_symmetric)
      
      # Convert to MINC array
      img_abs <- mincArray(img_abs)
      img_rel <- mincArray(img_rel)
      
      # Generate slice series
      fig_supp_8_10_grob <- sliceSeries(nrow = 6, ncol = 1, begin = 20, end = 200) %>%
        anatomy(mouse_anat_vol, low = mouse_anat_low, high = mouse_anat_high) %>%
        overlay(img_abs, low = 0.2, high = 1.0, symmetric = TRUE) %>%
        sliceSeries() %>% anatomy() %>%
        overlay(img_rel, low = 0.2, high = 1.0, symmetric = TRUE) %>%
        grobify()
      
      # Dimensions
      fig_supp_8_10_width_pt <- fig_width_pt/(2)
      fig_supp_8_10_height_pt <- (fig_supp_8_10_width_pt/3)*6
      
      # Export
      outfile <- paste(output_plot_prefix, fig_supp_nums[[l]], "mouse", mouse_clust, sep = "_")
      outfile <- paste0(outfile, ".pdf")
      outfile <- file.path(output_dir, outfile)
      export_pdf(x = fig_supp_8_10_grob,
                 file = outfile,
                 width = fig_supp_8_10_width_pt,
                 height = fig_supp_8_10_height_pt,
                 units = "bigpts")
      
      # Get human matches for current mouse cluster
      human_matches <- df_sim_pvals_POND %>% 
        filter(mouse_cluster_id == mouse_clust, significant == 1) %>% 
        pull(human_cluster_id)
      
      # Iterate over human clusters
      for (human_clust in human_matches) {
        
        message(paste("\tHuman cluster:", human_clust))
        
        # Extract cluster IDs
        nk_human <- str_split(human_clust, pattern = "-", simplify = TRUE)[1]
        k_human <- str_split(human_clust, pattern = "-", simplify = TRUE)[2]
        
        # Import centroid image for specific cluster using threshold
        img_abs <- import_cluster_map(imgdir = human_centroid_dirs[["absolute"]],
                                      mask = human_mask_file,
                                      nk = nk_human, k = k_human,
                                      threshold = threshold,
                                      threshold_value = threshold_value,
                                      threshold_symmetric = threshold_symmetric)
        
        # Import centroid image for specific cluster using threshold
        img_rel <- import_cluster_map(imgdir = human_centroid_dirs[["relative"]],
                                      mask = human_mask_file,
                                      nk = nk_human, k = k_human,
                                      threshold = threshold,
                                      threshold_value = threshold_value,
                                      threshold_symmetric = threshold_symmetric)
        
        # Crop image to remove black space
        img_abs <- mincArray(img_abs)
        img_abs <- img_abs[human_slices_dim_1,,human_slices_dim_3]
        
        # Crop image to remove black space
        img_rel <- mincArray(img_rel)
        img_rel <- img_rel[human_slices_dim_1,,human_slices_dim_3]
        
        # Generate slice series
        fig_supp_8_10_grob <- sliceSeries(nrow = 6, ncol = 1, begin = 60, end = 220) %>%
          anatomy(human_anat_vol_cropped, low = human_anat_low, high = human_anat_high) %>%
          overlay(img_abs, low = 0.2, high = 1.0, symmetric = TRUE) %>%
          sliceSeries() %>% anatomy() %>%
          overlay(img_rel, low = 0.2, high = 1.0, symmetric = TRUE) %>%
          grobify()
        
        # Dimensions
        fig_supp_8_10_width_pt <- 130
        fig_supp_8_10_height_pt <- (fig_supp_8_10_width_pt/2)*6
        
        # Export
        outfile <- paste(output_plot_prefix, fig_supp_nums[[l]], "mouse", mouse_clust, "human", human_clust, sep = "_")
        outfile <- paste0(outfile, ".pdf")
        outfile <- file.path(output_dir, outfile)
        export_pdf(x = fig_supp_8_10_grob,
                   file = outfile,
                   width = fig_supp_8_10_width_pt,
                   height = fig_supp_8_10_height_pt,
                   units = "bigpts")
        
      }    
    }
  }
}
```

```{r fig-supp-8-pvals}
df_sim_pvals_POND %>% 
  filter(mouse_cluster_id %in% mouse_cluster_streams[[1]],
         significant == 1) %>% 
  arrange(mouse_nk, mouse_k) %>%   
  select(mouse_cluster_id, human_cluster_id, similarity, pval) %>% 
  mutate(similarity = round(similarity, 3),
         pval = round(pval, 4))  
```

```{r fig-supp-9-pvals}
df_sim_pvals_POND %>% 
  filter(mouse_cluster_id %in% mouse_cluster_streams[[2]],
         significant == 1) %>% 
  arrange(mouse_nk, mouse_k) %>%   
  select(mouse_cluster_id, human_cluster_id, similarity, pval) %>% 
  mutate(similarity = round(similarity, 3),
         pval = round(pval, 3))  
```
```{r fig-supp-10-pvals}
df_sim_pvals_POND %>% 
  filter(mouse_cluster_id %in% mouse_cluster_streams[[3]],
         significant == 1) %>% 
  arrange(mouse_nk, mouse_k) %>%   
  select(mouse_cluster_id, human_cluster_id, similarity, pval) %>% 
  mutate(similarity = round(similarity, 3),
         pval = round(pval, 3))    
```

```{r fig-supp-11-pvals}
df_sim_pvals_POND %>% 
  filter(mouse_cluster_id %in% mouse_cluster_streams[[4]],
         significant == 1) %>% 
  arrange(mouse_nk, mouse_k) %>%   
  select(mouse_cluster_id, human_cluster_id, similarity, pval) %>% 
  mutate(similarity = round(similarity, 3),
         pval = round(pval, 3))   
```


# Supplementary Figure 12: Extended molecular pathway enrichment analysis

```{r fig-supp-12-pathways-import}
# Iterate over cluster solutions and import mouse pathway enrichment files
list_mouse_pathways <- vector(mode = "list", length = nk_max-1)
names(list_mouse_pathways) <- 2:nk_max
for (nk in 2:nk_max) {
  
  # Iterate over cluster number
  list_mouse_pathways[[as.character(nk)]] <- vector(mode = "list", length = nk)
  for (k in 1:nk) {
    pathways_file <- paste(mouse_pathways_file_prefix, nk, k, stringdb_score, sep = "_")
    pathways_file <- paste0(pathways_file, ".csv")
    pathways_file <- file.path(mouse_pathways_dir, pathways_file)
    list_mouse_pathways[[as.character(nk)]][[k]] <- read_csv(pathways_file, show_col_types = FALSE)  
    
    # Fix mouse enrichment p-values and q-values
    list_mouse_pathways[[as.character(nk)]][[k]] <- list_mouse_pathways[[as.character(nk)]][[k]] %>%
      mutate(NLQ = -log10(adj.P.Val))
  }
  
  # Combine clusters per solution
  list_mouse_pathways[[as.character(nk)]] <- list_mouse_pathways[[as.character(nk)]] %>% 
    reduce(.f = bind_rows) %>% 
    rename(pathway = Title,
           k = cluster) %>% 
    mutate(nk = nk) %>% 
    unite(col = "cluster_id", nk, k, 
          sep = "-", remove = FALSE)
  
}

# Reduce list of pathways to a data frame
df_pathways_all <- list_mouse_pathways %>% 
  bind_rows() 
```

```{r fig-supp-12-pathways-scree}
# Get enrichment for nk >= 4
df_pathways_all_nk_geq4 <- df_pathways_all %>% 
  filter(nk >= 4)

# Get cluster levels
cluster_lvls <- df_pathways_all_nk_geq4 %>% 
  select(nk, k, cluster_id) %>% 
  distinct() %>% 
  arrange(nk, k) %>% 
  pull(cluster_id)

# Number of most enriched pathways for each cluster
nhighest <- 10

# Filter for top pathways
list_pathways_all_topn <- vector(mode = "list", length = length(cluster_lvls))
for (i in 1:length(list_pathways_all_topn)) {
  list_pathways_all_topn[[i]] <-
    df_pathways_all_nk_geq4 %>% 
    filter(cluster_id == cluster_lvls[i]) %>% 
    arrange(rank) %>% 
    head(n = nhighest) %>% 
    pull(pathway)
}

# Get the full set of top pathways
pathways_topn <- reduce(.x = list_pathways_all_topn, .f = c)
pathways_topn <- unique(pathways_topn)

# Filter for top pathways and normalize enrichment 
df_pathways_topn <- df_pathways_all_nk_geq4 %>% 
  filter(pathway %in% pathways_topn) %>% 
  group_by(pathway) %>% 
  mutate(NLQ_norm = NLQ/max(NLQ)) %>% 
  ungroup() %>% 
  mutate(NLQ_norm = ifelse(is.nan(NLQ_norm), 0, NLQ_norm))

# Convert to matrix
mat_pathways_topn <- df_pathways_topn %>% 
  select(pathway, cluster_id, NLQ_norm) %>% 
  pivot_wider(id_cols = pathway, 
              names_from = cluster_id, 
              values_from = NLQ_norm) %>% 
  column_to_rownames("pathway") %>% 
  as.matrix()

# Pathway motif scree plot
mat_pathways_topn %>% 
  t() %>% 
  hclust_wcss() %>% 
  as_tibble() %>% 
  mutate(nk = 1:nrow(.)) %>% 
  ggplot(df_pathway_hclust,
         mapping = aes(nk, y = value)) + 
  geom_line() + 
  geom_point() + 
  coord_cartesian(xlim = c(1, 70)) + 
  scale_x_continuous(breaks = seq(0, length(pathways_topn), by = 5)) +
  labs(x = "Number of clusters",
       y = "Within-cluster sum of squared distance") + 
  theme_bw() +
  theme(panel.grid.minor.x = element_blank())
```

```{r fig-supp-12-pathways-dendrogram}
# Dendrogram cut
hclust_kcut <- 20

# Hierarchical clustering of the pathways
pathways_topn_hc <- hclust(d = dist(mat_pathways_topn, 
                                    method = "euclidean"))

# Extract pathway order according to clustering
pathways_topn_lvls <- pathways_topn_hc[["labels"]]
pathways_topn_order <- pathways_topn_hc[["order"]]
pathways_topn_lvls_clustered <- pathways_topn_lvls[pathways_topn_order]

# Obtain pathway cluster order at selected solution
df_pathways_topn_hclust <- cutree(pathways_topn_hc, k = hclust_kcut) %>% 
  enframe(name = "pathway", value = "pathway_cluster") 

# Relevel pathways to follow dendrogram order
df_pathways_topn_cluster_lvls <- df_pathways_topn_hclust %>% 
  mutate(pathway = factor(pathway, levels = pathways_topn_lvls_clustered)) %>% 
  arrange(pathway) %>% 
  select(pathway_cluster) %>% 
  distinct() %>% 
  mutate(pathway_cluster_new = 1:nrow(.))

df_pathways_topn_hclust <- df_pathways_topn_hclust %>% 
  left_join(df_pathways_topn_cluster_lvls, by = "pathway_cluster") %>% 
  select(-pathway_cluster, pathway_cluster = pathway_cluster_new)

# Generate clustered heatmap
fig_supp_12_pheatmap <- pheatmap(mat = mat_pathways_topn,
                                 cluster_col = FALSE,
                                 cluster_rows = TRUE,
                                 clustering_distance_rows = "euclidean",
                                 cutree_rows = hclust_kcut,
                                 silent = TRUE)

# Extract dendrogram from pheatmap object
fig_supp_12_dendrogram_grob <- fig_supp_12_pheatmap[["gtable"]][["grobs"]][[1]]
fig_supp_12_dendrogram_grob[["gp"]] <- gpar(lwd = 0.75)
```

```{r fig-supp-12-sim-HBN-import}
# Similarity directory
similarity_dir <- file.path(PROJECTPATH, "/data/cross_species//v3/", "861", "similarity")

# Directory for mouse-human cluster similarity permutations
permutation_dir <- file.path(PROJECTPATH, "/data/cross_species//v3/", "861", "permutations", "similarity")

# Path to mouse-human similarity directory
similarity_file <- file.path(similarity_dir, "similarity.csv")

# Import the similarity data and extract cluster information
similarity <- read_csv(similarity_file, show_col_types = FALSE) %>% 
  rename(human_img = img1,
         mouse_img = img2) %>% 
  mutate(human_nk = human_img %>% 
           basename() %>% 
           str_extract("_nk_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         human_k = human_img %>% 
           basename() %>% 
           str_extract("_k_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         human_jacobians = human_img %>% 
           str_extract("absolute|relative"),
         mouse_nk = mouse_img %>% 
           basename() %>% 
           str_extract("_nk_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         mouse_k = mouse_img %>% 
           basename() %>% 
           str_extract("_k_[0-9]+") %>% 
           str_extract("[0-9]+") %>% 
           as.numeric(),
         mouse_jacobians = mouse_img %>% 
           str_extract("absolute|relative"),) %>% 
  unite(col = "human_cluster_id", human_nk, human_k, 
        sep = "-", remove = FALSE) %>% 
  unite(col = "mouse_cluster_id", mouse_nk, mouse_k, 
        sep = "-", remove = FALSE)

# Filter similarity data for desired cluster numbers
# and combine Jacobians
df_similarity <- similarity %>% 
  group_by(human_cluster_id, human_nk, human_k, 
           mouse_cluster_id, mouse_nk, mouse_k) %>% 
  summarise(similarity = mean(similarity),
            .groups = "drop")


# Permutation file names
permutation_files <- list.files(permutation_dir)

# Number of permutations
np <- length(permutation_files)
list_permutations <- vector(mode = "list", length = np)  
for (p in 1:np) {
  
  # Permutation data to import
  permutation_file <- permutation_files %>% 
    str_subset(str_c("similarity_permutation_", p, ".csv"))
  permutation_file <- file.path(permutation_dir, permutation_file)
  
  # Import permutation data
  list_permutations[[p]] <- read_csv(permutation_file, 
                                     show_col_types = FALSE) %>% 
    rename(human_img = img1,
           mouse_img = img2) %>% 
    mutate(human_nk = human_img %>% 
             basename() %>% 
             str_extract("_nk_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           human_k = human_img %>% 
             basename() %>% 
             str_extract("_k_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           mouse_nk = mouse_img %>% 
             basename() %>% 
             str_extract("_nk_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric(),
           mouse_k = mouse_img %>% 
             basename() %>% 
             str_extract("_k_[0-9]+") %>% 
             str_extract("[0-9]+") %>% 
             as.numeric()) %>% 
    unite(col = "human_cluster_id", human_nk, human_k, 
          sep = "-", remove = FALSE) %>% 
    unite(col = "mouse_cluster_id", mouse_nk, mouse_k, 
          sep = "-", remove = FALSE) %>% 
    mutate(permutation = p)
  
}

# Filter permutations data for desired cluster numbers
# and combine Jacobians
df_permutations <- list_permutations %>% 
  bind_rows() %>% 
  group_by(permutation, human_nk, mouse_nk, human_cluster_id, mouse_cluster_id) %>% 
  summarise(similarity = mean(similarity), .groups = "drop")
```

```{r fig-supp-12-sim-HBN-pvals}
# Mouse and human max nk
human_nk_max <- max(df_similarity[["human_nk"]])
mouse_nk_max <- max(df_similarity[["mouse_nk"]])

# Iterate along nk diagonal +/- 1
df_sim_pvals_HBN <- tibble()
for (h_nk in 2:human_nk_max) {
  for (m_nk in (h_nk-1):(h_nk+1)){
    
    if ((m_nk > 1) & (m_nk <= mouse_nk_max)) {
      
      df_sim_nk <- df_similarity %>% 
        select(human_cluster_id, human_nk, human_k,
               mouse_cluster_id, mouse_nk, mouse_k,
               similarity) %>% 
        filter(human_nk == h_nk,
               mouse_nk == m_nk) %>% 
        mutate(pval = 0)
      
      sim_perm_nk <- df_permutations %>% 
        filter(human_nk == h_nk,
               mouse_nk == m_nk) %>% 
        pull(similarity) %>% 
        sort()
      
      for (i in 1:nrow(df_sim_nk)) {
        ntail <- sum(sim_perm_nk >= df_sim_nk[[i, "similarity"]])
        df_sim_nk[[i, "pval"]] <- ntail/length(sim_perm_nk)
      }
      
      df_sim_pvals_HBN <- bind_rows(df_sim_pvals_HBN, df_sim_nk)
      
    }
  }
}

# Evaluate significance
sim_alpha <- 0.05
df_sim_pvals_HBN <- df_sim_pvals_HBN %>% 
  mutate(significant = ifelse(pval < sim_alpha, 1, 0))
```

```{r fig-supp-12-heatmaps}
# Get pathway motifs
df_pathways_topn_heatmap <- df_pathways_topn %>% 
  left_join(df_pathways_topn_hclust, by = "pathway") %>% 
  mutate(pathway = factor(pathway, levels = pathways_topn_lvls_clustered))

# Create data frame for significant POND matches
df_sig_nk_POND <- df_sim_pvals_POND %>% 
  group_by(mouse_nk, mouse_k) %>% 
  summarise(p = min(pval),
            nsignificant = sum(significant),
            .groups = "drop") %>% 
  mutate(plab = case_when(p < 0.05 ~ "**",
                          p >= 0.05 & p < 0.1 ~ "*",
                          p >= 0.1 ~ ""),
         has_match = ifelse(nsignificant > 0, TRUE, FALSE),
         y = "y") %>% 
  select(nk = mouse_nk, k = mouse_k, p, plab, has_match, y) %>% 
  filter(nk >= 4) %>% 
  unite(col = "cluster_id", "nk", "k", 
        sep = "-", remove = FALSE) 

# Create data frame for significant HBN matches
df_sig_nk_HBN <- df_sim_pvals_HBN %>% 
  group_by(mouse_nk, mouse_k) %>% 
  summarise(p = min(pval),
            nsignificant = sum(significant),
            .groups = "drop") %>% 
  mutate(plab = case_when(p < 0.05 ~ "**",
                          p >= 0.05 & p < 0.1 ~ "*",
                          p >= 0.1 ~ ""),
         has_match = ifelse(nsignificant > 0, TRUE, FALSE),
         y = "HBN") %>% 
  select(nk = mouse_nk, k = mouse_k, p, plab, has_match, y) %>% 
  filter(nk >= 4) %>% 
  unite(col = "cluster_id", "nk", "k", 
        sep = "-", remove = FALSE) 

# Combine POND and HBN data
df_sig_nk <- bind_rows(df_sig_nk_POND,
                       df_sig_nk_HBN)

df_pathways_topn_heatmap <- df_pathways_topn_heatmap %>% 
  left_join(df_sig_nk_POND %>% 
              select(cluster_id, has_match),
            by = "cluster_id")

# Clamped enrichment statistic
NLQ_threshold <- 30
df_pathways_topn_heatmap <- df_pathways_topn_heatmap %>% 
  mutate(intensity = ifelse(NLQ > NLQ_threshold, NLQ_threshold, NLQ))
heatmap_limits <- c(2, NLQ_threshold)
heatmap_fill_lab <- "Enrichment (-log10(q))"

# Pathways ####

# Heatmap palette
heatmap_palette_cols <- brewer.pal(n = 9, name = "OrRd")
heatmap_palette <- colorRampPalette(colors = heatmap_palette_cols)(255)

fig_supp_12_pathways_legend_width_pt <- 50

# Generate heatmap of enrichment significance
fig_supp_12_pathways <- ggplot(df_pathways_topn_heatmap, 
                               aes(x = factor(k), 
                                   y = fct_rev(pathway), 
                                   fill = intensity)) + 
  geom_tile(col = "grey60") +
  facet_grid(pathway_cluster~nk, scales = "free", space = "free") + 
  scale_x_discrete(expand = expansion()) + 
  scale_y_discrete(expand = expansion(), 
                   position = "right") + 
  scale_fill_gradientn(colors = heatmap_palette,
                       limits = heatmap_limits,
                       na.value = "grey85",
                       guide = guide_colourbar(title.position = "top",
                                               title.hjust = 0.5,
                                               barwidth = unit(fig_supp_12_pathways_legend_width_pt, "bigpts"),
                                               barheight = unit(10, "bigpts"))) +
  labs(x = "Mouse cluster",
       y = "Biological pathway module",
       fill = heatmap_fill_lab) +
  theme_bw() +
  theme(strip.background = element_blank(),
        strip.text = element_blank(),
        panel.spacing = unit(4, "bigpts"),
        axis.title.x = element_text(size = font_size, family = font_family),
        axis.text.x = element_text(size = font_size-2, family = font_family),
        axis.ticks.x = element_line(size = 0.25),
        axis.title.y = element_text(size = font_size, family = font_family),
        axis.text.y = element_text(size = font_size-2, family = font_family), 
        axis.ticks.y = element_line(size = 0.25),
        legend.position = "bottom",
        legend.title = element_text(size = font_size-1, family = font_family),
        legend.text = element_text(size = font_size-1, family = font_family),
        legend.margin = margin(),
        plot.margin = margin(l = 0))

# Extract legend grob
fig_supp_12_pathways_legend_grob <- fig_supp_12_pathways %>%
  ggplotGrob() %>%
  grid.force() %>%
  getGrob("guides.3-3-3-3")

# Remove legend from ggplot object
fig_supp_12_pathways <- fig_supp_12_pathways +
  theme(legend.position = "none")

# Match ####

# Generate heatmap of mouse clusters with human matches
fig_supp_12_match <- ggplot(df_sig_nk,
                            mapping = aes(x = factor(k), 
                                          y = y, 
                                          fill = p,
                                          label = plab)) + 
  geom_tile(col = "grey50") +
  geom_text(col = "white",
            angle = 90,
            vjust = "middle",
            nudge_x = 0.1,
            family = font_family,
            size = font_size*0.36) + 
  facet_grid(.~nk, scales = "free", space = "free") + 
  scale_x_discrete(expand = expansion()) +
  scale_y_discrete(expand = expansion()) +
  scale_fill_gradientn(colors = rev(brewer.pal(n = 9, name = "PuBu")[c(1:4, 8)]),
                       guide = guide_colourbar(title.position = "top", 
                                               barwidth = unit(80, "bigpts"))) +
  labs(x = "Mouse cluster",
       fill = "Human-mouse equivalence (p-value)") +
  theme_bw() +
  theme(panel.spacing = unit(4, "bigpts"),
        strip.background.x = element_rect(fill = "grey90"),
        strip.text.x = element_text(size = font_size-1, family = font_family,
                                    margin = margin(b = 1, t = 1)),
        strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        legend.direction = "horizontal",
        legend.position = "bottom",
        legend.key.size = unit(10, "bigpts"),
        legend.title = element_text(size = font_size-1,
                                    family = font_family,
                                    hjust = 0.5),
        legend.text = element_text(size = font_size-1,
                                   family = font_family),
        legend.margin = margin(),
        plot.margin = margin(l = 0))

# Extract heatmap legend
fig_supp_12_match_legend_grob <- fig_supp_12_match %>%
  ggplotGrob() %>%
  grid.force() %>%
  getGrob("guides.3-3-3-3")

# Remove legend from ggplot object
fig_supp_12_match <- fig_supp_12_match +
  theme(legend.position = "none")
```

```{r fig-supp-12-patchwork}
# Patchwork #### 
fig_supp_12_patchwork <- (fig_supp_12_match / plot_spacer() / fig_supp_12_pathways) +
  plot_layout(heights = c(0.020, 0.005, 0.975)) &
  theme(plot.margin = margin(l = 0))
fig_supp_12_patchwork_grob <- patchworkGrob(fig_supp_12_patchwork)


# Grob ####

# Width of dendrogram panel in bigpts
fig_supp_12_dendrogram_width_pt <- 26

# Dimensions of heatmap patchwork in bigpts
fig_supp_12_patchwork_width_pt <- fig_width_pt - fig_supp_12_dendrogram_width_pt

# Heights of padding elements in bigpts
fig_supp_12_padding_height_1_pt <- 21
fig_supp_12_padding_height_2_pt <- 17

fig_supp_12_patchwork_height_pt <- fig_height_pt - fig_supp_12_padding_height_1_pt - fig_supp_12_padding_height_2_pt

# Dimensions of heatmap plot
fig_supp_12_widths <- c(fig_supp_12_dendrogram_width_pt, fig_supp_12_patchwork_width_pt)
fig_supp_12_heights <- c(fig_supp_12_padding_height_1_pt, 
                         fig_supp_12_patchwork_height_pt,
                         fig_supp_12_padding_height_2_pt)

# Layout of heatmap plot
fig_supp_12_layout <- rbind(c(01, 02),
                            c(03, 02),
                            c(04, 02))

# Grob grid for heatmap plot
fig_supp_12_grob <- arrangeGrob(zeroGrob(),
                                fig_supp_12_patchwork_grob,
                                fig_supp_12_dendrogram_grob,
                                zeroGrob(),
                                layout_matrix = fig_supp_12_layout,
                                widths = unit(fig_supp_12_widths, "bigpts"),
                                heights = unit(fig_supp_12_heights, "bigpts"))


fig_supp_12_width_pt <- fig_width_pt
fig_supp_12_height_pt <- fig_height_pt

# Viewport for pathways heatmap legend
fig_supp_12_pathways_legend_vp <- viewport(x = unit(fig_width_pt-12, "bigpts"),
                                           y = unit(35, "bigpts"),
                                           width = unit(fig_supp_12_pathways_legend_width_pt, "bigpts"),
                                           height = unit(22, "bigpts"),
                                           just = c("right", "bottom"))

# Viewport for human match heatmap legend
fig_supp_12_match_legend_vp_width <- 105
fig_supp_12_match_legend_vp_x <- fig_width_pt - fig_supp_12_match_legend_vp_width
fig_supp_12_match_legend_vp <- viewport(x = unit(fig_supp_12_match_legend_vp_x, "bigpts"),
                                        y = unit(fig_supp_12_height_pt-3, "bigpts"),
                                        width = unit(fig_supp_12_match_legend_vp_width, "bigpts"),
                                        height = unit(27, "bigpts"),
                                        just = c("left", "top"))

fig_supp_12_width_in <- fig_supp_12_width_pt/pt_per_in
fig_supp_12_height_in <- fig_supp_12_height_pt/pt_per_in

# Export
outfile <- paste(output_plot_prefix, 12, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(fig_supp_12_width_in, "in"),
    height = unit(fig_supp_12_height_in, "in"))
grid.draw(fig_supp_12_grob)
pushViewport(fig_supp_12_pathways_legend_vp)
grid.draw(fig_supp_12_pathways_legend_grob)
popViewport()
pushViewport(fig_supp_12_match_legend_vp)
grid.draw(fig_supp_12_match_legend_grob)
popViewport()
dev.off()
```


# Supplementary Figures 13-14: POND and HBN diagnosis Sankey diagrams

```{r fig-supp-13-14}
figure_id <- c(13, 14)
param_ids <- c("700", "013")
pipeline_dirs <- file.path(PROJECTPATH, "data/human/derivatives/v3/", param_ids)
demographics_files <- file.path(pipeline_dirs, "demographics.csv")
cluster_files <- file.path(pipeline_dirs, "clusters", "resolution_3.0", "clusters.csv")

df_diagnoses <- tibble(DX = c("ASD", 
                              "OCD", 
                              "ADHD", 
                              "Sub-threshold OCD", 
                              "Anxiety", 
                              "Sub-threshold ADHD",
                              "Intellectual Disability only",
                              "Tourette Syndrome",
                              "Other", 
                              "Fragile X"),
                       DX_new = c("ASD",
                                  "OCD",
                                  "ADHD",
                                  "OCD",
                                  "Other",
                                  "ADHD",
                                  "Other",
                                  "Other", 
                                  "Other", 
                                  "Other"))

diagnoses <- c("ASD", "ADHD", "OCD")

list_clusters_long <- vector(mode = "list", length = length(figure_id))
list_chi2 <- vector(mode = "list", length = length(figure_id))
for (i in 1:length(figure_id)) {
  
  demographics <- read_csv(demographics_files[i], show_col_types = FALSE)
  clusters <- read_csv(cluster_files[i], show_col_types = FALSE)
  
  demographics <- demographics %>% 
    filter(!is.na(DX),
           !is.na(Age),
           !is.na(Sex),
           !is.na(Site))
  
  clusters <- rename(clusters, file = ID)
  
  # Join demographics information to cluster assignments
  df_cluster_demographics <- clusters %>% 
    left_join(demographics, by = "file") %>% 
    left_join(df_diagnoses, by = "DX")
  
  # Extract diagnoses and convert cluster assignments to long format
  df_cluster_dx_long <- df_cluster_demographics %>% 
    select(ID = file, contains("nk"), DX = DX_new) %>% 
    pivot_longer(cols = c(-ID, -DX), 
                 names_to = "nk", 
                 values_to = "k") %>% 
    mutate(nk = str_remove(nk, "nk"),
           nk = as.numeric(nk),
           k = as.numeric(k)) %>% 
    unite(col = "cluster_id", nk, k, 
          sep = "-", remove = FALSE) %>% 
    select(ID, cluster_id, nk, k, DX)
  
  # Compute per cluster diagnostic proportions
  df_cluster_dx_freq <- df_cluster_dx_long %>%
    select(-ID) %>% 
    group_by(nk, k, DX) %>% 
    mutate(n_per_dx_per_k = n()) %>% 
    ungroup() %>% 
    distinct()
  
  df_cluster_freq <- df_cluster_dx_long %>% 
    select(-ID) %>% 
    group_by(cluster_id, nk, k) %>% 
    summarise(n_per_k = n(), 
              .groups = "drop")
  
  list_clusters_long[[i]] <- df_cluster_dx_long %>% 
    left_join(df_cluster_freq,
              by = c("cluster_id", "nk", "k"))
  
  # Cluster IDs in order
  cluster_ids <- df_cluster_freq %>% 
    arrange(nk, k) %>% 
    pull(cluster_id)
  
  # Full grid of cluster labels and diagnoses
  df_cluster_dx_grid <- expand_grid(cluster_id = cluster_ids,
                                    DX = diagnoses) %>% 
    separate(col = cluster_id, into = c("nk", "k"), 
             sep = "-", remove = FALSE) %>% 
    mutate(nk = as.numeric(nk),
           k = as.numeric(k))
  
  # Include diagnoses where cluster proportion is null
  df_cluster_dx_freq <- df_cluster_dx_freq %>% 
    right_join(df_cluster_dx_grid, 
               by = c("cluster_id", "nk", "k", "DX")) %>% 
    mutate(n_per_dx_per_k = ifelse(is.na(n_per_dx_per_k), 0, n_per_dx_per_k)) %>% 
    left_join(df_cluster_freq,
              by = c("cluster_id", "nk", "k")) %>% 
    mutate(prop_dx_per_k = n_per_dx_per_k/n_per_k)
  
  # Generate a grid of clusters and diagnoses
  df_chi2 <- expand_grid(nk = 2:nk_max,
                         DX = diagnoses) %>% 
    mutate(chi2 = 0, pval = 0)
  
  # Iterate over cluster-dx combinations
  for (r in 1:nrow(df_chi2)) {
    
    # Extract cluster nk and diagnosis
    nk_i <- df_chi2[[r, "nk"]]
    dx_i <- df_chi2[[r, "DX"]]
    
    # Format data to run a binary chi-squared test for the given diagnosis
    df_chi2_test <- df_cluster_dx_long %>% 
      filter(nk == nk_i) %>% 
      mutate(isDX = factor(DX == dx_i),
             k = factor(k))
    
    # Run the chi-squared test
    chi2 <- chisq.test(x = df_chi2_test[["k"]],
                       y = df_chi2_test[["isDX"]], 
                       simulate.p.value = TRUE, 
                       B = 1e5)
    
    # Assign the test values
    df_chi2[[r, "chi2"]] <- chi2[["statistic"]]
    df_chi2[[r, "pval"]] <- chi2[["p.value"]]
  }
  list_chi2[[i]] <- df_chi2
  
  # Data frame containing cluster DX proportions with patient IDs
  df_alluvial_all <- df_cluster_dx_freq %>%
    select(cluster_id, nk, k, DX, prop_dx_per_k) %>%
    pivot_wider(id = c(cluster_id, nk, k), 
                names_from = "DX", 
                values_from = "prop_dx_per_k") %>% 
    right_join(df_cluster_dx_long, 
               by = c("cluster_id", "nk", "k"))
  
  ymax <- df_alluvial_all %>% 
    pull(ID) %>% 
    unique() %>% 
    length() %>% 
    round(-2)
  
  # Iterate over diagnoses
  list_alluvials <- vector(mode = "list", length = length(diagnoses))
  list_pvals <- vector(mode = "list", length = length(diagnoses))
  for (j in 1:length(diagnoses)) {
    
    # Extract dx
    dx_i <- diagnoses[j]
    
    # Subset alluvial data frame for given dx
    df_alluvial_i <- df_alluvial_all %>% 
      rename(prop = contains(dx_i)) %>% 
      mutate(isDX = DX == dx_i,
             k = factor(k, levels = 1:nk_max))
    
    pvals_i <- df_chi2 %>% 
      filter(DX == dx_i) %>% 
      pull(pval)
    
    pvals_i <- sprintf("%.2f", pvals_i)
    pvals_i <- paste0("p = ", pvals_i)
    
    # Generate alluvial plot
    list_alluvials[[j]] <- ggplot(data = df_alluvial_i,
                                  mapping = aes(x = nk, 
                                                stratum = k, 
                                                alluvium = ID)) + 
      geom_flow(mapping = aes(alpha = isDX),
                stat = "alluvium", aes.flow = "forward",
                fill = "grey70",
                show.legend = FALSE) +
      scale_alpha_manual(values = c(0, 1)) +
      new_scale_fill() + 
      geom_stratum(mapping = aes(fill = prop),
                   size = 0.25) + 
      scale_fill_gradient(low = "white", high = "red",
                          limits = c(0, 1)) + 
      scale_x_continuous(breaks = seq(2, 10, by = 1),
                         sec.axis = dup_axis(labels = pvals_i)) +
      scale_y_continuous(breaks = seq(0, ymax, by = 100), 
                         minor_breaks = seq(0, ymax, by = 50),
                         expand = expansion(add = 20)) + 
      labs(x = "Number of clusters",
           y = "Number of patients",
           fill = "Proportion per cluster",
           title = dx_i) + 
      theme_bw()
    
  }
  
  # Combine p-values with alluvial
  plot_alluvials <- (list_alluvials[[1]] / list_alluvials[[2]] / list_alluvials[[3]]) +
    plot_layout(guides = "collect") &
    theme(plot.margin = margin(t = 2),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.title = element_text(size = font_size, family = font_family),
          axis.text = element_text(size = font_size, family = font_family),
          axis.ticks.x.top = element_blank(), 
          axis.title.x.top = element_blank(),
          legend.title = element_text(size = font_size, family = font_family),
          legend.text = element_text(size = font_size, family = font_family),
          plot.title = element_text(size = font_size+1, family = font_family))
  
  # Plot dimensions in bigpts
  fig_alluvial_width_pt <- 510
  fig_alluvial_height_pt <- 430
  
  # Plot dimensions in inches
  fig_alluvial_width_in <- fig_alluvial_width_pt/pt_per_in
  fig_alluvial_height_in <- fig_alluvial_height_pt/pt_per_in
  
  # Export plot
  outfile <- paste(output_plot_prefix, figure_id[i], sep = "_")
  outfile <- paste0(outfile, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(fig_alluvial_width_in, "in"),
      height = unit(fig_alluvial_height_in, "in"))
  print(plot_alluvials)
  dev.off()
  
}
```

```{r fig-supp-13-fdr}
list_chi2[[1]] %>% 
  group_by(DX) %>% 
  mutate(qval = p.adjust(pval, method = "fdr")) %>%
  summarise(fdr5 = sum(qval < 0.05),
            fdr10 = sum(qval < 0.10),
            fdr20 = sum(qval < 0.20))
```

```{r fig-supp-14-fdr}
list_chi2[[2]] %>% 
  group_by(DX) %>% 
  mutate(qval = p.adjust(pval, method = "fdr")) %>%
  summarise(fdr5 = sum(qval < 0.05),
            fdr10 = sum(qval < 0.10),
            fdr20 = sum(qval < 0.20))
```

```{r fig-supp-14-ASD-pvals}
list_chi2[[2]] %>% 
  filter(DX == "ASD") %>% 
  mutate(qval = p.adjust(pval, method = "fdr")) %>% 
  filter(qval < 0.05)
```

```{r fig-supp-14-ASD-props}
list_clusters_long[[2]] %>% 
  filter(DX == "ASD") %>% 
  group_by(nk, k, n_per_k) %>% 
  summarise(n_ASD = n(), 
            .groups = "drop") %>% 
  mutate(prop_ASD = n_ASD/n_per_k)  
```


# Supplementary Figures 15-16: Diagnostic proportion cluster numbers

```{r fig-supp-15-16}
figure_id <- c(15, 16)
for (i in 1:length(list_clusters_long)) {
  
  nmin <- seq(10, 50, by = 10)
  list_chi2 <- vector(mode = "list", length = length(nmin))
  for (l in 1:length(list_chi2)) {
    
    # Generate a grid of clusters and diagnoses
    df_chi2 <- expand_grid(nk = 2:nk_max,
                           DX = diagnoses) %>%  
      mutate(chi2 = 0, pval = 0, nmin = nmin[l])
    
    # Iterate over cluster-dx combinations
    for (r in 1:nrow(df_chi2)) {
      
      # Extract cluster nk and diagnosis
      nk_i <- df_chi2[[r, "nk"]]
      dx_i <- df_chi2[[r, "DX"]]
      
      # Format data to run a binary chi-squared test for the given diagnosis
      df_chi2_test <- list_clusters_long[[i]] %>% 
        filter(n_per_k > nmin[l],
               nk == nk_i) %>% 
        mutate(isDX = factor(DX == dx_i),
               k = factor(k))
      
      # Run the chi-squared test
      chi2 <- chisq.test(x = df_chi2_test[["k"]],
                         y = df_chi2_test[["isDX"]], 
                         simulate.p.value = TRUE, 
                         B = 1e5)
      
      # Assign the test values
      df_chi2[[r, "chi2"]] <- chi2[["statistic"]]
      df_chi2[[r, "pval"]] <- chi2[["p.value"]]
    }
    
    list_chi2[[l]] <- df_chi2
    
  }
  
  df_chi2_large <- bind_rows(list_chi2)
  
  fig_chi2_cluster_size <- df_chi2_large %>% 
    filter(DX != "Other") %>%
    mutate(nk = factor(nk),
           DX = factor(DX, levels = c("ASD", "ADHD", "OCD"))) %>% 
    ggplot(aes(x = nmin, y = pval, group = nk, col = nk)) + 
    geom_line(size = 0.4) + 
    geom_point(size = 0.75) +
    geom_hline(yintercept = 0.05, 
               linetype = "dashed",
               size = 0.4) + 
    facet_grid(.~DX) + 
    scale_x_continuous(breaks = nmin, minor_breaks = NULL) + 
    scale_y_continuous(breaks = seq(0, 1, by = 0.1)) + 
    labs(x = "Minimum cluster size",
         y = "p-value",
         col = "Number of clusters") + 
    theme_bw() +
    theme(axis.title = element_text(size = font_size, family = font_family),
          axis.text = element_text(size = font_size, family = font_family),
          legend.text = element_text(size = font_size, family = font_family),
          legend.title = element_text(size = font_size, family = font_family),
          strip.text = element_text(size = font_size, family = font_family))
  
  # Plot dimensions in bigpts
  fig_chi2_cluster_size_width_pt <- fig_width_pt
  fig_chi2_cluster_size_height_pt <- 200
  
  # Plot dimensions in inches
  fig_chi2_cluster_size_width_in <- fig_chi2_cluster_size_width_pt/pt_per_in
  fig_chi2_cluster_size_height_in <- fig_chi2_cluster_size_height_pt/pt_per_in
  
  # Export plot
  outfile <- paste(output_plot_prefix, figure_id[i], sep = "_")
  outfile <- paste0(outfile, ".pdf")
  outfile <- file.path(output_dir, outfile)
  pdf(file = outfile,
      width = unit(fig_chi2_cluster_size_width_in, "in"),
      height = unit(fig_chi2_cluster_size_height_in, "in"))
  print(fig_chi2_cluster_size)
  dev.off()
  
}
```

# Supplementary Figure 17: PLS-DA loadings 

Execute 'figure_supp.ipynb'

```{r fig-supp-17-import}
# List of cluster comparisons used for PLS-DA
plsda_comparisons <- list(c("7-4", "7-7"),
                          c("8-7", "8-4"),
                          c("9-4", "9-5"),
                          c("10-4", "10-6"))

# Import PLSDA scores
plsda_scores <- map_chr(plsda_comparisons, str_flatten, collapse = "_")
plsda_scores <- paste("plsda", plsda_scores, "scores", sep = "_")
plsda_scores <- paste0(plsda_scores, ".csv")
plsda_scores <- file.path(output_dir, plsda_scores)
list_scores <- map(plsda_scores, read_csv, show_col_types = FALSE)

# Import PLSDA loadings
plsda_loadings <- map_chr(plsda_comparisons, str_flatten, collapse = "_")
plsda_loadings <- paste("plsda", plsda_loadings, "loadings", sep = "_")
plsda_loadings <- paste0(plsda_loadings, ".csv")
plsda_loadings <- file.path(output_dir, plsda_loadings)
list_loadings <- map(plsda_loadings, read_csv, show_col_types = FALSE)

# New names for features
df_features <- tibble(features = c("CB68IPTS", "CB68EPTS", 
                                   "AB21GCCS", 
                                   "OWL2LCSS", "OWL2OESS", "OWL2OLCSS", 
                                   "RBSALLT", "SCQTOT",
                                   "ADHD_I_SUB", "ADHD_HI_SUB",
                                   "TPOCS_TOT", "FSIQ"),
                      features_new = c("CBCL-IP", "CBCL-EP", 
                                       "ABAS-II", 
                                       "OWL2-LC", "OWL2-OE", "OWL2-OLC", 
                                       "RBS-R", "SCQ",
                                       "SWAN-I", "SWAN-HI",
                                       "TOCS", "FSIQ"))

# Rename features
list_loadings <- map(list_loadings, function(x){
  x %>% 
    inner_join(df_features, by = "features") %>% 
    select(-features) %>% 
    rename(features = features_new)  
})

# Flip x-axis for first plot
list_loadings[[1]][["x"]] <- -1*list_loadings[[1]][["x"]]

# Import PLS-DA results
plsda_results <- "figure_supplementary/plsda_results.csv"
df_plsda_results <- read_csv(plsda_results, show_col_types = FALSE)

# Get AUC values for comparisons
plsda_auc <- numeric(length(plsda_comparisons))
for (i in 1:length(plsda_comparisons)) {
  plsda_auc[i] <- df_plsda_results %>% 
    filter(cluster_id_1 == sort(plsda_comparisons[[i]])[[1]],
           cluster_id_2 == sort(plsda_comparisons[[i]])[[2]],
           components == 2, threshold == 0.6) %>% 
    pull(auc)
}
```

```{r fig-supp-17}
# Palette based on Figure 4
palette <- c("seagreen2", "sienna2")

# Lists for different figure components
list_plots_scatter <- vector(mode = "list", length = length(list_scores))
list_plots_histx <- vector(mode = "list", length = length(list_scores))
list_plots_histy <- vector(mode = "list", length = length(list_scores))
list_patchworks <- vector(mode = "list", length = length(list_scores))

# List of x limits
list_xlims <- list(c(-4.5, 3.8),
                   c(-4.2, 4.0),
                   c(-4.5, 4.5),
                   c(-4.5, 4.5))

# List of y limits
list_ylims <- list(c(-3.0, 4.0),
                   c(-3.0, 3.5),
                   c(-3.5, 4.0),
                   c(-3.5, 4.0))

# AUC labels
auc_labels <- paste("AUC", "=", sprintf("%.2f", plsda_auc))

# AUC positions
auc_positions = list(c(-3.5, -2.5),
                     c(-3.0, -2.5),
                     c(-3.5, -3.0),
                     c(-3.5, -3.0))

# List of nudge values for loading vectors
# 1: CB68IPTS, 2: CB68EPTS, 3: AB21GCCS, 4: OWL2LCSS, 5: OWL2OESS, 6: OWL2OLCSS, 7: RBSALLT, 8: SCQTOT, 9: ADHD_I_SUB, 10: ADHD_HI_SUB, 11: TPOCS_TOT, 12: FSIQ
list_loadings_nudge <- list(tibble(x = c( 0.8,  0.0, 0.0, -0.8, -0.8, -0.8,  0.3,  0.0, 0.6, 0.0, -0.20, -0.5),
                                   y = c( 0.1,  0.2, 0.2,  0.2,  0.0, -0.1, -0.2, -0.2, 0.0, 0.2,  0.20,  0.0)),
                            tibble(x = c(-0.2,  0.7, 0.0, -0.8, -0.8,  0.0,  0.2,  0.0, 0.7, 0.7, -0.55, -0.5),
                                   y = c(-0.1,  0.2, 0.2,  0.1, -0.1,  0.2, -0.2, -0.2, 0.0, 0.2,  0.00,  0.0)),
                            tibble(x = c( 0.0,  0.8, 0.0, -0.8, -0.8,  0.0,  0.2,  0.0, 0.7, 0.7, -0.40, -0.5),
                                   y = c(-0.2,  0.0, 0.2,  0.1, -0.1,  0.2, -0.2, -0.2, 0.0, 0.2,  0.20,  0.0)),
                            tibble(x = c(-0.8, -0.2, 0.0, -0.8, -0.8, -0.6,  0.3,  0.0, 0.4, 0.4, -0.50, -0.5),
                                   y = c( 0.0,  0.3, 0.2,  0.1, -0.2,  0.2, -0.2, -0.2, 0.2, 0.2,  0.00,  0.0)))

# Axis breaks
xbreaks <- seq(-10, 10, by = 1)
ybreaks <- xbreaks

# Theme for scatter plots
theme_scatter <- theme_bw() +
  theme(legend.position = c(1.15, 1.16),
        axis.title = element_text(size = font_size),
        axis.text = element_text(size = font_size),
        legend.title = element_text(size = font_size+1,
                                    margin = margin()),
        legend.text = element_text(size = font_size,
                                   margin = margin()),
        legend.margin = margin(),
        plot.margin = margin())

# Theme for histograms
theme_hist <- theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.spacing = unit(0, "pt"),
        plot.margin = margin())

# Patchwork layout
patchwork_design <- '12
34
'

# Iterate over PLSDA comparisons
for (i in 1:length(list_scores)) {
  
  # Get scores and loadings
  df_scores <- list_scores[[i]]
  df_loadings <- list_loadings[[i]]
  df_loadings_nudge <- list_loadings_nudge[[i]]
  
  # Set cluster factor levels
  df_scores <- df_scores %>% 
    mutate(cluster = factor(cluster, levels = plsda_comparisons[[i]]))
  
  # Create scatter plot
  list_plots_scatter[[i]] <- ggplot(df_scores, mapping = aes(x = x, y = y, col = cluster)) + 
    geom_point() + 
    annotate("segment",
             x = 0, y = 0,
             xend = df_loadings$x,
             yend = df_loadings$y,
             arrow = arrow(type = "closed", length = unit(0.02, "npc")),
             size = 0.1,
             col = "grey30") +
    annotate("text",
             x = df_loadings$x + df_loadings_nudge$x,
             y = df_loadings$y + df_loadings_nudge$y,
             label = df_loadings$features,
             size = (font_size-1)*0.36) +
    annotate("label",
             x = auc_positions[[i]][[1]],
             y = auc_positions[[i]][[2]],
             label = auc_labels[[i]],
             size = (font_size)*0.36) + 
    coord_cartesian(xlim = list_xlims[[i]],
                    ylim = list_ylims[[i]]) +
    scale_x_continuous(breaks = xbreaks) + 
    scale_y_continuous(breaks = ybreaks) + 
    scale_colour_manual(values = palette) + 
    labs(x = "Latent variable 1",
         y = "Latent variable 2", 
         col = "Cluster") + 
    theme_scatter
  
  # Create x marginal histogram
  list_plots_histx[[i]] <- ggplot(df_scores, aes(x = x, col = cluster, fill = cluster)) + 
    geom_histogram(position = "dodge", binwidth = 0.5) +
    coord_cartesian(xlim = list_xlims[[i]]) + 
    scale_x_continuous(breaks = xbreaks, labels = NULL, guide = "none") + 
    scale_colour_manual(values = palette, guide = "none") + 
    scale_fill_manual(values = palette, guide = "none") + 
    theme_hist +
    theme(plot.margin = margin(b = -5))
  
  # Create y marginal histogram
  list_plots_histy[[i]] <- ggplot(df_scores, aes(x = y, col = cluster, fill = cluster)) + 
    geom_histogram(position = "dodge", binwidth = 0.5) +
    coord_flip(xlim = list_ylims[[i]]) +
    scale_x_continuous(breaks = ybreaks) + 
    scale_colour_manual(values = palette, guide = "none") + 
    scale_fill_manual(values = palette, guide = "none") +
    theme_hist +
    theme(plot.margin = margin(l = -10),
          panel.spacing = unit(-5, "pt"))
  
  # Generate patchwork for current comparison
  list_patchworks[[i]] <- (list_plots_histx[[i]] + plot_spacer()+ list_plots_scatter[[i]] + list_plots_histy[[i]]) +
    plot_layout(widths = c(4, 1), heights = c(1,4), design = patchwork_design)
}


# Padding width
fig_supp_17_padding_width <- 0.010

# Individual plot width
fig_supp_17_plot_width <- (1 - fig_supp_17_padding_width)/2

# Plot title height
fig_supp_17_title_height <- 0.04

# Individual plot height
fig_supp_17_plot_height <- fig_supp_17_plot_width - fig_supp_17_title_height

# Grid panel widths
fig_supp_17_widths <- c(fig_supp_17_plot_width, fig_supp_17_padding_width, fig_supp_17_plot_width)

# Grid panel heights
fig_supp_17_heights <- c(fig_supp_17_title_height, fig_supp_17_plot_height, 
                         fig_supp_17_padding_width, 
                         fig_supp_17_title_height, fig_supp_17_plot_height)

# Grid panel titles
nk_labels <- paste("K", "=", 7:10)
list_label_grobs <- map(.x = nk_labels, .f = function(x) {
  gTree(children = gList(rectGrob(gp = gpar(fill = "grey85",
                                            col = "grey30",
                                            lwd = 1)),
                         textGrob(label = x, gp = gpar(fontsize = font_size+1,
                                                       fontfamily = font_family))))
})

# Grid grob
fig_supp_17_grob <- arrangeGrob(list_label_grobs[[1]],
                                zeroGrob(),
                                list_label_grobs[[2]],
                                patchworkGrob(list_patchworks[[1]]), 
                                # rectGrob(),
                                zeroGrob(),
                                patchworkGrob(list_patchworks[[2]]),
                                # rectGrob(),
                                zeroGrob(),
                                list_label_grobs[[3]],
                                zeroGrob(),
                                list_label_grobs[[4]],
                                patchworkGrob(list_patchworks[[3]]), 
                                zeroGrob(),
                                # rectGrob(),
                                patchworkGrob(list_patchworks[[4]]), 
                                layout_matrix = rbind(c(01, 02, 03),
                                                      c(04, 05, 06),
                                                      c(07, 07, 07),
                                                      c(08, 09, 10),
                                                      c(11, 12, 13)),
                                widths = fig_supp_17_widths,
                                heights = fig_supp_17_heights)

# Plot dimensions in bigpts
fig_supp_17_width_pt <- fig_width_pt
fig_supp_17_height_pt <- fig_height_pt

# Plot dimensions in inches
fig_supp_17_width_in <- fig_supp_17_width_pt/pt_per_in
fig_supp_17_height_in <- fig_supp_17_height_pt/pt_per_in

# Export
outfile <- paste(output_plot_prefix, 17, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(fig_supp_17_width_in, "in"),
    height = unit(fig_supp_17_height_in, "in"))
grid.draw(fig_supp_17_grob)
dev.off()
```


# Supplementary Figure 18: PLS-DA results 

Execute 'figure_supp.ipynb'

```{r fig-supp-18-prep}
# Import PLS-DA results
plsda_results <- "figure_supplementary/plsda_results.csv"
df_plsda_results <- read_csv(plsda_results, show_col_types = FALSE)

# Identify which POND clusters have mouse matches
df_cluster_matches <- df_sim_pvals_POND %>% 
  group_by(human_nk, human_k) %>% 
  summarise(nsignificant = sum(significant),
            .groups = "drop") %>% 
  mutate(has_match = nsignificant > 0) %>% 
  unite(col = "cluster_id", human_nk, human_k, sep = "-", remove = FALSE)

# Cluster levels
cluster_lvls <- df_cluster_matches %>% 
  select(cluster_id, human_nk, human_k) %>% 
  distinct() %>% 
  arrange(human_nk, human_k) %>% 
  pull(cluster_id) 

# Clusters with mouse match
clusters_w_match <- df_cluster_matches %>% 
  filter(has_match) %>% 
  pull(cluster_id)

# Update PLSDA data frame with cross-species information
df_plsda_results <- df_plsda_results %>% 
  mutate(has_match_1 = cluster_id_1 %in% clusters_w_match,
         has_match_2 = cluster_id_2 %in% clusters_w_match,
         matches = case_when((has_match_1 & has_match_2) ~ "Both",
                             (has_match_1 | has_match_2) ~ "One",
                             (!has_match_1 & !has_match_2) ~ "Neither"),
         small_group = (participants_1 < 20 | participants_2 < 20)) %>% 
  unite(col = "comparison", cluster_id_1, cluster_id_2, sep = " vs. ", remove = FALSE)  

# Get PLSDA comparison levels
comparison_lvls <- df_plsda_results %>% 
  select(cluster_id_1, cluster_id_2) %>% 
  separate(cluster_id_1, into = c("nk_1", "k_1"), remove = FALSE) %>% 
  separate(cluster_id_2, into = c("nk_2", "k_2"), remove = FALSE) %>% 
  mutate(nk_1 = as.numeric(nk_1),
         nk_2 = as.numeric(nk_2),
         k_1 = as.numeric(k_1),
         k_2 = as.numeric(k_2)) %>% 
  unite(col = "comparison", cluster_id_1, cluster_id_2, sep = " vs. ") %>% 
  distinct() %>% 
  arrange(nk_1, k_1, nk_2, k_2) %>% 
  pull(comparison)

# Summarize AUC values
df_plsda_summary <- df_plsda_results %>% 
  group_by(nk, comparison, cluster_id_1, cluster_id_2, threshold, small_group, matches, has_match_1, has_match_2) %>% 
  summarise(auc_mean = mean(auc), 
            auc_min = min(auc),
            auc_max = max(auc),
            .groups = "drop") %>% 
  mutate(comparison = factor(comparison, levels = comparison_lvls))
```

```{r fig-supp-18-colours}
df_sig_matches <- df_sim_pvals_POND %>% 
  filter(significant == 1)

mouse_colours <- c("4-1", "darkorchid1",
                   "4-3", "sienna2",
                   "4-4", "springgreen4",
                   "5-1", "springgreen4",
                   "5-4", "darkorchid1",
                   "5-5", "seagreen2",
                   "6-1", "springgreen4",
                   "6-4", "seagreen2",
                   "6-5", "darkorchid1",
                   "7-1", "springgreen4",
                   "7-4", "seagreen2",
                   "7-7", "darkorchid1",
                   "8-1", "springgreen4",
                   "8-2", "seagreen2",
                   "8-5", "sienna2",
                   "8-6", "darkorchid1",
                   "9-4", "sienna2",
                   "9-5", "seagreen2",
                   "10-3", "sienna2",
                   "10-4", "darkorchid1",
                   "10-5", "seagreen2")

mouse_colours <- matrix(mouse_colours, ncol = 2, byrow = TRUE)
colnames(mouse_colours) <- c("mouse_cluster_id", "colour")

df_mouse_colours <- as_tibble(mouse_colours)

df_sig_matches <- df_sig_matches %>% 
  left_join(df_mouse_colours, by = "mouse_cluster_id")

df_human_colours <- df_sim_pvals_POND %>%  
  select(human_cluster_id) %>% 
  distinct() %>% 
  mutate(colour = "")

for (i in 1:nrow(df_human_colours)) {
  
  cluster_id <- df_human_colours[[i, "human_cluster_id"]]
  
  colours <- df_sig_matches %>% 
    filter(human_cluster_id == cluster_id) %>% 
    pull(colour)
  
  colours <- colours[!is.na(colours)] 
  colours <- unique(colours)
  
  if (length(colours) == 0) {
    df_human_colours[[i, "colour"]] <- "black"
  } else if (length(colours) > 1) {
    if (i == 21) {
      df_human_colours[[i, "colour"]] <- "darkorchid1"
    } else if (i == 28) {
      df_human_colours[[i, "colour"]] <- "darkorchid1"
    } else if (i == 40) {
      df_human_colours[[i, "colour"]] <- "sienna2"
    } else {
      print(i)
      stop()
    }
  } else {
    df_human_colours[[i, "colour"]] <- colours
  }
  
}

# "darkorchid1"
# "seashell4"
# "sienna2"
# "springgreen4"
# "seagreen2"
```

```{r fig-supp-18}
# Range of cluster solutions
nk_range <- df_plsda_summary %>% 
  pull(nk) %>% 
  unique() %>% 
  sort()

# Iterate over cluster solutions
list_plots <- vector(mode = "list", length = length(nk_range))
for (i in 1:length(list_plots)) {
  
  # Data frame of axis parameters
  axis_params <- df_plsda_summary %>% 
    select(nk, comparison, cluster_id_1, cluster_id_2, 
           matches, has_match_1, has_match_2) %>% 
    distinct() %>% 
    filter(nk == nk_range[i]) %>% 
    arrange(desc(comparison)) %>% 
    left_join(df_human_colours, by = c("cluster_id_1" = "human_cluster_id")) %>% 
    rename(fontcolour_1 = colour) %>% 
    left_join(df_human_colours, by = c("cluster_id_2" = "human_cluster_id")) %>% 
    rename(fontcolour_2 = colour) %>% 
    mutate(fontface = ifelse(matches == "Both", "bold", "plain"),
           fontcolour = ifelse(matches == "Both", "black", "grey30"),
           fontface_1 = ifelse(has_match_1, "bold", "plain"),
           fontface_2 = ifelse(has_match_2, "bold", "plain"),
           ybreaks = as.numeric(fct_rev(comparison)))
  
  if (nk_range[i] %in% 2:4) {
    yexpansion <- expansion(add = 1)
  } else if (nk_range[i] %in% 5:7) {
    yexpansion <- expansion(add = 1)
  } else {
    yexpansion <- expansion(add = 1)
  }
  
  # Generate plot for current nk
  plt <- df_plsda_summary %>% 
    filter(nk %in% nk_range[i]) %>% 
    ggplot(aes(x = as.numeric(fct_rev(comparison)), 
               y = auc_mean, 
               ymin = auc_min, 
               ymax = auc_max,
               col = factor(threshold),
               alpha = small_group,
               size = small_group)) + 
    geom_linerange(size = 0.30) + 
    geom_point() + 
    facet_wrap(~nk, ncol = 1, scales = "free_y") +
    coord_flip(ylim = c(0.5, 1.0)) +
    scale_x_continuous(breaks = axis_params$ybreaks,
                       labels = axis_params$cluster_id_1,
                       sec.axis = dup_axis(labels = axis_params$cluster_id_2),
                       expand = yexpansion) + 
    scale_alpha_manual(values = c(1.0, 0.4), guide = "none") + 
    scale_size_manual(values = c(1.2, 0.8), guide = "none") + 
    labs(y = "AUC",
         x = "Cluster comparison",
         col = "Completion threshold") + 
    theme_bw() +
    theme(axis.text.y.left  = element_text(size = font_size-2, 
                                           family = font_family,
                                           face = axis_params$fontface_1,
                                           color = axis_params$fontcolour_1),
          axis.text.y.right  = element_text(size = font_size-2, 
                                            family = font_family,
                                            face = axis_params$fontface_2,
                                            color = axis_params$fontcolour_2),
          axis.text.x = element_text(size = font_size-2,
                                     family = font_family),
          axis.title.x = element_text(size = font_size),
          axis.title.y = element_blank(),
          axis.ticks = element_line(size = 0.3),
          panel.grid.minor.y = element_blank(),
          strip.text = element_text(size = font_size, 
                                    margin = margin(t = 2, b = 2)),
          plot.margin = margin(t = 1, b = 1, l = 5, r = 5))
  
  # Options for specific nk
  if (!(nk_range[i] %in% 8:10)) {
    plt <- plt +
      theme(axis.title.x = element_blank())
  }
  
  if (i != 8) {
    list_plots[[i]] <- plt +
      theme(legend.position = "none")
    
  } else {
    list_plots[[i]] <- plt +
      theme(legend.position = "bottom",
            legend.direction = "horizontal",
            legend.title = element_text(size = font_size, margin = margin()),
            legend.text = element_text(size = font_size, margin = margin()),
            legend.margin = margin(),
            legend.box.margin = margin(t = -10))
  }
}

# Generate patchwork
p_plsda_summary <- ((list_plots[[1]] | list_plots[[2]] | list_plots[[3]]) /
                      (list_plots[[4]] | list_plots[[5]] | list_plots[[6]]) /
                      (list_plots[[7]] | list_plots[[8]] | list_plots[[9]])) +
  plot_layout(heights = c(0.15,0.60,1.20))

# Plot dimensions in bigpts
width_pt <- fig_width_pt
height_pt <- fig_height_pt

# Plot dimensions in inches
width_in <- width_pt/pt_per_in
height_in <- height_pt/pt_per_in

# Export
outfile <- paste(output_plot_prefix, 18, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(width_in, "in"),
    height = unit(height_in, "in"))
print(p_plsda_summary)
dev.off()
```

```{r eval = FALSE}
nk_range <- df_plsda_summary %>% 
  pull(nk) %>% 
  unique() %>% 
  sort()

list_plots <- vector(mode = "list", length = length(nk_range))
for (i in 1:length(list_plots)) {
  axis_params <- df_plsda_summary %>% 
    select(nk, comparison, matches) %>% 
    distinct() %>% 
    filter(nk == nk_range[i]) %>% 
    arrange(desc(comparison)) %>% 
    mutate(fontface = ifelse(matches == "Both", "bold", "plain"),
           fontcolour = ifelse(matches == "Both", "black", "grey30"))
  
  plt <- df_plsda_summary %>% 
    filter(nk %in% nk_range[i]) %>% 
    ggplot(aes(x = fct_rev(comparison), 
               y = auc_mean, 
               ymin = auc_min, 
               ymax = auc_max,
               col = factor(threshold),
               alpha = small_group,
               size = small_group)) + 
    geom_linerange(size = 0.30) + 
    geom_point() + 
    facet_wrap(~nk, ncol = 1, scales = "free_y") +
    coord_flip(ylim = c(0.5, 1.0)) +
    scale_alpha_manual(values = c(1.0, 0.4), guide = "none") + 
    scale_size_manual(values = c(1.2, 0.8), guide = "none") + 
    labs(y = "AUC",
         x = "Cluster comparison",
         col = "Completion threshold") + 
    theme_bw() +
    theme(axis.text.y = element_text(size = font_size-2, 
                                     family = font_family,
                                     face = axis_params$fontface,
                                     color = axis_params$fontcolour),
          axis.text.x = element_text(size = font_size-2,
                                     family = font_family),
          axis.title = element_text(size = font_size),
          axis.ticks = element_line(size = 0.3),
          strip.text = element_text(size = font_size, 
                                    margin = margin(t = 2, b = 2)),
          plot.margin = margin(t = 1, b = 1, l = 3, r = 2))
  
  if (!(nk_range[i] %in% c(2, 5, 8))) {
    plt <- plt +
      theme(axis.title.y = element_blank())
  }
  
  if (!(nk_range[i] %in% 8:10)) {
    plt <- plt +
      theme(axis.title.x = element_blank())
  }
  
  if (i != 8) {
    list_plots[[i]] <- plt +
      theme(legend.position = "none")
    
  } else {
    list_plots[[i]] <- plt +
      theme(legend.position = "bottom",
            legend.direction = "horizontal",
            legend.title = element_text(size = font_size, margin = margin()),
            legend.text = element_text(size = font_size, margin = margin()),
            legend.margin = margin(),
            legend.box.margin = margin(t = -10))
  }
}

p_plsda_summary <- ((list_plots[[1]] | list_plots[[2]] | list_plots[[3]]) /
                      (list_plots[[4]] | list_plots[[5]] | list_plots[[6]]) /
                      (list_plots[[7]] | list_plots[[8]] | list_plots[[9]])) +
  plot_layout(heights = c(0.15,0.60,1.20))

# Plot dimensions in bigpts
width_pt <- fig_width_pt
height_pt <- fig_height_pt

# Plot dimensions in inches
width_in <- width_pt/pt_per_in
height_in <- height_pt/pt_per_in

outfile <- "plsda_summary_1.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(width_in, "in"),
    height = unit(height_in, "in"))
print(p_plsda_summary)
dev.off()
```


# Supplementary Figure 19: Comparison of clusters with matches vs. those without

Execute 'figure_supp.ipynb'

```{r}
nk_range = 7:10

plsda_scores <- str_c("plsda_matches_vs_not_nk", nk_range, "_scores.csv")
plsda_scores <- file.path(output_dir, plsda_scores)
list_scores <- map(plsda_scores, read_csv, show_col_types = FALSE)

plsda_loadings <- str_c("plsda_matches_vs_not_nk", nk_range, "_loadings.csv")
plsda_loadings <- file.path(output_dir, plsda_loadings)
list_loadings <- map(plsda_loadings, read_csv, show_col_types = FALSE)

# New names for features
df_features <- tibble(features = c("CB68IPTS", "CB68EPTS", 
                                   "AB21GCCS", 
                                   "OWL2LCSS", "OWL2OESS", "OWL2OLCSS", 
                                   "RBSALLT", "SCQTOT",
                                   "ADHD_I_SUB", "ADHD_HI_SUB",
                                   "TPOCS_TOT", "FSIQ"),
                      features_new = c("CBCL-IP", "CBCL-EP", 
                                       "ABAS-II", 
                                       "OWL2-LC", "OWL2-OE", "OWL2-OLC", 
                                       "RBS-R", "SCQ",
                                       "SWAN-I", "SWAN-HI",
                                       "TOCS", "FSIQ"))

# Rename features
list_loadings <- map(list_loadings, function(x){
  x %>% 
    inner_join(df_features, by = "features") %>% 
    select(-features) %>% 
    rename(features = features_new)  
})

# Import PLS-DA results
plsda_results <- "figure_supplementary/plsda_matches_vs_not_results.csv"
df_plsda_results <- read_csv(plsda_results, show_col_types = FALSE)

# Get AUC values for comparisons
plsda_auc <- numeric(length(nk_range))
for (i in 1:length(nk_range)) {
  plsda_auc[i] <- df_plsda_results %>% 
    filter(nk == nk_range[i],
           components == 2) %>% 
    pull(auc)
}
```

```{r}
# Palette based on Figure 4
# palette <- c("seagreen2", "sienna2")
palette <- c("grey70", "firebrick3")

# Lists for different figure components
list_plots_scatter <- vector(mode = "list", length = length(list_scores))
list_plots_histx <- vector(mode = "list", length = length(list_scores))
list_plots_histy <- vector(mode = "list", length = length(list_scores))
list_patchworks <- vector(mode = "list", length = length(list_scores))

# List of x limits
list_xlims <- list(c(-5.0, 5.0),
                   c(-4.5, 4.5),
                   c(-4.0, 5.0),
                   c(-4.0, 4.0))

# List of y limits
list_ylims <- list(c(-4.0, 4.0),
                   c(-4.5, 4.0),
                   c(-5.0, 4.0),
                   c(-3.0, 3.5))

# AUC labels
auc_labels <- paste("AUC", "=", sprintf("%.2f", plsda_auc))

# AUC positions
auc_positions = list(c(-3.5, 3.75),
                     c(-3.5, 3.75),
                     c(-3.0, 3.75),
                     c(-3.0, 3.0))

# List of nudge values for loading vectors
# 1: CB68IPTS, 2: CB68EPTS, 3: AB21GCCS, 4: OWL2LCSS, 5: OWL2OESS, 6: OWL2OLCSS, 7: RBSALLT, 8: SCQTOT, 9: ADHD_I_SUB, 10: ADHD_HI_SUB, 11: TPOCS_TOT, 12: FSIQ
list_loadings_nudge <- list(tibble(x = c( 0.0, -0.2,  0.7, -0.0,  1.0,  1.0,  0.0,  0.0,  0.0, -0.8, -0.0,  0.5),
                                   y = c(-0.3,  0.2,  0.0,  0.4,  0.0, -0.0, -0.3, -0.3,  0.2,  0.0, -0.2,  0.0)),
                            tibble(x = c(-0.0,  0.0, -0.3,  1.0, -0.0, -1.1,  0.0, -0.3,  0.0,  0.0,  0.5,  0.6),
                                   y = c(-0.2, -0.2,  0.3,  0.2,  0.3,  0.0, -0.3, -0.3, -0.3,  0.3,  0.0, -0.1)),
                            tibble(x = c( 0.0,  0.9,  0.0,  0.8, -0.6,  0.8, -0.7, -0.6,  0.0,  0.8, -0.5, -0.6),
                                   y = c( 0.2,  0.0,  0.2,  0.0,  0.3,  0.3, -0.0, -0.0, -0.4,  0.0,  0.0,  0.0)),
                            tibble(x = c( 0.6, -0.5, -0.7,  0.7,  0.8, -0.0,  0.5,  0.4, -0.8, -0.8,  0.4,  0.0),
                                   y = c( 0.1,  0.2,  0.0, -0.2, -0.0,  0.3, -0.2, -0.0, -0.1, -0.1,  0.0, -0.3)))
# df_tmp <- tibble(x = rep(0, nrow(df_features)),
#                  y = rep(0, nrow(df_features)))
# list_loadings_nudge <- list(df_tmp, df_tmp, df_tmp, df_tmp)

# Axis breaks
xbreaks <- seq(-10, 10, by = 1)
ybreaks <- xbreaks

# Theme for scatter plots
theme_scatter <- theme_bw() +
  theme(legend.position = c(1.15, 1.16),
        axis.title = element_text(size = font_size),
        axis.text = element_text(size = font_size),
        legend.title = element_text(size = font_size+1,
                                    margin = margin()),
        legend.text = element_text(size = font_size,
                                   margin = margin()),
        legend.margin = margin(),
        plot.margin = margin())

# Theme for histograms
theme_hist <- theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.spacing = unit(0, "pt"),
        plot.margin = margin())

# Patchwork layout
patchwork_design <- '12
34
'

# Iterate over PLSDA comparisons
for (i in 1:length(list_scores)) {
  
  # Get scores and loadings
  df_scores <- list_scores[[i]]
  df_loadings <- list_loadings[[i]]
  df_loadings_nudge <- list_loadings_nudge[[i]]
  
  # Set cluster factor levels
  df_scores <- df_scores %>% 
    mutate(cluster = str_to_sentence(cluster),
           cluster = factor(cluster, levels = c("No match", "Match")))
  
  # Create scatter plot
  list_plots_scatter[[i]] <- ggplot(df_scores, mapping = aes(x = x, y = y, fill = cluster)) + 
    geom_point(size = 1.0,
               shape = 21,
               col = "black",
               stroke = 0.1) + 
    annotate("segment",
             x = 0, y = 0,
             xend = df_loadings$x,
             yend = df_loadings$y,
             arrow = arrow(type = "closed", length = unit(0.02, "npc")),
             size = 0.1,
             col = "grey30") +
    annotate("text",
             x = df_loadings$x + df_loadings_nudge$x,
             y = df_loadings$y + df_loadings_nudge$y,
             label = df_loadings$features,
             size = (font_size-1)*0.36) +
    annotate("label",
             x = auc_positions[[i]][[1]],
             y = auc_positions[[i]][[2]],
             label = auc_labels[[i]],
             size = (font_size)*0.36) + 
    coord_cartesian(xlim = list_xlims[[i]],
                    ylim = list_ylims[[i]]) +
    scale_x_continuous(breaks = xbreaks) + 
    scale_y_continuous(breaks = ybreaks) + 
    scale_colour_manual(values = palette) +
    scale_fill_manual(values = palette) +
    labs(x = "Latent variable 1",
         y = "Latent variable 2", 
         col = NULL) + 
    theme_scatter
  
  # Create x marginal histogram
  list_plots_histx[[i]] <- ggplot(df_scores, aes(x = x, col = cluster, fill = cluster)) + 
    geom_histogram(position = "dodge", binwidth = 0.5) +
    coord_cartesian(xlim = list_xlims[[i]]) + 
    scale_x_continuous(breaks = xbreaks, labels = NULL, guide = "none") + 
    scale_colour_manual(values = palette, guide = "none") + 
    scale_fill_manual(values = palette, guide = "none") + 
    theme_hist +
    theme(plot.margin = margin(b = -5))
  
  # Create y marginal histogram
  list_plots_histy[[i]] <- ggplot(df_scores, aes(x = y, col = cluster, fill = cluster)) + 
    geom_histogram(position = "dodge", binwidth = 0.5) +
    coord_flip(xlim = list_ylims[[i]]) +
    scale_x_continuous(breaks = ybreaks) + 
    scale_colour_manual(values = palette, guide = "none") + 
    scale_fill_manual(values = palette, guide = "none") +
    theme_hist +
    theme(plot.margin = margin(l = -10),
          panel.spacing = unit(-5, "pt"))
  
  # Generate patchwork for current comparison
  list_patchworks[[i]] <- (list_plots_histx[[i]] + plot_spacer()+ list_plots_scatter[[i]] + list_plots_histy[[i]]) +
    plot_layout(widths = c(4, 1), heights = c(1,4), design = patchwork_design)
}


# Padding width
fig_supp_19_padding_width <- 0.010

# Individual plot width
fig_supp_19_plot_width <- (1 - fig_supp_19_padding_width)/2

# Plot title height
fig_supp_19_title_height <- 0.04

# Individual plot height
fig_supp_19_plot_height <- fig_supp_19_plot_width - fig_supp_19_title_height

# Grid panel widths
fig_supp_19_widths <- c(fig_supp_19_plot_width, fig_supp_19_padding_width, fig_supp_19_plot_width)

# Grid panel heights
fig_supp_19_heights <- c(fig_supp_19_title_height, fig_supp_19_plot_height, 
                         fig_supp_19_padding_width, 
                         fig_supp_19_title_height, fig_supp_19_plot_height)

# Grid panel titles
nk_labels <- paste("K", "=", nk_range)
list_label_grobs <- map(.x = nk_labels, .f = function(x) {
  gTree(children = gList(rectGrob(gp = gpar(fill = "grey85",
                                            col = "grey30",
                                            lwd = 1)),
                         textGrob(label = x, gp = gpar(fontsize = font_size+1,
                                                       fontfamily = font_family))))
})

# Grid grob
fig_supp_19_grob <- arrangeGrob(list_label_grobs[[1]],
                                zeroGrob(),
                                list_label_grobs[[2]],
                                patchworkGrob(list_patchworks[[1]]), 
                                zeroGrob(),
                                patchworkGrob(list_patchworks[[2]]),
                                zeroGrob(),
                                list_label_grobs[[3]],
                                zeroGrob(),
                                list_label_grobs[[4]],
                                patchworkGrob(list_patchworks[[3]]), 
                                zeroGrob(),
                                patchworkGrob(list_patchworks[[4]]), 
                                layout_matrix = rbind(c(01, 02, 03),
                                                      c(04, 05, 06),
                                                      c(07, 07, 07),
                                                      c(08, 09, 10),
                                                      c(11, 12, 13)),
                                widths = fig_supp_19_widths,
                                heights = fig_supp_19_heights)

# Plot dimensions in bigpts
fig_supp_19_width_pt <- fig_width_pt
fig_supp_19_height_pt <- fig_height_pt

# Plot dimensions in inches
fig_supp_19_width_in <- fig_supp_19_width_pt/pt_per_in
fig_supp_19_height_in <- fig_supp_19_height_pt/pt_per_in

# Export
outfile <- paste(output_plot_prefix, 19, sep = "_")
outfile <- paste0(outfile, ".pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(fig_supp_19_width_in, "in"),
    height = unit(fig_supp_19_height_in, "in"))
grid.draw(fig_supp_19_grob)
dev.off()
```




# Supplementary Figure ??: Genetic variants and cross-species matches

```{r}
library(readxl)

demographics <- "../../data/human/registration/v3/subject_info/demographics.csv"
demographics <- read_csv(demographics, show_col_types = FALSE)

genetics <- "../../data/human/registration/v3/subject_info/POND_variants.xlsx"
genetics <- read_excel(genetics)
genetics <- genetics %>% 
  filter(!(SUBJECT_ID_INT %in% c("SK0664-003", "SK1016-003", "QAM-22961A2"))) %>% 
  select(POND_ID, 
         `SIGNIFICANT VARIANT TYPE`,
         `SIGNIFICANT VARIANT`,
         `CLASSIFICATION`) %>%
  filter(str_detect(POND_ID, "POND-[a-zA-Z]+.*", negate = TRUE),
         str_detect(POND_ID, ";", negate = TRUE)) %>% 
  mutate(POND_ID = str_remove(POND_ID, "-")) %>% 
  distinct()

ids_multiple <- genetics %>% 
  group_by(POND_ID) %>% 
  count() %>% 
  filter(n > 1) %>% 
  pull(POND_ID)

genetics_repeats <- genetics %>% 
  filter(POND_ID %in% ids_multiple) %>% 
  arrange(POND_ID)

genetics_unique <- genetics %>% 
  filter(!(POND_ID %in% ids_multiple)) %>% 
  arrange(POND_ID)

genetics_repeats_unique <- genetics_repeats %>% 
  filter(!is.na(CLASSIFICATION))

genetics <- bind_rows(genetics_unique, 
                      genetics_repeats_unique)

clusters <- "../../data/human/derivatives/v3/700/clusters/resolution_3.0/clusters.csv"
clusters <- read_csv(clusters, show_col_types = FALSE)
clusters <- clusters %>% 
  left_join(demographics %>% 
              select(Subject_ID, file),
            by = c("ID" = "file")) %>% 
  mutate(Subject_ID = str_remove(Subject_ID, "POND_"),
         Subject_ID = str_remove(Subject_ID, "sub-"))

clusters_genetics <- clusters %>% 
  left_join(genetics, by = c("Subject_ID" = "POND_ID")) %>% 
  mutate(gene_identified = !is.na(CLASSIFICATION)) %>% 
  distinct()

clusters_genetics <- clusters_genetics %>% 
  mutate(has_genetics = (Subject_ID %in% genetics$POND_ID))

df_clusters_long <- clusters_genetics %>% 
  select(ID, contains("nk"), gene_identified, has_genetics) %>% 
  pivot_longer(cols = c(-ID, -gene_identified, -has_genetics),names_to = "nk_name", values_to = "k") %>% 
  mutate(nk = str_remove(nk_name, "nk"),
         nk = as.numeric(nk)) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE) %>% 
  select(-nk_name)

clusters_w_matches <- c("2-1", "2-2", 
                        "3-1", "3-3", 
                        "4-1", "4-2", "4-3", 
                        "5-2", "5-5", 
                        "6-2", "6-6",
                        "7-1", "7-2", "7-4",
                        "8-1", "8-2", "8-4", "8-6", "8-7",
                        "9-4", "9-5", "9-7",
                        "10-10")

df_clusters_long <- df_clusters_long %>% 
  mutate(has_match = (cluster_id %in% clusters_w_matches))
```

```{r}
chisq.test(x = df_clusters_long$has_match,
           y = df_clusters_long$gene_identified,
           simulate.p.value = TRUE, B = 1e6)
```

```{r}
df_clusters_long_genetics_only <- df_clusters_long %>% filter(has_genetics)

chisq.test(x = df_clusters_long_genetics_only$has_match,
           y = df_clusters_long_genetics_only$gene_identified,
           simulate.p.value = TRUE, B = 1e6)
```



```{r eval = FALSE}
df_clusters_gene_counts <- df_clusters_long %>% 
  group_by(nk, k) %>% 
  summarise(ngenes = sum(gene_identified), .groups = "drop")

df_clusters_long <- df_clusters_long %>% 
  left_join(df_clusters_gene_counts, by = c("nk", "k"))

df_clusters_long <- df_clusters_long %>% 
  mutate(ngenes = ifelse(ngenes == 0, NA, ngenes))

clusters_w_matches <- c("2-1", "2-2", 
                        "3-1", "3-3", 
                        "4-1", "4-2", "4-3", 
                        "5-2", "5-5", 
                        "6-2", "6-6",
                        "7-1", "7-2", "7-4",
                        "8-1", "8-2", "8-4", "8-6", "8-7",
                        "9-4", "9-5", "9-7",
                        "10-10")

df_gene_counts_matches <- df_clusters_gene_counts %>% 
  mutate(nk = as.numeric(as.character(nk)),
         k = as.numeric(as.character(k))) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE) %>% 
  mutate(has_match = cluster_id %in% clusters_w_matches)

p_genes_and_matches_bar_agg <- df_gene_counts_matches %>% 
  group_by(nk, has_match) %>% 
  summarise(ngenes = sum(ngenes), 
            .groups = "drop") %>% 
  ggplot(aes(x = factor(nk), y = ngenes, fill = has_match)) +
  geom_col(position = "dodge") +
  scale_fill_discrete(labels = c("No", "Yes")) + 
  labs(x = "Number of clusters",
       y = "Patients with identified variants",
       fill = "Cluster matches mouse") + 
  theme_bw()

p_genes_and_matches_bar_agg
```

```{r}
clusters_genetics_only <- clusters_genetics %>% 
  filter(has_genetics)
```


```{r}
clusters_w_matches <- c("2-1", "2-2", 
                        "3-1", "3-3", 
                        "4-1", "4-2", "4-3", 
                        "5-2", "5-5", 
                        "6-2", "6-6",
                        "7-1", "7-2", "7-4",
                        "8-1", "8-2", "8-4", "8-6", "8-7",
                        "9-4", "9-5", "9-7",
                        "10-10")

list_clusters_w_matches <- list("2" = c(1, 2),
                                "3" = c(1, 3),
                                "4" = c(1, 2, 3),
                                "5" = c(2, 5),
                                "6" = c(2, 6),
                                "7" = c(1, 2, 4),
                                "8" = c(1, 2, 4, 6, 7),
                                "9" = c(4, 5, 7),
                                "10" = 10)

df_chi2 <- tibble(nk = 2:10,
                  chi2 = 0, p = 0)
for (i in 1:nrow(df_chi2)) {
  
  nk <- df_chi2[[i, "nk"]]
  cols <- c("ID", paste0("nk", nk), "gene_identified")
  new_cols <- c("ID", "k", "gene_identified")
  
  clusters_genetics_nk <- clusters_genetics[,cols]
  colnames(clusters_genetics_nk) <- new_cols
  clusters_genetics_nk <- clusters_genetics_nk %>% 
    mutate(has_match = (k %in% list_clusters_w_matches[[as.character(nk)]]),
           has_match = factor(has_match, levels = c("FALSE", "TRUE")),
           gene_identified = factor(gene_identified, levels = c("FALSE", "TRUE")))
  
  chi2_results <- tryCatch({
    chisq.test(x = clusters_genetics_nk[["has_match"]],
               y = clusters_genetics_nk[["gene_identified"]],
               simulate.p.value = TRUE, B = 1e6)
  }, error = function(e) {
    list("statistic" = NA,
         "p.value" = 0) 
  })
  
  df_chi2[[i, "chi2"]] <- chi2_results[["statistic"]][[1]]
  df_chi2[[i, "p"]] <- chi2_results[["p.value"]]
}

df_chi2
```

```{r}
tmp <- df_clusters_long %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE) %>% 
  mutate(has_match = (cluster_id %in% clusters_w_matches),
         nk = as.numeric(as.character(nk))) %>% 
  select(ID, nk, has_match, gene_identified)

tmp_summary <- tmp %>% 
  group_by(nk, has_match) %>% 
  mutate(n_per_group = n()) %>% 
  ungroup() %>% 
  group_by(nk, has_match, gene_identified) %>% 
  mutate(n_per_gene_group = n()) %>% 
  ungroup() %>% 
  select(-ID) %>% 
  distinct() %>% 
  mutate(prop_per_gene_group = n_per_gene_group/n_per_group) %>% 
  arrange(nk)

p <- tmp_summary %>%
  # ggplot(aes(x = has_match, y = prop_per_gene_group, fill = gene_identified)) +
  ggplot(aes(x = has_match, y = n_per_gene_group, fill = gene_identified)) +
  geom_col() + 
  facet_grid(.~nk) +
  # coord_cartesian(ylim = c(0, 0.1)) + 
  scale_x_discrete(labels = c("No", "Yes")) + 
  scale_fill_discrete(labels = c("No", "Yes")) + 
  labs(x = "Mouse match",
       y = "Identified variant") + 
  theme_bw() 

outfile <- "genes_and_matches_num.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(10, "in"),
    height = unit(5, "in"))
print(p)
dev.off()
```

```{r}
p <- tmp_summary %>%
  ggplot(aes(x = has_match, y = prop_per_gene_group, fill = gene_identified)) +
  geom_col() + 
  facet_grid(.~nk) +
  # coord_cartesian(ylim = c(0, 0.1)) + 
  scale_x_discrete(labels = c("No", "Yes")) + 
  scale_fill_discrete(labels = c("No", "Yes")) + 
  labs(x = "Mouse match",
       y = "Identified variant") + 
  theme_bw() 

outfile <- "genes_and_matches_prop.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(10, "in"),
    height = unit(5, "in"))
print(p)
dev.off()
```

```{r}
p <- tmp_summary %>%
  ggplot(aes(x = has_match, y = prop_per_gene_group, fill = gene_identified)) +
  geom_col() + 
  facet_grid(.~nk) +
  coord_cartesian(ylim = c(0, 0.1)) +
  scale_x_discrete(labels = c("No", "Yes")) + 
  scale_fill_discrete(labels = c("No", "Yes")) + 
  labs(x = "Mouse match",
       y = "Identified variant") + 
  theme_bw() 

outfile <- "genes_and_matches_prop_zoomed.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(10, "in"),
    height = unit(5, "in"))
print(p)
dev.off()
```


```{r}
tmp2 <- tmp %>% 
  filter(gene_identified) %>% 
  mutate(nk = factor(nk))

chisq.test(x = tmp2$nk,
           y = tmp2$has_match, 
           simulate.p.value = TRUE,
           B = 1e7)
```

```{r}
chisq.test(x = tmp$has_match,
           y = tmp$gene_identified,
           simulate.p.value = TRUE,
           B = 1e7)
```


```{r}
nperms <- 1000
df_chi2_perms <- tibble(permutation = 1:nperms,
                        chi2 = 0, p = 0)
for (i in 1:nrow(df_chi2_perms)) {
  
  set.seed(i)
  tmp_sample <- tmp %>% 
    group_by(ID) %>% 
    sample_n(size = 1) %>% 
    ungroup()
 
  chi2_results <- chisq.test(x = tmp_sample$has_match,
                             y = tmp_sample$gene_identified,
                             simulate.p.value = TRUE,
                             B = 1e5)
  
  df_chi2_perms[[i, "chi2"]] <- chi2_results$statistic
  df_chi2_perms[[i, "p"]] <- chi2_results$p.value
  
}

df_chi2_perms
```

```{r}
ggplot(df_chi2_perms, 
       aes(x = p)) + 
  geom_histogram()
```

```{r}
df_props <- tmp_summary %>% 
  filter(gene_identified, nk > 2)

ggplot(df_props, aes(x = has_match, y = prop_per_gene_group)) + 
  geom_jitter(width = 0.1)

summary(glm(prop_per_gene_group ~ has_match, data = df_props, family = "binomial"))
```

```{r}
nvariants <- tmp %>% 
  filter(gene_identified) %>% 
  pull(ID) %>% 
  unique() %>% 
  length()
  
df_props <- tmp %>% 
  filter(nk > 2, gene_identified)  %>% 
  group_by(nk, has_match) %>% 
  summarise(num = n(), 
            prop = num/nvariants,
            .groups = "drop")
  
df_props
```

```{r}
ggplot(df_props, 
       aes(x = has_match, y = prop)) + 
  geom_jitter(width = 0.2)
```
```{r}
df_props_test %>% 
  arrange(desc(prop))

df_props_test <- df_props %>% 
  filter(!(nk == 10 & !has_match))
```


```{r}
summary(glm(prop ~ has_match, data = df_props_test, family = "binomial"))
```


# Supplementary Figure ??: Univariate clinical scores analysis

```{r}
# Demogrpahics information
demographics <- file.path(PROJECTPATH, "data/human/registration/v3/", "subject_info", "demographics.csv")
demographics <- read_csv(demographics, show_col_types = FALSE)

demographics <- demographics %>% 
  filter(!is.na(DX),
         !is.na(Age),
         !is.na(Sex),
         !is.na(Site),
         !is.na(Scanner))

pond_clinical <- file.path(PROJECTPATH, "data/human/registration/v3/subject_info/POND/POND_clinical_scores_20230915.csv")
pond_clinical <- read_csv(pond_clinical, show_col_types = FALSE)
pond_clinical <- pond_clinical[,-1]

# Remove columns that aren't directly related to clinical scales
pond_clinical <- pond_clinical %>% 
  select(-contains("NSI"), 
         -contains("ETHNCTY"),
         -contains("EDUC"),
         -HSHLD_INCOME_STD,
         -PRMY_CGVR_STD)

# Remove additional columns
# DX will be joined in later
pond_clinical <- pond_clinical %>% 
  select(-site, -SUB_ID, -DOB, 
         -PRIMARY_DIAGNOSIS, -RESEARCH_CONFIRM_DIAG,
         -SWANPDOC, -TPOCSPDOC) %>% 
  rename(Subject_ID = subject)

# Extract the set of clinical scales
clinical_scales <- pond_clinical %>% 
  select(-Subject_ID) %>% 
  colnames()

clusters <- file.path(PROJECTPATH, "data/human/derivatives/v3/700/clusters/resolution_3.0/clusters.csv")
clusters <- read_csv(clusters, show_col_types = FALSE)

# Join demographics and clinical data to clusters data
clusters_clinical <- clusters %>%
  rename(file = ID) %>% 
  left_join(demographics, by = "file") %>% 
  mutate(Subject_ID = str_remove(Subject_ID, "sub-")) %>% 
  filter(Dataset == "POND") %>% 
  mutate(Subject_ID = as.numeric(Subject_ID)) %>% 
  left_join(pond_clinical, by = "Subject_ID")

# Convert cluster data to long format
clusters_long <- clusters %>% 
  pivot_longer(cols = -ID, names_to = "nk", values_to = "k") %>% 
  mutate(nk = str_remove(nk, "nk"),
         nk = as.numeric(nk),
         k = as.numeric(k)) %>% 
  unite(col = "cluster_id", nk, k, sep = "-", remove = FALSE)

# Number of participants per cluster
cluster_counts <- clusters_long %>% 
  group_by(cluster_id, nk, k) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(nk, k)
```

```{r}
# Number of patients with clinical data
npatients <- nrow(clusters_clinical)

# Calculate the completion rate for each of the scales
scales_completed <- clusters_clinical %>% 
  select(Subject_ID, all_of(clinical_scales)) %>% 
  pivot_longer(cols = -Subject_ID, 
               names_to = "scale",
               values_to = "score") %>% 
  mutate(missing = is.na(score)) %>% 
  group_by(scale) %>% 
  summarise(ncompleted = sum(!missing),
            pcompleted = ncompleted/npatients,
            .groups = "drop") 

# Proportions plot for scale completion rate.
p_scale_completion <- scales_completed %>% 
  select(-ncompleted) %>% 
  mutate(scale = factor(scale, levels = clinical_scales),
         pmissing = 1 - pcompleted) %>% 
  rename(completed = pcompleted,
         missing = pmissing) %>% 
  pivot_longer(cols = -scale, names_to = "status", values_to = "percent") %>% 
  mutate(status = factor(status, levels = c("missing", "completed"))) %>% 
  ggplot(aes(x = percent, y = fct_rev(scale),
             fill = status)) + 
  geom_col(width = 1,
           col = "grey50") + 
  geom_vline(xintercept = seq(0.2, 1.0, by = 0.2),
             linetype = "dashed",
             col = "red") + 
  scale_fill_manual(values = c("grey90", "green3"),
                    labels = c("Missing", "Completed")) +
  labs(x = "Percentage", y = "Scale", fill = NULL) +
  scale_x_continuous(breaks = seq(0, 1.0, by = 0.2),
                     expand = expansion(),
                     sec.axis = sec_axis(~.*npatients,
                                         name = "Number of patients",
                                         breaks = round(seq(0, 1.0, by = 0.2)*npatients))) + 
  theme_bw() +
  theme(axis.text.y = element_text(size = 7))

# Export plot
outfile <- "clinical_scale_completion.pdf"
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_scale_completion)
dev.off()
```

```{r}
# Get the scales with the minimum completion rate
completion_threshold <- 120
clinical_scales_thresh <- scales_completed %>% 
  filter(ncompleted > completion_threshold) %>% 
  pull(scale)

# Subset the data set for those scales with suitable completion
clusters_clinical_thresh <- clusters_clinical %>% 
  select(Subject_ID, contains("nk"), all_of(clinical_scales_thresh))

# Some scales have values of 999. Set these to NA.
for (s in clinical_scales_thresh) {
  scores <- clusters_clinical_thresh[[s]]
  scores[scores == 999] <- NA
  clusters_clinical_thresh[[s]] <- scores
}
```


```{r}
# Compute Wilcoxon rank sum tests for all select scales 
# across 2-cluster solutions

# Initialize results data frame
df_wilcoxon <- tibble(nk = 2, 
                      scale = clinical_scales_thresh) %>% 
  mutate(uval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_wilcoxon)) {
  
  # Pull nk and scale acronym
  nk <- df_wilcoxon[[i, "nk"]]
  s <- df_wilcoxon[[i, "scale"]]
  
  # Get cluster labels and scale scores
  labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
  scores <- clusters_clinical_thresh[[s]]
  
  # Remove patients with missing scores
  missing <- is.na(scores)
  labels <- labels[!missing]
  scores <- scores[!missing]
  
  # Check that completed entries are not all in 
  # a single cluster. If they are, set NA. 
  # Otherwise, run Wilcoxon test.
  labels_count <- table(labels)
  test_ngroups <- length(labels_count) > 1
  if (test_ngroups) {
    wilcoxon <- wilcox.test(scores ~ factor(labels))
    df_wilcoxon[[i, "uval"]] <- wilcoxon[["statistic"]]
    df_wilcoxon[[i, "pval"]] <- wilcoxon[["p.value"]]
  } else {
    df_wilcoxon[[i, "uval"]] <- NA
    df_wilcoxon[[i, "pval"]] <- NA
  }
  df_wilcoxon[[i, "npatients"]] <- length(labels)
}

# Significance bins
sig_bins <- c("p >= 0.1",
              "0.05 <= p < 0.1",
              "0.01 <= p < 0.05",
              "p < 0.01")

# Convert p-values to log scale and create significance bins
df_wilcoxon_p <- df_wilcoxon %>% 
  mutate(pval_log = -log10(pval),
         scale = factor(scale, levels = clinical_scales_thresh),
         significance = case_when(pval >= 0.1 ~ sig_bins[1],
                                  pval >= 0.05 & pval < 0.1 ~ sig_bins[2],
                                  pval >= 0.01 & pval < 0.05 ~ sig_bins[3],
                                  pval < 0.01 ~ sig_bins[3]),
         significance = factor(significance, levels = sig_bins))

# p-value thresholds
pval_thresh <- c(0.1, 0.05, 0.01)
pval_thresh_log <- -log10(pval_thresh)
```


```{r}
# Point and segment plot for significance
p_nk2_pvals <- ggplot(df_wilcoxon_p, 
                      aes(x = pval_log, y = scale, col = significance)) + 
  geom_segment(aes(xend = 0, yend = scale)) + 
  geom_point() +
  geom_vline(xintercept = pval_thresh_log,
             linetype = "dashed") +
  scale_color_manual(values = c("grey60", "red2", "red4")) +
  scale_x_continuous(breaks = seq(0, 2, by = 0.2), 
                     expand = expansion(add = c(0, 0.05)),
                     sec.axis = sec_axis(~ 1/(10^.), breaks = c(1.0, 0.1, 0.05, 0.01), name = "p")) +
  labs(x = "-log10(p)",
       y = "Clinical scale") + 
  theme_bw() +
  theme(legend.position = "none")

# Export plot
outfile <- paste0("clinical_scores_nk_2_wilcoxon_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_nk2_pvals)
dev.off()
```

```{r}
# Compute Kruskal-Wallis tests for all select scales 
# across all cluster solutions

# Maximum number of cluster solutions
nk_max <- max(cluster_counts["nk"])

# Initialize results data frame
df_kw <- expand_grid(nk = 2:nk_max,
                     scale = clinical_scales_thresh) %>% 
  mutate(hval = 0, pval = 0, npatients = 0)

# Iterate over scales
for (i in 1:nrow(df_kw)) {
  
  # Pull nk and scale acronym
  nk <- df_kw[[i, "nk"]]
  s <- df_kw[[i, "scale"]]
  
  # Get cluster labels and scale scores
  labels <- clusters_clinical_thresh[[paste0("nk", nk)]]
  scores <- clusters_clinical_thresh[[s]]
  
  # Remove patients with missing scores
  missing <- is.na(scores)
  labels <- labels[!missing]
  scores <- scores[!missing]
  
  # Check that completed entries are not all in 
  # a single cluster. If they are, set NA. 
  # Otherwise, run KW test.
  labels_count <- table(labels)
  test_ngroups <- length(labels_count) > 1
  if (test_ngroups) {
    kw <- kruskal.test(x = scores, g = factor(labels))
    df_kw[[i, "hval"]] <- kw[["statistic"]]
    df_kw[[i, "pval"]] <- kw[["p.value"]]
  } else {
    df_kw[[i, "hval"]] <- NA
    df_kw[[i, "pval"]] <- NA
  }
  df_kw[[i, "npatients"]] <- length(labels)
}

# Convert p-values to log scale and create significance indicator
df_kw_p <- df_kw %>% 
  mutate(nk = factor(nk),
         scale = factor(scale, levels = clinical_scales_thresh),
         pval_log = -log10(pval),
         significant = case_when(pval < 0.05 ~ "**",
                                 pval >= 0.05 & pval < 0.1 ~ "*",
                                 pval >= 0.1 ~ ""))

p_kw_pvals <- ggplot(df_kw_p,
                     aes(x = nk, y = scale, fill = pval_log)) + 
  geom_tile(col = "black") +
  geom_text(mapping = aes(label = significant)) + 
  scale_x_discrete(expand = expansion()) + 
  scale_y_discrete(expand = expansion()) + 
  scale_fill_gradientn(colours = brewer.pal(n = 9, name = "Reds")) +
  labs(x = "Number of clusters",
       y = "Clinical scale",
       fill = "-log10(p)") +
  theme_bw()

# Export plot
outfile <- paste0("clinical_scores_kruskalwallis_pvals.pdf")
outfile <- file.path(output_dir, outfile)
pdf(file = outfile,
    width = unit(8, "inch"),
    height = unit(8, "inch"))
print(p_kw_pvals)
dev.off()
```

```{r}
df_kw %>% 
  group_by(nk) %>% 
  mutate(qval = p.adjust(pval, method = "fdr")) %>% 
  ungroup() %>% 
  summarise(fdr5 = sum(qval < 0.05),
            fdr10 = sum(qval < 0.10),
            fdr20 = sum(qval < 0.20))
```
```{r}
for (K in 2:10) {
  nsig <- df_kw %>% 
    filter(nk == K) %>% 
    mutate(qval = p.adjust(pval, method = "fdr"),
           significant = qval < 0.05) %>% 
    pull(significant) %>% 
    sum()
  print(nsig)
}
```


